<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Rust 错误处理]]></title>
    <url>%2F2020%2F06%2F02%2Frust-error-handling%2F</url>
    <content type="text"><![CDATA[引言 本文内容主要翻译自 Andrew Gallant 的文章 Error Handling in Rust。 如同大多数的编程语言，Rust 中也需要通过特定的方式处理错误。众所周知，目前常见的错误处理方式主要分为两种： 异常机制（C#/Java/Python 等）； 返回错误（Go/Rust 等）。 本文将会综合全面地介绍 Rust 中的错误处理，通过循序渐进地引导，带领初学者扎实地掌握这块知识。如果我们不熟悉标准库的话，我们可能会使用较为愚蠢的方式处理错误，这种会比较繁琐，产生很多样板代码。所以本文会演示如何借助标准库让错误处理更加优雅和简洁。 说明本文的代码放在作者的 博客仓库。Rust Book, Error Handling 中也有关于错误处理的部分，可以参照阅读。 本文篇幅巨长，主要是因为写了很多关于 Sum Types 和组合子（Combinators）的内容作为开头，逐步讲解 Rust 错误处理方式的改进。因此，如果你认为没有必要的话，也可以略过。以下是作者提供的简要指南： 如果你是 Rust 新手，对于系统编程和富类型系统（expressive type systems）不太熟悉的话，推荐你从头开始阅读（如果是完全没有了解过 Rust 的童鞋，推荐先阅读下 [Rust Book](https://doc.rust-lang.org/book/title-page.html）； 如果你从来没有了解过 Rust，但是对于函数式语言很熟悉（看到「代数数据类型（algebaric data types）」和「组合子（combinators）」不会让你感到陌生），那也许可以直接跳过基础部分，从「多错误类型」部分开始阅读，然后阅读「标准库中的 error traits」部分; 如果你已经拥有 Rust 编程经验，并且只想了解下错误处理的方式，那么可以直接跳到最后，看看作者给出的案例研究（当然，还有译者给出的实际案例）。 运行代码如果想要直接运行样例代码，可以参考下面的操作： 123$ git clone git://github.com/BurntSushi/blog$ cd blog/code/rust-error-handling$ cargo run --bin NAME-OF-CODE-SAMPLE [ args ... ] TL;TR文章太长，如果没耐心阅读的话，我们可以先来看看关于 Rust 错误处理的一些总结。以下是作者提供的「经验法则」，仅供参考，我们可以从中获得一些启发。 如果你正在编写简短的示例代码，并且可能会有不少错误处理的负担，这种场景下可以考虑使用 unwrap（比如 Result::unwrap, Option::unwrap 或者 Option::expect 等）。阅读你代码的人应该知道如何以优雅的姿势处理错误（如果 TA 不会，把这篇文章甩给 TA 看）； 如果你正在写一个类似临时脚本一样的程序（quick-n-dirty program），直接用 unwrap 也不用觉得羞愧。不过需要注意的是：如果别人接收你这个程序，那可能是要不爽的哦（毕竟没有特别丰富的错误消息）； 对于👆的场景，如果你觉得直接用 unwrap 不太好（毕竟出错会直接 panic 掉），那么可以考虑使用 Box&lt;dyn Error&gt; 或者 anyhow::Error 类型作为函数的错误返回类型。如果使用了 anyhow crate，当使用 nightly 版本的 Rust 时，错误会自动拥有关联的 backtrace； 要是上面的方法还不行，那么可以考虑自定义错误类型，并且实现 From 和 Error trait，从而可以顺利地使用 ? 操作符，让错误处理更加优雅（要是你连 From 和 Error trait 也不愿意动手实现的话，可以使用 thiserror 来自动生成）； 如果你正在编写一个库，并且可能会产生错误，推荐你自定义错误类型，并且实现 std::error::Error trait，并且实现合适的 From trait，从而方便库的调用者编写代码（因为基于 Rust 的相干性原则（coherence rules），调用者不能为库中定义的错误类型实现 From，因此这是库作者的职责）； 学会使用 Option 和 Result 中定义的组合子，有时候只是使用它们可能比较索然无味，但是可以通过合理地组合使用 ? 操作符合组合子来改善代码。and_then, map 和 unwrap_or 是作者比较喜欢的几个组合子。 总结一下流程如下： 基础知识错误处理可以看成是利用 分支判断（case analysis） 逻辑来指示一次计算成功与否。优雅的错误处理方式，关键就是要考虑减少显式编写分支判断逻辑的代码，同时还能保持代码的可组合性（就是让调用方有错误处理的决定权，调用方可以在约到错误时 panic 或者只是打印出错误消息）。 保持代码的可组合性非常重要，否则我们可能在任何遇到不可预期的异常时出现 panic（panic 会导致当前的线程栈展开，多数情况下，还会导致整个进程退出）。示例如下： 1234567891011121314// file: panic-simple//// Guess a number between 1 and 10.// If it matches the number I had in mind, return true. Else, return false.fn guess(n: i32) -&gt; bool &#123; if n &lt; 1 || n &gt; 10 &#123; panic!("Invalid number: &#123;&#125;", n); &#125; n == 5&#125;fn main() &#123; guess(11);&#125; 如果尝试运行上述代码，程序会直接崩溃，并且会吐出下面的消息： 1thread '&lt;main&gt;' panicked at 'Invalid number: 11', src/bin/panic-simple.rs:5 下面这个例子，对于用户输入更加不可预知。它预期用户输入一个整数字符串，然后将其转换成整数后再乘以 2，打印出结果： 123456789101112// file: unwrap-doubleuse std::env;fn main() &#123; let mut argv = env::args(); let arg: String = argv.nth(1).unwrap(); // error 1 let n: i32 = arg.parse().unwrap(); // error 2 println!("&#123;&#125;", 2 * n);&#125;// $ cargo run --bin unwrap-double 5// 10 如果我们输入的是 0 个参数（error 1），或者干脆输入不可转换成整数的字符串（error 2），则会导致程序 panic 掉。 Unwrap 详解unwrap-double 示例中，虽然没有显式地使用 panic，但是它在遇到错误时依然会 panic 掉。这是因为 unwrap 内部调用了 panic。 unwrap 在 Rust 中的意思是这样的：根据提供的计算结果，如果是错误结果，则会直接调用 panic。也许你开始好奇 unwrap 真正的实现了（实现很简单），不过在我们学习完 Option 和 Result 类型后自然就知道了。这两种类型都有关联的 unwrap 方法定义。 Option 类型Option 类型是标准库定义的枚举类型： 1234enum Option&lt;T&gt; &#123; None, Some(T),&#125; 在 Rust 中，我们可以利用 Option 类型来表达存在性。将这种类型加入到 Rust 的类型系统非常重要，这样编译器会强制使用者处理存在性。下面来看个简单的示例： 12345678910// Searches `haystack` for the Unicode character `needle`. If one is found, the// byte offset of the character is returned. Otherwise, `None` is returned.fn find(haystack: &amp;str, needle: char) -&gt; Option&lt;usize&gt; &#123; for (offset, c) in haystack.char_indices() &#123; if c == needle &#123; return Some(offset); &#125; &#125; None&#125; 温馨提示：不要在你的代码中使用上述代码，直接使用标准库提供的 find 方法 我们注意到，上述函数在找到匹配的字符后，不会直接返回 offset，而是返回 Some(offset)。Some 是 Option 类型的值构造器，可以将它想象成这样的函数：fn&lt;T&gt;(value: T) -&gt; Option&lt;T&gt;。相应地，None 也是一个值构造器，不过它没有参数，可以将它想象成这样的函数：fn&lt;T&gt;() -&gt; Option&lt;T&gt;。 Oops，看起来有点无聊哦，不过故事还没唠完。我们来看看怎么使用 find 函数，下面就利用它查找文件扩展名： 1234567fn main_find() &#123; let file_name = "foobar.rs"; match find(file_name, '.') &#123; Some(i) =&gt; println!("File extension: &#123;&#125;", &amp;file_name[i+1..]), None =&gt; println!("No file extension found."), &#125;&#125; 上述代码对于 find 返回的 Option&lt;usize&gt; 使用了「模式匹配」来执行分支判断。事实上，分支判断是获得 Option&lt;T&gt; 内部值的唯一方式。因此我们必须要处理好 Option&lt;T&gt; 为 None 的情况。 啊喂，等下，在前面提到的 unwrap 是怎么实现的呢？没错，它的内部也使用了分支判断！我们也可以自己定义这样的方法： 1234567891011121314enum Option&lt;T&gt; &#123; None, Some(T),&#125;impl&lt;T&gt; Option&lt;T&gt; &#123; fn unwrap(self) -&gt; T &#123; match self &#123; Option::Some(val) =&gt; val, Option::None =&gt; panic!("called `Option::unwrap()` on a `None` value"), &#125; &#125;&#125; unwrap 为我们封装了分支判断逻辑，方便我们使用。不过由于它内部使用了 panic! 调用，这也意味着它不具备可组合性。 组合 Option&lt;T&gt; 值Result 类型解析整数Result 类型别名小插曲：unwrap 并非邪恶处理多种错误类型组合 Option 和 Result组合子的限制提前返回使用 try! 宏或者 ? 操作符自定义错误类型标准库中的错误处理 traitError traitFrom traittry! 和 ? 内部实现组合自定义错误类型给库作者的一些建议案例研究：阅读人口数据的小程序它在 GitHub 上配置参数解析编写业务逻辑使用 Box&lt;dyn Error&gt; 处理错误从 stdin 中读取使用自定义错误类型添加功能独创案例研究：新冠数据查询原文 Error Handling in Rust]]></content>
      <categories>
        <category>Rust</category>
      </categories>
      <tags>
        <tag>Rust</tag>
        <tag>Error Handling</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Talent Plan 之 Rust 网络编程实践（二）：预备知识]]></title>
    <url>%2F2020%2F04%2F21%2Ftalent-plan-rust-network-programming-bb2%2F</url>
    <content type="text"><![CDATA[引言 材料阅读炫酷算法之日志结构存储Damn Cool Algorithms: Log structured storage 日志结构文件系统设计与实现Bitcask，高性能 &amp; 基于日志结构的 Key/Value 存储Rust 中的错误处理std::collections 文档学习std::io 文档学习练习题使用 serde 序列化和反序列化数据结构（JSON）使用 serde 序列化和反序列化数据结构（RON）使用 serde 序列化反序列化 1000 个数据结构（BSON）小结参考 PNA Rust — Building Blocks 2 What’s rustdoc 延伸阅读 What is the difference between a journaling vs a log structured file system? Journaling and Log-structured file systems]]></content>
      <categories>
        <category>Rust</category>
      </categories>
      <tags>
        <tag>Rust</tag>
        <tag>网络编程</tag>
        <tag>Log-Structured</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Talent Plan 之 Rust 网络编程实践（二）：编写内存 KV 存储]]></title>
    <url>%2F2020%2F04%2F17%2Ftalent-plan-rust-network-programming-proj1%2F</url>
    <content type="text"><![CDATA[引言经过 上一节 的学习，相信对于 Cargo、Rust API 文档编写规范、命令行工具编写都有了初步认识，没有掌握也没关系。本节将会继续深入学习和实践，我们将采用 测试驱动开发（Test-Driven Development, TDD） 的方式编写一个简单的内存 key-value 存储库，以及一个命令行工具用于接收和处理增删查命令，并且最终还要能够通过所有单元测试。 关键词：单元测试、clap 和 structopt crate、Cargo 环境变量、clippy 和 rustfmt 工具 目标： 学习规范的项目结构； 学习 cargo new/init/test/run/clippy/fmt 命令； 学习如何从 crates.io 导入新的 crates； 为 key-value 存储定义合适的数据类型。 了解 TDD测试驱动开发（Test-Driven Development） 是一种比较有趣的软件开发模式，简单来说，就是根据需求先写好单元测试条例，然后再去编写业务逻辑，让测试通过。通过测试驱动软件开发推进，一方面可以保证我们编写的代码满足需求，另一方面也能增强我们的信心，充足单元测试也有助于代码重构，避免出现核心逻辑变动而导致 Bug。 在 Test-Driven Development by Example 中给出了 TDD 的基本流程： 为新功能编写测试； 运行所有测试，查看新功能相关测试是否失败； 编写代码； 运行测试，如果没有通过测试，则回到上一步继续修复代码； 重构代码； 不断重复上述流程。 需要注意的是，再次运行所有测试前，最好每次变更的代码不要太多。这样一旦有测试失败，可以快速定位问题，并进行修复或者回滚。 命令行和接口约定本节会创建一个名叫 tinkv 的项目，包含一个名为 tinkv 的命令行客户端，将会调用 tinkv 库中提供的方法（和命令行客户端打通放到后面小节介绍）。 tinkv 命令行客户端需要支持如下操作： tinkv set &lt;key&gt; &lt;value&gt;：设置 String 类型的 key value 到存储中； tinkv get &lt;key&gt;：查询指定 key 对应的 String 值； tinkv rm &lt;key&gt;：删除指定的 key； tinkv -V：打印程序的版本号。 tinkv 库中定义了一个 KvStore 类型，封装了存储服务的操作，需要支持如下操作： KvStore::set(&amp;mut self, key: String, value: String) KvStore::get(&amp;self, key: String) -&gt; Option&lt;String&gt; KvStore::remove(&amp;mut self, key: String) 动手实践创建项目使用 Cargo 新建项目 tinkv。 12$ cargo new tinkv$ cd tinkv 然后创建 src/bin/tinkv.rs, src/lib.rs 和 src/kvstore.rs 文件，还有一个存放测试的文件 tests/tests.rs。最终的目录结构如下： 12345678910.├── Cargo.toml├── README.md├── src│ ├── bin│ │ └── tinkv.rs│ ├── kvstore.rs│ └── lib.rs└── tests └── tests.rs 紧接着，我们在 src/bin/tinkv.rs 中创建一个简单的 main 函数： 123fn main() &#123; println!("hello, tinkv");&#125; 在 src/kvstore.rs 中新增 KvStore 类型： 1234#[derive(Debug)]struct KvStore &#123;&#125; 然后在 src/lib.rs 中导出 KvStore 类型，这样可以在测试以及 src/bin/tinkv.rs::main() 中使用： 12mod kvstore;pub use kvstore::KvStore; 最后，我们完善下 Cargo.toml 中 [package] 部分： 123456789[package]name = "tinkv"version = "0.1.0"authors = ["0xE8551CCB &lt;noti@ifaceless.space&gt;"]edition = "2018"description = "A simple key-value store"keywords = ["database", "key-value"]categories = ["Development"]license = "MIT" 添加单元测试按照 TDD 的方式，我们需要先完成新需求对应的单元测试编写，不过现在已经为你准备好啦，所以请到 tinkv/tests 中将所有测试复制到本地 tests/tests.rs 文件中。 仔细阅读测试文件，可以发现有两类测试： cli_* 是针对命令行客户端的测试； get_stored_value 等是针对 tinkv::KvStore 的功能测试。 1234567#[test]fn cli_no_args() &#123;/* 省略内容 */&#125;//===============分割线===============#[test]fn get_stored_value() &#123; /* 省略内容 */&#125; 单元测试某种意义上也是文档的补充，它清晰描述了某个接口的行为，而我们只需要实现那个行为即可通过单元测试。所以后面的我们的任务便是逐个通过单元测试，完成功能开发。 安装测试依赖包现在，我们来运行下测试看看会发生什么（不用多想，一定会失败，重点是找到原因），运行 cargo test 结果如下： 果不其然，看起来 assert_cmd, predicates crate 无法导入，这时我们需要编辑下 Cargo.toml 添加一下测试需要的依赖包： 123[dev-dependencies]assert_cmd = "0.11.0"predicates = "1.0.0" 然后，我们再次运行 cargo test 看看效果，看起来还是失败了嘛，不过这次报错的原因是我们还没有给 tinkv::KvStore 实现 get, set, remove 方法呢。 编写 KvStore当前的目标是让测试跑起来，至少不要编译失败，也就是要让 cargo test --no-run 能够正常运行起来。从上面的报错看到 tinkv::KvStore 还缺少必须的方法定义呢，不过我们目前先完成框架，即函数定义，实现细节先用 panic!() 替代（当然，我们也可使用 unimplemented!()，不过 panic!() 字数更少，在这种场景下用得更多）。 添加函数定义如下： 123456789#[derive(Debug)]pub struct KvStore &#123;&#125;impl KvStore &#123; pub fn new() -&gt; Self &#123; KvStore &#123;&#125; &#125; pub fn set(&amp;mut self, key: String, value: String) &#123; panic!(); &#125; pub fn get(&amp;self, key: String) -&gt; Option&lt;String&gt; &#123; panic!(); &#125; pub fn remove(&amp;mut self, key: String) &#123; panic!(); &#125;&#125; 好啦，这时再执行 cargo test 后可以发现已经可以编译通过，并能运行单元测试了（虽然都挂了，但至少编译通过了，可喜可贺）。 关于 cargo test 使用提示细心的话，可以看到测试输出中有这样的提示： 1234567891011121314running 0 teststest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out Running target/debug/deps/tinkv-3292fe1fc5408d8crunning 0 teststest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out Running target/debug/deps/tests-850c7d178475e2f3running 13 tests... 看起来是运行了三次测试嘛，这是因为 cargo test 默认会在如下几个位置查找并运行测试： 库源码里面； 每个二进制文件的源码中； 每个测试文件； 库文档测试。 不过我们可以通过添加额外的参数，指定运行测试，选项如下（详细可以通过 cargo help test 查看）： cargo test --lib cargo test --doc cargo test --bins cargo test --bin foo cargo test --test foo 通常我们在实现某个接口功能时，可以只运行对应的测试，方式如下： 12# 仅运行名称为 cli_no_args 的测试函数cargo test cli_no_args 编写命令行客户端在之前的小节中，我们已经学习了如何使用 clap 来创建一个 CLI App，也演示了通过 cli.yml 配置或者在代码中使用 clap 提供的构造函数生成命令行应用的方式。但是存在两个问题： 生成 clap::App 时，需要编写很多样板代码，比较啰嗦； 在处理命令行参数时，使用 matches.value_of(&quot;arg&quot;) 的方式拿到值后，可能还涉及到类型转换等操作，也同样会产生很多样板代码，不够优雅和高效。 本节将会引入一个新的 crate structopt，我们将命令行参数通过结构体成员变量表示，参数类型、帮助信息等编写起来都很轻松，它使用 Rust 宏来帮助我们生成 clap::App，同时可以自动完成参数类型转换，非常灵活。 首先，使用 cargo add structopt 添加该依赖指项目中，然后在 src/bin/tinkv.rs 中配置命令行参数对应的结构体，并根据单元测试的预期行为实现命令行程序如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253use std::process::exit;use structopt::StructOpt;#[derive(StructOpt, Debug)]enum Command &#123; /// Get value from store Get &#123; /// A string key key: String, &#125;, /// Save key value to store Set &#123; /// A string key key: String, /// A string value value: String, &#125;, #[structopt(name = "rm")] /// Remove value from store Remove &#123; /// A string key key: String, &#125;,&#125;#[derive(StructOpt, Debug)]#[structopt( rename_all = "kebab-case", name = env!("CARGO_PKG_NAME"), about = env!("CARGO_PKG_DESCRIPTION"), version = env!("CARGO_PKG_VERSION"), author = env!("CARGO_PKG_AUTHORS"),)]struct Opt &#123; #[structopt(subcommand)] command: Command,&#125;fn main() &#123; let opt = Opt::from_args(); match opt.command &#123; Command::Get &#123; key: _key &#125; =&gt; unimplemented(), Command::Set &#123; key: _key, value: _value &#125; =&gt; unimplemented(), Command::Remove &#123; key: _value&#125; =&gt; unimplemented(), &#125;&#125;/// 暂时没有实现命令行执行时与 [`tinkv::KvStore`] 的交互，/// 因为当前还不能持久化存储。fn unimplemented() &#123; eprintln!("unimplemented"); exit(1);&#125; 此时，使用 cargo test --tests cli 运行所有和命令行有关的测试，不出意外的话，应该会全部通过。 1234567891011121314151617$ cargo test --tests cli...test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out Running target/debug/deps/tests-850c7d178475e2f3running 9 teststest cli_get ... oktest cli_invalid_rm ... oktest cli_invalid_get ... oktest cli_invalid_subcommand ... oktest cli_set ... oktest cli_rm ... oktest cli_no_args ... oktest cli_invalid_set ... oktest cli_version ... ok... 将数据保存到内存中简单起见，我们使用 HashMap&lt;String, String&gt; 保存设置的数据到内存，让单元测试通过。具体实现比较简单，不再赘述。 1234567891011121314151617181920212223242526use std::collections::HashMap;#[derive(Debug)]pub struct KvStore &#123; db: HashMap&lt;String, String&gt;,&#125;impl KvStore &#123; pub fn new() -&gt; Self &#123; KvStore &#123; db: HashMap::new(), &#125; &#125; pub fn set(&amp;mut self, key: String, value: String) &#123; self.db.insert(key, value); &#125; pub fn get(&amp;self, key: String) -&gt; Option&lt;String&gt; &#123; self.db.get(&amp;key).map(|x| x.to_string()) &#125; pub fn remove(&amp;mut self, key: String) &#123; self.db.remove(&amp;key); &#125;&#125; 至此，运行 cargo test 后，所有的测试用例应该都会通过了。 1234567891011121314151617$ cargo test...running 13 teststest cli_get ... oktest cli_invalid_rm ... oktest cli_invalid_subcommand ... oktest cli_invalid_get ... oktest cli_no_args ... oktest cli_invalid_set ... oktest get_non_existent_value ... oktest get_stored_value ... oktest overwrite_value ... oktest remove_key ... oktest cli_rm ... oktest cli_set ... oktest cli_version ... ok... 规范文档在上一节中已经提到如何规范编写 API 文档了，本节不再赘述，但是需要强调的是文档非常重要。在 Rust 标准库以及一些优秀的第三方 crates 中，通常会在代码中看到非常丰富且规范的文档，建议多多阅读。 这里需要提几点： 在编写好文档后，一般可以通过 cargo doc --open 在本地浏览器查看 API 文档（生成的文档位于 target/doc 目录下）； 可以使用 cargo test --doc 对文档中的示例进行测试； 在 src/lib.src 顶部添加 #![deny(missing_docs)] 会强制所有公开的类型、函数等必须编写文档，否则编译失败。 所以，在完成代码编写后，一定要添加上规范的文档哦~ clippy 和 rustfmtclippy 和 rustfmt 是 Rust 工具链中两款重要的工具： clippy 会检查到代码中不够优雅或者可能会导致错误的模式，并会给出修改建议； rustfmt 则会格式化代码，保证代码风格一致。 这两个组件默认没有安装，需要通过下面的方式安装： 12$ rustup component add clippy$ rustup component add rustfmt 安装后，可以通过 cargo clippy 和 cargo fmt 分别调用它们。强烈建议在提交代码前，先运行 cargo clippy 将建议修改的地方修改好，然后使用 cargo fmt 格式化好代码后再提交到主干。 小结本节以实践为主，采用 TDD 方式逐步完成了一个简单的内存 key-value 存储库以及一个命令行客户端，并最终通过了所有单元测试，在最后再次强调了文档规范以及代码风格统一、程序健壮的重要性。本节涉及的完整的源码参见：tinkv_v0.2.0。 参考 Project 1: The Rust toolbox]]></content>
      <categories>
        <category>Rust</category>
      </categories>
      <tags>
        <tag>Rust</tag>
        <tag>网络编程</tag>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Talent Plan 之 Rust 网络编程实践（一）：预备知识]]></title>
    <url>%2F2020%2F04%2F15%2Ftalent-plan-rust-network-programming-bb1%2F</url>
    <content type="text"><![CDATA[引言今天开始「Rust 网络编程实践」的第一部分中的预备知识学习，并最终能编写出一个简单的命令行工具。以下材料是今天需要阅读的： The Cargo manifest format：了解 Cargo mainfest 文件格式； Cargo environment variables：了解 Cargo 环境变量； Rust API Guidelines: Documentation：了解 Rust 程序中的文档编写； Write a Good CLI Program：学习如何编写命令行程序。 接下来我们将依次完成上述材料学习，着重记录一些知识点，并在最后编写一个简单的命令行程序。 Cargo Manifest 文件格式 在使用 cargo 命令创建的项目中，都会存在一个 cargo.toml 文件，这也就是所谓的 manifest。一个简单的示例如下： 1234567891011[package]name = "app"version = "0.1.0"authors = ["0xE8551CCB &lt;user@host&gt;"]edition = "2018"[dependencies]clap = &#123;version = "2.33.0", features = ["yaml"]&#125;maplit = "1.0.2"lazy_static = "1.4.0"yaml-rust = "0.3.5" cargo.toml 是由多个部分配置组成的，主要包括如下几个部分（详细定义请参考文档）： cargo-features: 实验性功能 [package]: 包定义（如名称、版本、作者、Rust 编译器版本等） [[lib]]: 库的设置 [[bin]]: 二进制文件设置 [[example]]: 示例文件设置 [[test]]: 测试设置 [[bench]]: 基准测试设置 [dependencies]: 依赖库列表 [features]: 条件编译功能 [workspace]: 工作空间定义 Cargo 环境变量环境变量可以用来和 rustc 以及 Cargo 进行通信，可以在代码中通过 env! 宏或者在构建脚本中设置环境变量，这样可以控制构建行为。相关环境变量比较多，笔者在这里不多赘述了，等用到时再来查阅。建议把 Cargo environment variables 简单阅读下，留个印象。 Rust 程序文档编写Rust API Guidelines 列出了一些设计和编写 Rust API 的建议，主要是由 Rust Lib 小组在构建 Rust 生态，编写标准库和一些其它 crates 期间总结而来。当然，这些建议并非一定需要遵守，不过既然来自于官方，那还是非常值得像笔者这样的 Rust 小白学习的。 今天主要学习其中关于文档编写的一些建议，其它内容建议抽空阅读下。关于文档编写的一些大建议梳理如下（详细示例还请参见文档 Rust API Guidelines: Documentation）： crate 级别的文档应该是全面详细的，且包含使用示例； 所有公开的模块、trait、struct、enum、函数、方法、宏以及类型定义都需要提供使用示例； 文档中的实例应该使用 ? 处理错误，而非 try! 或者 unwrap； 函数的文档中应该包括：函数功能描述、返回的错误（# Errors）、Panic 情况（# Panics）以及一些安全使用的提示（# Safty，比如 std::ptr::read 这种 unsafe 函数）； 文档中提到的类型应该关联到对应的文档（Link all the things）； Cargo.toml 中应该包含所有常用的元信息： authors description license repository readme keywords categories crate 要设置正确的 #![doc(html_root_url = &quot;https://docs.rs/CRATE/MAJOR.MINOR.PATCH&quot;)]，尤其要注意这里的版本号要和 Cargo.toml 中的 version 保持一致； 在发布日志（Release notes）中记录所有重大变更，尤其是不兼容变更需要清晰指出； 可以通过 #[doc(hidden)] 将一些没什么帮助的实现细节（如私有类型关联的方法实现等）从生成的文档中隐藏起来。 如何编写命令行（CLI）程序（Write a Good CLI Program）Write a Good CLI Program 一文中讲解在使用 Rust 编写命令行程序的最佳实践，核心知识点包括： 使用 clap crates 编写可以接收复杂参数的命令行程序； 使用 .env 编写应用配置，使用 dotenv 读取环境变量； 错误处理： panic 会导致程序直接退出，退出没有错误码，适合在脚本中使用； 函数返回 Result，可以根据是否为 Error 来决定后续操作； 可以为自定义 Error 实现 fmt::Display trait，方便格式化输出错误消息。 使用 println!() 会打印到标准输出中，而使用 eprintln!() 则是标准错误； 使用 std::process::exit(1) 设置程序退出码（Exit Code）。 所谓的命令行程序（Command Line Interface, CLI）就是指在终端中运行的程序，没有图形界面。比如 ls, ps 等。在 awesome-cli-apps 中收集了很多比较优质的命令行程序。 题外话：作者安利了一个叫作 exa 命令行程序，使用 Rust 语言实现，可以替代 ls 命令。笔者试用了一下，体验不错。 命令行程序长什么样一般而言，命令行程序使用形式如下： 1$./program [args] [flags] [options] 可以通过 -h 或 --help 查看更多帮助信息。 动手实践大神 Linus Torvalds 曾言「Talk is cheap, show me the code」。那么，接下来就通过一个简单的示例把 Write a Good CLI Program 中提到的一些技巧实践一遍。 笔者曾经使用 Rust 实现过一个小工具 gic，它可以生成风格一致的 git commit message，还算实用。接下来实现一个简单版本 gitc 仅供参考，全部代码参见 talent-plan-projects/gitc。 首先使用 cargo 创建一个命令行应用： 12$ cargo new gitc$ cd gitc 应用目录结构如下： 12345678.├── Cargo.lock├── Cargo.toml├── src│ ├── cli.yml│ └── main.rs└── target └── debug 定义命令行配置文件1234567891011121314&lt;--cli.yml--&gt;name: gitcversion: &quot;0.1.0&quot;author: 0xE8551CCB &lt;noti@ifaceless.space&gt;about: Generate elegant and uniform commit messageargs: - message: required: true index: 1 takes_value: true help: Use the given &lt;message&gt; as the commit message - use-emoji-code-only: long: use-emoji-code-only help: Use emoji code instead of emoji 注册 emoji 列表为了方便扩展，将 emoji 相关信息放置在全局的列表中，扩展只需要新增列表项即可。这里使用 layzy_static 宏，他可以定义需要在运行时初始化的静态变量，用法类似在其它语言中定义全局变量。 12345678910111213141516171819use lazy_static::lazy_static;lazy_static! &#123; // 这里注册 git emoji 列表 static ref GITMOJI_LIST: Vec&lt;HashMap&lt;&amp;'static str, &amp;'static str&gt;&gt; = vec![ hashmap! &#123; "name" =&gt; "feat", "emoji" =&gt; "✨", "code" =&gt; ":feat:", "description" =&gt; "✨ Introduce new features" &#125;, hashmap! &#123; "name" =&gt; "fix", "emoji" =&gt; "🐛", "code" =&gt; ":fix:", "description" =&gt; "🐛 Fix bugs" &#125; ];&#125; 构建命令行 Appclap 是一个功能丰富、工作高效的 Rust 命令行解析器，借助它可以非常轻松地创建命令行应用。gitc 在创建时，一部分命令行配置来自静态的 YAML 文件，另一部分则是基于上述可扩展的 emoji 列表配置。 123456789101112fn make_cli_app&lt;'a, 'b&gt;(yml: &amp;'a Yaml) -&gt; App&lt;'a, 'b&gt; &#123; let mut app = App::from_yaml(yml); // 将 gitmoji 相关命令注册进来 for item in GITMOJI_LIST.iter() &#123; app = app.arg( Arg::with_name(item.get("name").unwrap()) .help(item.get("description").unwrap()) .long(item.get("name").unwrap()), ); &#125; app&#125; 理解命令行参数并生成执行配置为了便于理解，下面抽象了一个 CommitConfig 结构体，用于将 git commit 有关的特殊配置通过命令行参数解析到这里。具体定义如下： 123456789101112131415161718192021222324252627#[derive(Debug)]struct CommitConfig &#123; message: String, use_emoji_code_only: bool, gitmoji: Option&lt;Gitmoji&gt;,&#125;impl CommitConfig &#123; fn from_cli_arg_matches(m: &amp;ArgMatches) -&gt; Self &#123; let message = m.value_of("message").unwrap(); let use_emoji_code_only = m.is_present("use-emoji-code-only"); CommitConfig &#123; message: message.to_string(), use_emoji_code_only: use_emoji_code_only, gitmoji: Self::match_gitmoji(m), &#125; &#125; fn match_gitmoji(m: &amp;ArgMatches) -&gt; Option&lt;Gitmoji&gt; &#123; for x in GITMOJI_LIST.iter() &#123; if m.is_present(x.get("name").unwrap()) &#123; return Some(Gitmoji::from_gitmoji_config(x)); &#125; &#125; None &#125;&#125; 执行 git commit 命令由于需要通过 Shell 执行 git commit 命令，这里需要使用 std::process::Command 协助完成。核心代码如下： 1234567891011121314fn do_git_commit(c: &amp;CommitConfig) -&gt; Result&lt;(), std::io::Error&gt; &#123; let mut msg = c.message.to_string(); // 构建 commit 消息...（省略消息构建代码） let mut cmd = Command::new("git"); cmd.arg("commit").arg("-m").arg(msg); // 执行命令，拿到输出结果 let output = cmd.output()?; println!("&#123;&#125;", String::from_utf8_lossy(&amp;output.stdout)); if !output.status.success() &#123; eprintln!("&#123;&#125;", String::from_utf8_lossy(&amp;output.stderr)); &#125; Ok(())&#125; 编写 main 函数好啦，现在可以将上述过程串联起来，完成我们的 gitc 命令行工具： 123456789101112fn main() &#123; let yml = load_yaml!("cli.yml"); let matches = make_cli_app(yml).get_matches(); let commit_config = CommitConfig::from_cli_arg_matches(&amp;matches); match do_git_commit(&amp;commit_config) &#123; Ok(_) =&gt; (), Err(e) =&gt; &#123; eprintln!("Error: &#123;&#125;", e); process::exit(1); &#125; &#125;&#125; 完成后，使用 cargo build 可以生成可执行文件，运行效果如下： 小结本节预备知识主要学习了与 Cargo 有关的环境变量作用、Cargo.toml 中的元信息构成以及编写规范的 API 文档的方法，最后通过编写 talent-plan-projects/gitc 掌握了如何编写一个简单的命令行程序以及一些最佳实践。 参考 PNA Rust — Building Blocks 1]]></content>
      <categories>
        <category>Rust</category>
      </categories>
      <tags>
        <tag>Rust</tag>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Talent Plan 之 Rust 网络编程实践入门]]></title>
    <url>%2F2020%2F04%2F15%2Ftalent-plan-rust-network-programming-intro%2F</url>
    <content type="text"><![CDATA[引言本节将开始「Talent Plan 之 Rust 网络编程实践」系列课程学习啦，该系列课程的最终目标是使用 Rust 语言编写一个高性能的单机日志类型（log-structured） key/value 存储服务，分为客户端和服务端两个部分，并使用自定义的协议进行通信，能够使用命令行进行操作。 需要注意的是，该系列课程并非面向初级编程爱好者。参与该系列课程学习和实践前，最好已经有过其它语言编程经验，并且对 Rust 语言有基本了解，写过一些 Rust 代码。笔者强烈建议阅读 The Rust Book 或者《Rust 编程之道》这样的书籍来打好基础。Rust 中引入的所有权、生命周期等概念需要转变思维来理解它，这样才能更好地领悟到这门语言的精髓。 大纲以下是 Rust 网络编程实践课程大纲，总共分为六个部分（最后一个部分还没完成），循序渐进地引导我们阅读一些博客，掌握最佳编程实践，通过不断实践来加深对这门语言的理解。 学习姿势GitHub talent-plan 仓库中存放了课程中安排的编程项目，位于 /rust/projects 目录下。这里的每一个项目都是基于前一个项目进行改造的，在每个项目中都会增量应用一些新的 Rust 知识，比如学习引入第三方 crates，使用标准网络库，使用多线程编程改进服务性能等。 在进行每个项目实践之前，会有一个针对性的 Building Block，可以看成是一些预备知识。在预备知识中，会针对和接下来要实践的项目有关的话题，提供一些阅读材料和练习题，在阅读完成后可以通过练习题巩固下学习到的知识，这样在进行项目实践时会更加得心应手，提升效率。 开发环境准备我们可以通过 rustup 管理 Rust 版本及相关的工具链。如果还没有安装 Rust 编译器，可以通过下面的命令行完成（Linux 或者 macOS 环境）： 1$ curl https://sh.rustup.rs -sSf | sh rustup 工具会为我们安装最新稳定版本的 Rust 编译器。之后也可以通过 rustup update 进行版本更新，或者使用 rustup self uninstall 完成 Rust 编译器和 rustup 卸载。详细操作不再赘述，可参见 Rust Getting Started。 下面笔者将要安利两款神器级插件，便于提升 Rust 编程体验。早期的 Rust IDE 支持比较差，明显没有其它语言在 IDE 中体验舒服（笔者曾经在 Clion 中尝试 Rust 插件，但是效果欠佳）。不过社区一直都在努力改进这一点，下面介绍下笔者的开发环境，仅供参考。 Rust 版本：1.42 代码编辑器：Visual Studio Code 插件： rust-analyzer：这个是用来替代 RLS（Rust Language Server）的实验产品，目标是提供更加优秀的 IDE 功能支持。目前虽然处于 alpha 阶段，不过相对已有的其它插件，已经非常实用了。支持代码自动补齐、文档提示、函数实现跳转、main 函数识别、单元测试识别等。推荐使用~ TabNine：这是一款智能代码自动补全工具，采用深度学习技术加速代码编写，支持主流编程语言。值得一提的是，TabNine 服务本身是使用 Rust 编写，所以它的很多付费功能都是对 Rust 语言开放的，所以尽管使用吧。 关于调试掌握调试技能，对于排查程序问题非常有帮助。那么如何在 Visual Studio Code 中调试我们的 Rust 项目呢？下面将以一个简单的例子来演示下如何进行调试。 首先，在工程目录下新建一个示例项目 cargo new miao，然后输入如下代码，并执行 cargo build，生成的可执行文件位于 target/debug 目录下。 1234567891011121314151617181920212223242526fn main() &#123; assert_eq!(binary_search(vec![1, 2, 3, 4, 5, 8], 10), -1); assert_eq!(binary_search(vec![1, 2, 3, 4, 5, 8], 1), 0);&#125;fn binary_search(nums: Vec&lt;i32&gt;, target: i32) -&gt; i32 &#123; if nums.len() == 0 &#123; return -1; &#125; let mut left = 0; let mut right = nums.len() - 1; while left &lt; right &#123; let mid = left + (right - left) / 2; if nums[mid] == target &#123; return mid as i32; &#125; else if nums[mid] &lt; target &#123; left = mid + 1; &#125; else &#123; right = mid - 1; &#125; &#125; -1&#125; 接下来，点击 vscode 左侧工具栏中的「调试」按钮，并且点击「create a launch.json file」按钮，创建启动配置文件。在弹出的候选框中选择「C++ (GDB/LLDB)」。 紧接着，编辑生成的 .vscode/launch.json 文件，修改其中的程序启动配置，即 configurations.program 指向可执行文件 ${workspaceFolder}/target/debug/miao。 接下来，在代码中添加断点，然后执行 cargo build（默认会以 debug 模式构建），最后启动调试即可。 当然，也可以使用命令行工具 rust-lldb 执行调试，感兴趣的话，可以前往 Rust LLDB 调试入门指北 了解更多细节。 小结本节对「Talent Plan 之 Rust 网络编程实践」系列课程进行了简单介绍，了解课程的具体安排，并在最后给出了 Rust 开发环境搭建的一些参考。 参考 Practical Networked Applications in Rust]]></content>
      <categories>
        <category>Rust</category>
      </categories>
      <tags>
        <tag>Rust</tag>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PingCAP Talent Plan 课程介绍]]></title>
    <url>%2F2020%2F04%2F13%2Ftalent-plan-summary%2F</url>
    <content type="text"><![CDATA[引言随着移动互联网、物联网、云计算以及未来 5G 技术场景的应用拓展，相关应用的数据规模也在不断增长，面临的存储压力越发明显。在此背景下，传统的单机 MySQL 数据库已经无法轻松应付，即便以分库分表的方式应对，也依然存在扩展性较差、可伸缩能力不足、自动化运维能力不足等问题。伴随着 Google 内部的分布式数据库 Spanner 和 F1 的设计思想开放，PingCAP 公司在 2015 年受到相应的启发后开发了 TiDB 数据库，历经将近五年的迭代，目前它已经成为开源社区非常知名的 NewSQL 数据库代表了，并且已经在诸多知名企业中得到了部署和应用。 在正式引入 PingCAP Talent Plan 系列课程介绍前，有必要对 TiDB 有所了解。以下将要介绍的内容包括： TiDB 是什么？ TiDB 的核心组件有哪些？ 为什么会诞生 Talent Plan 课程？ Talent Plan 课程内容是什么？ 初识 TiDB从官网上得知，TiDB 是一款真正意义上的分布式关系型数据库，并且高度兼容 MySQL 协议，这也为我们迁移广泛基于 MySQL 的应用奠定了基础。下面来看看它主要有哪些特性呢？ 支持 OLTP + OLAP 的混合场景，是一款 HTAP（Hybrid Transactional/Analytical Processing） 融合型数据库产品； 支持分布式事务（乐观事务+悲观事务模型均支持）； 高可用，具备故障自动恢复能力； 易于伸缩，TiDB 和 TiKV 均可水平扩展，支持海量数据存储； TiDB 4.0 全面拥抱云原生，提供了非常多的部署方式，同时为了方便本地部署测试，tiup 工具的诞生，也为像笔者这样的小白用户铺平了道路。 核心组件 TiDB in Action 中对于 TiDB 的整体架构有详细的描述。概括来说，TiDB 的整体架构清晰易懂，包括三个核心组件： TiDB：此为 SQL 层，即无状态计算层。负责 SQL 解析、优化，并生成分布式执行计划。实际的数据请求会发送给底层的存储引擎 TiKV。具体可以阅读 谈计算 了解更多细节。 TiKV：此为存储引擎层，本身是一个支持分布式事务的 KV 数据库。TiFlash 是列式存储引擎，主要是针对分析型场景查询而设计。 具体可以阅读 说存储 和 TiFlash 架构原理 了解更多细节。 PD：全称为 Placement Driver，它负责整个 TiDB 集群的元信息管理、存储节点访问自动负载均衡调度、分布式事务 ID 分配等，可以看成整个集群的大脑。可以阅读 讲调度 了解更多细节。 更多学习资源TiDB 的社区资源相当丰富，在 PingCAP 官网中可以看到很多学习资源，笔者简单整理了下，传送门如下： 快速入门； 最佳实践； 周边工具； DM 源码解读； TiDB Binglog 源码解读； TiDB 源码解读； TiKV 源码解读； PingCAP University； 深入 TiKV。 跃跃欲试如果对于分布式系统，尤其是分布式存储系统感兴趣的话，那么跟着 PingCAP 推出的系列课程学习并参与到开源项目中，一定会有很多收获。不过面对如此庞大的系统，想要深入了解其原理并能够读懂源码还是有些门槛的。好在有很多官方的源码解读博客可以学习~ 不过在实际学习中还是遇到一些困难，比如编程语言（Go 和 Rust）实践不足，分布式系统理论和实践结合存在鸿沟等。所以，PingCAP 官方推出了 Talent Plan 课程，分为 TiDB 方向和 TiKV 方向。由于笔者对于 Rust 语言的了解仅仅浮于表面，实践不多，刚好 Talent Plan 提供了这样的机会，可以从 0 到 1 设计并实现一个分布式存储系统。在完成这个系列课程学习后，也能让我们更好地理解 TiDB 和 TiKV，并且在尝试阅读它们的源码时，也不至于一头雾水啦~ 在 GitHub talent-plan 仓库中可以看到关于这个系列课程的介绍。为了便于快速了解课程大纲，画了一个思维导图如下（笔者主要关注的是 Rust 部分）： 上车，走吧接下来，笔者将按照 Talent Plan 安排的课程循序渐进地学习，并在学习中做一些笔记，以便随时复习，欢迎围观交流~ 参考 PingCAP 官网 TiDB in Action 我们是如何设计 Rust &amp; 分布式存储教程的？ | Talent Plan 背后的故事]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>Go</tag>
        <tag>Rust</tag>
        <tag>PingCAP</tag>
        <tag>分布式系统</tag>
        <tag>存储系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go RESTful API 项目模板介绍]]></title>
    <url>%2F2020%2F04%2F02%2Fgo-rest-api-for-beginners%2F</url>
    <content type="text"><![CDATA[0x00 引言疫情期间学的东西比较杂（比如学习了如何在市场行情不好的时候还盲目加仓 🙂），没什么干货值得分享。不过考虑到很久都没有更新了，还是要强迫自己写一点东西，不然容易变懒。总之，多思考，多实践还是很重要。 今天主要是想把三个月前就放到 GitHub 上的 go-rest-api-starter 项目介绍下，目的有两个： 分享下我们目前的工程实践； 给 portal 增加点曝光度 😊。虽然笔者在 Go 语言中如何以优雅的姿势实现对象序列化 做过介绍，不过一直没有给过我们在真实环境中的具体用法，今天提供的示例也刚好可以帮助感兴趣的同学了解下它的用法。 0x01 为什么？好的工程规范是在项目实践中不断踩坑总结出来的，期间我们也遇到各种写起来不够优雅的地方，自然就需要想办法解决这些问题。经过若干项目的实践，结合遇到的问题，也造了些轮子便于提升开发幸福度。沉淀和提炼的结果，便是一套可以沿袭的项目脚手架，集成了一些我们认为的「最佳实践」。 笔者相信不同的团队有不同的想法，但本质上都是更好的服务于业务。我们希望能够以一致、清晰的方式来编写代码，并且保证项目结构不被随意破坏，项目的可维护性大于一切。另外，对于业务框架，也不应该一味地排斥。合理地使用业务框架，既有利于简化业务代码编写，又有利于理解和维护。 0x02 是什么？go-rest-api-starter 是一个完整的 RESTful API 项目（商品管理后台+前台接口，源自 aizoo 管理后台），演示了我们目前的工程实践是什么样的。当然，团队内部版本使用了一些非开源框架，不过同样的理念换成别的框架依然可行。所以，在该项目中，笔者将一些内部框架换成了开源框架，方便大家参考。 从这个项目中可以了解到什么？ 整体的项目结构，分层情况； Model 层怎么编写，关联资源如何以属性方式暴露； Schema 层怎么编写，表单校验逻辑放在什么位置； 复杂业务逻辑如何在 Controller 层实现； 如何保证 Handler 层整洁清晰； portal 所扮演的角色，如何简化字段格式化逻辑。 首先来看下项目结构： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263├── .env（环境变量配置，资源连接串等）├── .env_unittest（跑单元测试使用的测试资源配置）├── LICENSE├── Makefile├── README.md├── bin│ ├── starter-admin（面向管理后台的 RESTful API 服务器）│ └── starter-web（面向客户端、PC 等前台的 RESTful API 服务器）├── cmd（各个服务启动的入口）│ ├── admin（管理后台）│ │ └── main.go│ ├── bee（离线异步任务）│ │ └── main.go│ ├── service（RPC 服务）│ │ └── main.go│ └── web（客户端、PC、小程序等前台）│ └── main.go├── go.mod（依赖包 go modules）├── pkg│ ├── admin（管理后台服务）│ │ ├── handler│ │ ├── router.go│ │ ├── schema（和返回的 JSON 数据关联的资源结构体定义）│ │ └── validator（通用的校验代码）│ ├── config（资源配置）│ │ ├── fixture.go│ │ ├── init.go│ │ └── mysql.go│ ├── constant（常量、枚举定义）│ │ ├── enum.go│ │ ├── gen_enum.go│ │ └── macro.go│ ├── controller（复杂业务逻辑）│ │ ├── company.go│ │ ├── company_test.go│ │ └── product.go│ ├── job（异步离线任务业务逻辑）│ │ └── after_product_created.go│ ├── middleware（可复用的中间件）│ │ └── cors.go│ ├── model（Models，可能还会聚合来自 RPC 等数据源，数据模型抽象）│ │ ├── company.go│ │ ├── doc.go│ │ ├── init.go│ │ └── product.go│ ├── util（工具集）│ │ ├── orderby.go│ │ ├── pic│ │ ├── rest│ │ ├── seqgen│ │ └── toolkit│ └── web（前台服务）│ ├── handler│ ├── router.go│ └── schema├── script（一些脚本文件）│ └── 20200101└── testdata（单元测试有关测试数据、表结构定义） ├── fixtures │ ├── company.yml │ ├── doc.yml │ └── product.yml └── schema.sql 0x03 说 Handler我们希望 Handler 层的逻辑不要太过复杂，曾经在看某后台项目时，某 Handler 足足近百行代码，糅杂了大量的字段校验逻辑、业务逻辑、数据格式化逻辑等，极度啰嗦，难以修改和维护，这个是我们不太想要的。 理想情况下，Handler 层应该保证足够轻量，它就应该像是胶水，负责将 Model 层、Controller 层以及 Schema 层粘在一起。我们来看看下面的示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344func GetProducts(c *rest.Context) (rest.Response, error) &#123; // 1. 复杂逻辑下沉到 Controller 层实现 products, total, err := controller.GetProducts( c.Query("title"), c.QueryWithFallback("order_by", "-created_at"), c.Offset(), c.Limit(), ) // 2. Model -&gt; Schema 渲染 var schemas []schema.OutputProductSchema // 借助 portal.Only，可以在请求的时候指定只吐出需要的字段值 err = portal.Dump(&amp;schemas, products, portal.Only(strings.Split(c.QueryWithFallback("only", ""), ",")...)) if err != nil &#123; return nil, err &#125; // 3. 返回结果 return rest.NewPage(c, schemas, total), nil&#125;func CreateProduct(c *rest.Context) (rest.Response, error) &#123; // 1. 表单校验和处理 var input schema.InputProductSchema err := c.BindJSON(&amp;input) if err != nil &#123; return nil, err &#125; var product model.ProductModel err = portal.Dump(&amp;product, input) if err != nil &#123; return nil, err &#125; // 2. 业务逻辑处理 prodID, err := controller.CreateProduct(&amp;product, &amp;input) if err != nil &#123; return nil, err &#125; // 3. 返回处理结果 return gin.H&#123;"success": true, "product_id": cast.ToString(prodID)&#125;, nil&#125; 总结来看，Handler 层无非执行如下几个步骤（Keep It Simple, Stupid）： 输入参数校验和处理（实际逻辑要么封装在 Schema 层，要么在框架层解决）； 业务逻辑处理（Controller 层负责）； 结果返回。 0x04 讲 Schema 与 Model这两个适合放在一起讲，因为 Schema 的字段映射的正是对应的 Model 中相关字段。也许这里会有疑惑，为什么我们不直接在 Model 层，给某个 Field 加个 Tag json: field_name，直接序列化返回出去呢？为何非要生硬地写一个 Schema 结构体再做映射呢？ 接下来将结合具体的场景来回答这个问题： API 要求返回的字段类型和 Model 中实际类型不一致（如 model.ID 为 int 类型，但 API 要求返回 string 类型）； 某些字段要求是可选返回字段（这时可以轻松地修改 Schema 中的字段为 *type 即可）。 总之，Model 层作为 Source of Truth，保持最原始的格式最好。Schema 层则根据具体的业务场景进行变动，对于不适配的场景，自定义 format 方法完成转换即可。这样可以将改动只聚焦在较小的范围，避免到处修改类型，想想也心累。 最后要提的一点是 Model 的关联资源，我们推荐的写法如下： 1234567891011121314151617181920212223type ProductModel struct &#123; ID int64 CompanyID int64 // ... other fields ignored&#125;// Company 返回商品关联的公司（来源于别的表）func (pd *ProductModel) Company() (*CompanyModel, error) &#123; var company CompanyModel err := DB.Where("id = ?", pd.CompanyID).Find(&amp;company).Error if err != nil &#123; if gorm.IsRecordNotFoundError(err) &#123; return nil, nil &#125; return nil, errors.WithStack(err) &#125; return &amp;company, nil&#125;// Rate 返回商品关联的评分（来源于 RPC 调用）func (pd *ProductModel) Rate() (float64, error) &#123; return rpc.GetProductRate(pd.ID)&#125; 这样在 Schema 层，我们只需要声明需要映射的字段，在经过 portal.Dump 时，框架会自动完成相关字段映射，并将返回的值填充到对应的 Schema 字段中： 12345678910111213141516type OutputCompanySchema struct &#123; ID string `json:"id"` // ...&#125;type OutputProductSchema struct &#123; ID *string `json:"id,omitempty"` // ... Company *OutputCompanySchema `json:"company,omitempty" portal:"nested;async"` CreatedAt *field.Timestamp `json:"created_at,omitempty"`&#125;var output OutputProductSchemaportal.Dump(&amp;output, product)// 此时将 output json 序列化，就是想要得到的结果 0x05 碎碎念最近几天在尝试重构某个项目的某个巨长的函数（接近 250 行，代码就不贴了，怕被打 😝），每次修改它的时候心态都要崩。但说起来，它也没有多么复杂的业务逻辑，只是产品线类型较多，糅杂了资源获取逻辑、字段格式化逻辑等等。严格来说，完全可以使用上述的 Model &amp; Schema 分层思路进行重构，但是该函数做了些优化： 使用 batch_get_resource 接口替代 get_resource 接口； 并发获取多个产品线的章节信息等。 因为这种优化的引入，会导致上述写法上存在一些不太优雅的地方。接下来举个栗子🌰能够更好地说明现在遇到的问题： 先看看常规的 StudentModel &amp; StudentSchema 定义： 123456789101112131415type StudentModel struct &#123; MemberID int64&#125;// Member 返回关联的账号详情func (s *StudentModel) Member(ctx context.Member) *rpc.Member &#123; // 注意，这里使用的是单次调用，而非批量调用 return rpc.GetMemberByID(s.MemberID)&#125;type MemberSchema struct &#123; /*...*/ &#125;type StudentSchema struct &#123; Member *MemberSchema `portal: nested`&#125; 假设一页需要获取 20 个学生信息，portal 序列化时，会默认启动 20 个 goroutine 分别处理 20 个 StudentSchema 的渲染。这样的话，具体到 StudentModel.Member 获取时，就会产生 20 个并发的 GetMemberByID 请求，相对串行执行，这种方式自然可以提高速度。但是代价也很明显，产生的请求较多。对于一些后台项目这样做还好，但是对于 C 端接口，如果请求量较高，那请求放大会比较严重。 1234students := DBGetStudents(20)var output []StudentSchemaportal.Dump(&amp;output, students) 假设上游为我们提供了类似 func BatchGetMemberByID(memberIDs []int64) map[int64]*Member 方法，那么们可以通过批量调用的方式解决上面提到的问题。不过，此时我们需要同时修改原有的 Model 层和 Schema 层如下： 12345678910111213type StudentModel struct &#123; MemberID int64&#125;type StudentSchema struct &#123; Member *MemberSchema `portal: nested`&#125;func (s *StudentSchema) GetMember(ctx context.Context, student *StudentModel) *rpc.Member &#123; // 假设外层批量调用结果放在 ctx 中传入 v := ctx.Value("members").(map[int64]*rpc.Member) return v[student.MemberID]&#125; 然后在 Handler 层，我们需要手动调用 BatchGetMemberByID 接口： 1234567891011121314students := DBGetStudents(20)// 收集 member_idsmemberIDs := make([]int64, len(students))for i, s := range students &#123; memberIDs[i] = s.MemberID&#125;// 批量调用一次members := rpc.BatchGetMemberByID(memberIDs)ctx = context.WithValue("members", members)var output []StudentSchemaportal.DumpWithContext(ctx, &amp;output, students) 嗯，似乎看起来并没有多么繁琐嘛。不过这样的写法很容易导致 Handler 层膨胀，试想再加点别的关联资源获取呢？那各种 BatchGetShit 就怼进去了。 所以，我们究竟怎么才能做到原有的 Model 层依然保持简单的 rpc.GetResourceByID 这种简单的调用方式；Schema 层也不用做侵入式修改；Handler 层更不用忍受可能导致的代码膨胀问题呢？也许我们可以对 rpc.GetResourceByID 做点包装，在底层框架上，自动支持请求合并；而对于上层调用方无感知。 熟悉 HTTP/2 的同学应该了解到其中一个特色是多路复用，避免每次新的请求都要进行 TCP+TLS 握手。那么如果我们能够做到在底层将上层的 rpc.GetResourceByID 自动合并为 rpc.BatchGetResourceByID，也能很大程度上提高请求效率，减少上游服务的请求压力。虽然相对于并发 20 个 rpc.GetResourceByID 请求，自动合并技术可能因为优化不到位或者策略上的问题，响应时间可能稍长，但是相对于串行调用，速度理论上会有很大提升。 关于这个请求合并的策略如何实现呢？可以想象下 rpc.BatchGetResourceByID 就像一辆往返于两地的公共汽车，假设它有两个关键属性： 车上乘客一旦坐满立刻出发（不许加塞，咱们要合法经营）； 到达一定超时时间立刻出发（守时很重要，保证服务质量）； 到达目的地后，还要在返程时将同一批乘客尽可能全部带回来（假设乘客们要么买到了想要的礼物 result 或者像笔者一样比较穷就什么也没买 error）。 基于这样的假设，尝试使用 Go 语言实现了一个简单的 Demo，感兴趣的同学可以前往仓库 rpcx 查看。尝试引入了一个 Proxy 层，由 Proxy 层收集业务方的调用参数，并批量发起调用，最后将结果分派给业务方。当然，目前 Proxy 是以一个单独的 goroutine 部署；理想情况下，如果能用 sidecar 方式部署，甚至可以做到语言无关，独立升级，其它语言实现的服务也可以享受到同样的优化。 12345678910111213141516171819func main() &#123; ctx := context.Background() rsdk.Init(10, 1*time.Millisecond) getMembersAutoAgg(ctx, 20)&#125;func getMembersAutoAgg(ctx context.Context, max int) &#123; var wg sync.WaitGroup for i := 0; i &lt;= max; i++ &#123; wg.Add(1) // 底层自动将并发单次调用转换成批量调用 go func(n int) &#123; r, err := rsdk.GetMember(ctx, int64(n)+1) _, _ = r, err wg.Done() &#125;(i) &#125; wg.Wait()&#125; 当然，想要在生产环境搞事情，还有很长的路要走。比如 Proxy 监控怎么做？单点问题怎么解解决？是否会成为接口调用瓶颈？如何与公司现有的 RPC 框架结合？收益是否真的达到预期（分析具体场景）？ 0x06 总结以上分享了一些关于工程实践方面的思考，欢迎指正，有什么好的想法也欢迎留言交流~]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>Go</tag>
        <tag>RESTful</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rust async-std 入门]]></title>
    <url>%2F2020%2F01%2F20%2Frust-async-std-intro%2F</url>
    <content type="text"><![CDATA[引言最近打算基于 Rust async-std 造轮子，自然是要熟悉下这个库。以下内容是根据 Rust async-std 官方文档翻译整理，当然也加入了部分自己的理解，有不到位的地方还请指点。 async-std 旨在简化异步编程，由于是模拟 Rust 标准库接口，所以熟悉标准库的话，使用起来也会非常舒服。目前 async-std 给我们提供了很多接口：文件系统、网络、计时器等等；它还提供了一个 task 模型，有点类似 Rust 标准库中的 thread 模块。此外，还有 async/await 风格的 Mutex 原语。 Rust 中有两种类型的 Future： 源自标准库的 std::future::Future 源自 futures-rs crate 的 futures::future::Future 背景是这样的，futures-rs crate 中定义的 future 是 Future 类型最初的实现。Rust 为了支持 async/await 语法，就把核心的 trait Future 转移到了标准库中，也就是现在的 std::future::Future。所以，我们可以把 std::future::Future 看作是 futures::future::Future 的最小子集。 我们需要严格区分 std::future::Future 和 futures::future::Future，以及 async-std 是如何使用它们的。总的来说，普通的用户一般是不会和 std::future::Future 打交道的（除了使用 .await 调用）。通常只有实现 Future 的开发者才会关注 std::future::Future 的内部工作机制。过去很多在 Future 中定义的功能都被移动到了 FuturesExt 扩展 trait 中。所以，可以将 futures 库当作是核心 Rust 异步功能的扩展。 那么，上面一直提到的 Futures 究竟是何方神圣？又是怎么被执行的呢？简单来说，Futures 就是对于代码是如何运行的一种抽象，它们其实什么也不做。那么怎么推进执行并获得结果呢？答案是依靠执行器 executor，它会决定何时及如何执行你的 Futures。async-std::task 模块就为我们提供了这样的执行器接口。 FuturesRust 有个非常亮眼的特性叫「无谓并发」，也就是说我们在编写多线程应用时，可以在获得并发特性的同时，不用担心数据竞争的问题（编译器会在编译时就能检查到数据竞争的问题）。 Futures 是对计算的抽象，它们描述了「做什么（what）」，但是与「在哪儿（where）」、「什么时候（when）」执行是分开的。因此，我们的目标是将代码打散成小段的、可组合的行为，这样可以作为系统的一部分执行。接下来我们来看看什么是计算（compute things），并找到可以抽象的地方。 Send 和 SyncRust 安全并发中有两个重要的抽象（Markers）：Send 和 Sync。下面来看看简单的介绍： Send 标记的数据类型是可以安全地从一个计算（computation）转移到（moved）另外一个并发计算（所有权也同样被转移了，发送方将不能再访问它）。 Sync 是指我们可以在并发环境中共享（sharing）数据。 以上没有使用 thread 即线程这样的字眼，而是使用了抽象的 computation。Send 和 Sync 最强大的特点在于它为我们减轻了知道共享什么的负担。在实现时，我们只需要知道对于相应的数据类型采用什么分享方式即可。 关于 Send 和 Sync 的组合还有更多有趣的特性，可以参考 Rust Book 了解更多。 什么是计算（computation）所谓的计算（computation）是指一个可组合的操作序列，可以基于决策分支，可以一直推进运行到结束，最终返回结果或者错误。 延迟计算如上所述，Send 和 Sync 都是描述数据的；但应用程序可不止数据，我们还要知道如何计算出数据，由此引入了 Futures。我们可以看看 Futures 是怎么允许我们用自然语言表达要做的事情的，Futures 从这样的计划： Do X If X succeeded, do Y 变成了： Start doing X Once X succeeds, start doing Y 相比于告诉计算机要做什么，并且根据当前结果决定下一步做什么；延迟计算就是让我们告诉计算机要开始做什么，并响应未来可能发生的事件。 从简单的例子开始下面的例子是从指定的文件中读取内容： 123456fn read_file(path: &amp;str) -&gt; io::Result&lt;String&gt; &#123; let mut file = File::open(path)?; let mut contents = String::new(); file.read_to_string(&amp;mut contents)?; Ok(contents)&#125; 我们可以在任意时刻调用上面的函数，也很直观。问题是，一旦调用上述函数，控制权就会转移至被调用的函数直到其返回。需要说明的是，上述返回值描述的是过去。而过去存在的问题是：所有的决策都已经确定了。但也不是没有优点：返回的结果很明显，我们可以直接将程序过去计算的结果解包（unwrap）出来，然后决定如何使用它。 但我们还是想要抽象计算，并让别人选择如何运行它。所以我们需要一种类型，可以描述计算过程，但是又不执行它。👆 上面的函数只能让我们在调用前或者调用后执行操作。这其实并非预期的，我们希望能够在在运行的时候做点别的事情（实际上就是能够打断执行流）。当在并行编程时，这也剥夺了我们在第一个任务运行时启动另外一个并行任务的能力（这时控制权已经转移给正在执行的函数了）。 此处虽然可以引入线程，但是线程本身是非常特定的并发原语，而我们需要寻找的是一种抽象。具体来说，这样的抽象就是用来表示一个进行中的工作，会在未来产生结果。下面看看非完整定义的 Future trait： 12345678trait Future &#123; // Ouput 是一个泛型，表示输出结果的泛型 type Output; // poll 方法会返回当前计算的状态，poll 方法会返回两种结果： // 1. `Poll::Ready`，表示计算结束 // 2. `Poll::Pending`，表示计算尚未结束 fn poll(self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context) -&gt; Poll&lt;Self::Output&gt;;&#125; 如此，我们可以通过 poll() 方法检查 Future 是否完成，如果已经完成，则返回对应的结果。显然，最简单的机制就是在循环中不断轮询；不过我们通常使用成熟的 runtime 来执行。需要注意的是，在 poll() 返回 Poll::Ready 后，继续调用可能会有令人困惑的行为产生，具体可以参见 futures-docs。 Async实际上 Future 在 Rust 中已经存在一段时间了，只是直接构建和描述它们比较麻烦。因此，async 关键词就是我们的救星，下面的例子中演示了 async-std 搭配 async/await 重构上面的函数：123456789// async 标记函数体是一个延迟计算对象，当函数调用时，会产生一个 `Future&lt;Output = io::Result&lt;string&gt;&gt;`，// 该值并非立即返回的结果 `io::Result&lt;String&gt;`，//（准确地说，是产生了实现了 `Future&lt;Output = io::Result&lt;String&gt;&gt;` 的类型）。async fn read_file(path: &amp;str) -&gt; io::Result&lt;String&gt; &#123; let mut file = File::open(path).await?; let mut contents = String::new(); file.read_to_string(&amp;mut contents).await?; Ok(contents)&#125; .await 干了什么顾名思义，.await 表示等待请求行为（requested action）直到完成，然后才会继续后续的执行。准确的来说，.await 是一个标记，表示此处的代码将会等待直到 Future 产生结果。至于 Future 是怎么结束的，我们不用关心。.await 会让运行时掌控这段代码的执行，至于在计算结束时要执行哪些操作都由运行时来操心。当你编写的操作在后台完成时，它会回到标记点，继续后续的操作。所以这种模式也称为 事件驱动编程（evented programming），因为我们在等待某些事件发生（如打开文件），并据此作出响应（比如开始读取内容）。 当有 2 个及以上这样的函数在同时运行时，我们的运行时系统就能够处理当前所有进行的事件了，避免了傻傻地等待。 Tasks我们已经知道什么是 Futures 了，那具体怎么运行它们呢？这就是接下来要介绍的 tasks 模块要做的事情。下面看个简单的例子： 123456789101112131415161718192021222324252627use async_std::&#123;fs::File, io, prelude::*, task&#125;;async fn read_file(path: &amp;str) -&gt; io::Result&lt;String&gt; &#123; let mut file: File = File::open(path).await?; let mut contents = String::new(); file.read_to_string(&amp;mut contents).await?; Ok(contents)&#125;fn main() &#123; // `spawn` 方法接收一个 `Future`，并且在一个任务中执行它。 // 该函数会返回 `JoinHanle`。 let reader_task = task::spawn(async &#123; // 这里是一个异步块，必须要使用异步块才能调用异步函数，同时 // 也会引导编译器将所有相关的指令包含进来。Rust 中所有的块 // 都会返回一个值，而 `async` 块则返回的是类型为 // `Future` 的值 let result = read_file("data.csv").await; match result &#123; Ok(s) =&gt; println!("&#123;&#125;", s), Err(e) =&gt; println!("Error reading &#123;:?&#125;", e) &#125; &#125;); println!("Started task!"); task::block_on(reader_task); println!("Stopped task!");&#125; Rust 的 Futures 有时也叫「冷（cold）」Futures，你需要运行它们的东西。为了运行一个 Future，可能还需要一些额外的记账工具：比如当前 Future 是否在运行中还是已经结束，在内存中的位置和当前的状态。这种记账逻辑就被抽象到了 Task 中。 Task 类似于 Thread，但也有些许不同：它是由应用程序（用户空间）被调度，操作系统内核不会感知；一旦到了某个点需要等待，应用程序自己需要负责唤醒任务。async_std 的任务可以拥有名称和 ID。 当通过 spawn 生成任务后，会一直在后台运行。返回的 JoinHandle 本身是一个 Future，它会在 Task 运行结束后（run to conclusion）也会结束。类似 threads 和 join 函数，我们可以调用对 JoinHandle 调用 block_on 函数，从而阻塞程序（准确来说是调用线程被阻塞）直到其运行结束。 Task 中是如何推进 Future 完成计算的呢？通过简单阅读源码，可以在 src/task/block_on.rs 看到执行的逻辑，当 Task 被调度执行时，对应的 run 函数也会被执行，进而推进 Future 中的计算逻辑直到完成： 12345678910111213141516171819202122232425/// Blocks the current thread on a future's result.fn run&lt;F, T&gt;(future: F) -&gt; Twhere F: Future&lt;Output = T&gt;,&#123; CACHE.with(|cache| &#123; // ... loop &#123; if let Poll::Ready(t) = future.as_mut().poll(cx) &#123; // Save the parker for the next invocation of `block`. cache.set(Some(arc_parker)); return t; &#125; // Yield a few times or park the current thread. if step &lt; 3 &#123; thread::yield_now(); step += 1; &#125; else &#123; arc_parker.park(); step = 0; &#125; &#125; &#125;)&#125; JoinHandle 是如何将任务结果返回的呢？翻阅 src/task/join_handle.rs 源码得知，它其实也是一个实现了 Future trait 的对象，具体逻辑如下： 1234567891011121314pub struct JoinHandle&lt;T&gt;(async_task::JoinHandle&lt;T, Task&gt;);// ...impl&lt;T&gt; Future for JoinHandle&lt;T&gt; &#123; type Output = T; fn poll(mut self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Self::Output&gt; &#123; match Pin::new(&amp;mut self.0).poll(cx) &#123; Poll::Pending =&gt; Poll::Pending, // 如果是 None，表示任务 panic 或者被取消了 Poll::Ready(None) =&gt; panic!("cannot await the result of a panicked task"), // 当任务结束，自然会拿到具体结果 Poll::Ready(Some(val)) =&gt; Poll::Ready(val), &#125; &#125;&#125; 可以看到，async_std 中的 JoinHandle 实际是对 async_task::JoinHandle 的包装，我们可以深入看下具体是怎么从 Task 中取到结果的：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// async-task-1.1.0/src/join_handle.rs/// A handle that awaits the result of a task.////// * `None` 表示任务被取消或者 panic 了/// * `Some(result)` 表示任务结束，返回的结果 `result` 类型为 `R`pub struct JoinHandle&lt;R, T&gt; &#123; /// A raw task pointer. pub(crate) raw_task: NonNull&lt;()&gt;, /// A marker capturing generic types `R` and `T`. pub(crate) _marker: PhantomData&lt;(R, T)&gt;,&#125;impl&lt;R, T&gt; Future for JoinHandle&lt;R, T&gt; &#123; type Output = Option&lt;R&gt;; fn poll(self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Self::Output&gt; &#123; let ptr = self.raw_task.as_ptr(); let header = ptr as *const Header; unsafe &#123; let mut state = (*header).state.load(Ordering::Acquire); loop &#123; // If the task has been closed, notify the awaiter and return `None`. if state &amp; CLOSED != 0 &#123; // ... return Poll::Ready(None); &#125; // If the task is not completed, register the current task. if state &amp; COMPLETED == 0 &#123; // ... &#125; // 任务完成，提取结果 match (*header).state.compare_exchange( state, state | CLOSED, Ordering::AcqRel, Ordering::Acquire, ) &#123; Ok(_) =&gt; &#123; // 从这里把任务结果获取出来（挺 Hack 的），就是下面的 output.read() let output = ((*header).vtable.get_output)(ptr) as *mut R; return Poll::Ready(Some(output.read())); &#125; Err(s) =&gt; state = s, &#125; &#125; &#125; &#125;&#125; async_std 中的 TaskTask 是 async_std 中最核心的抽象之一，和 Rust 中的 thread 类似。Tasks 和运行时虽然也有关联，但它们是分开的。async_std Task 有如下几个特性： 所有任务是单次分配的（in one single allocation）； 所有任务都有一个 backchannel，这样可以通过 JoinHandle 将结果和错误传递到对应的任务（spawning task）； 它们携带用于调试的元信息； 它们支持 任务级别的 local storage。 async_std 任务 API 会处理背后的 runtime 初始化（setup）和清理（teardown）工作，作为用户，我们不需要显式地启动运行时（这个和 Python 3 有丢丢区别）。 阻塞（Blocking）一般我们认为 Tasks 都是并发执行的，可能它们会共享同一个执行线程（在该线程上切换任务执行）。这同时也意味着如果在某个执行线程上调用了阻塞 API（比如 std::thread::sleep 或者标准库的 IO 函数），会导致对应执行线程阻塞，从而导致该执行线程上的所有任务都停止运行了。其它的一些库（如 db drivers）也会有类似的行为。 需要注意的是，阻塞当前线程本身并非坏事情，只是不要和 async_std 并发执行的模型搞混淆即可。总之，不要这样做： 123456fn main() &#123; task::block_on(async &#123; // 标准库 std::fs，会导致阻塞 std::fs::read_to_string("test_file"); &#125;)&#125; 如果需要混合阻塞 API 调用，建议另起一个线程执行这样的阻塞操作。 关于错误和 Panic常规模式下，如果任务可能出错，那么任务的输出 Output 应该是 Result&lt;T, E&gt; 类型。但是在 panic 的时候，具体的表现则取决于有没有合理处理 panic 的地方，如果没有的话，则会退出。 实践中，意味着 block_on 会传递 panic 到阻塞调用的地方：12345678fn main() &#123; task::block_on(async &#123; panic!(&quot;test&quot;); &#125;);&#125;thread &apos;async-task-driver&apos; panicked at &apos;test&apos;, examples/panic.rs:8:9note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace. 而对于 spwan 出去的任务如果 panic，则会导致退出（abort）：1234567891011task::spawn(async &#123; panic!(&quot;test&quot;);&#125;);task::block_on(async &#123; task::sleep(Duration::from_millis(10000)).await;&#125;)thread &apos;async-task-driver&apos; panicked at &apos;test&apos;, examples/panic.rs:8:9note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace.Aborted (core dumped) 上面的行为最初看上去有点奇怪，但另外一种选项是对于 spawn 出去的任务如果发生 panic，则简单忽略掉。当前的行为可以被修改为捕获 spawn 出去的任务中发生的 panic，并且根据不同的情况做出不同的响应，这样我们就可以根据需要采取不同的 panic 处理策略。 更多示例在 这里 有不少示例代码可以参考，下面是一个简单的 UDP 客户端例子：1234567891011121314151617181920use async_std::io;use async_std::net::UdpSocket;use async_std::task;fn main() -&gt; io::Result&lt;()&gt; &#123; task::block_on(async &#123; let socket = UdpSocket::bind("127.0.0.1:8081").await?; println!("Listening on &#123;&#125;", socket.local_addr()?); let msg = "hello world"; println!("&lt;- &#123;&#125;", msg); socket.send_to(msg.as_bytes(), "127.0.0.1:8080").await?; let mut buf = vec![0u8; 1024]; let (n, _) = socket.recv_from(&amp;mut buf).await?; println!("-&gt; &#123;&#125;\n", String::from_utf8_lossy(&amp;buf[..n])); Ok(()) &#125;)&#125; 参考 Async programming in Rust with async-std Asynchronous Programming in Rust]]></content>
      <categories>
        <category>Rust</category>
      </categories>
      <tags>
        <tag>Rust</tag>
        <tag>Async</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初识 Elasticsearch]]></title>
    <url>%2F2020%2F01%2F15%2Felasticsearch-intro%2F</url>
    <content type="text"><![CDATA[引言在很多应用场景下，我们都需要搜索功能，不管是在 App 中还是网站中。搜索每时每刻都在发生，比如搜索喜欢的零食、好看的衣服、喜欢的文章、想要学习的课程等等。如今要为我们的应用添加搜索已经非常容易了，早期我们可以使用 MySQL 的 MyISAM 存储引擎来做全文本搜索支持，不过今天要说的 Elasticsearch 同样可以做到，而且更强大。简单来说，Elasticsearch 是一个分布式搜索和分析引擎，也是众所周知的 ELK Stack 核心成员。它以 JSON 的格式存储文档到索引当中，能够高效地存储多种类型，并提供快速搜索的能力。此外，整个 ELK Stack 生态非常完善。 那么接下来，我们将跟着官方文档学习下 Elasticsearch 具体是什么？适用的场景有哪些？支持什么数据类型存储和检索？ PS: 我们在生产环境中，使用 ES 构建了课程商品（SKU）索引，方便对用户、管理后台提供课程搜索能力。 安装docker-elk 仓库提供了在 Docker 环境下搭建 ELK Stack 服务的配置，我们可以参考其说明文档进行安装（在 macOS Catalina 环境下操作）。 克隆仓库：git clone git@github.com:deviantony/docker-elk.git 第一次需要运行 docker-compose build，等待构建完成 需要在 docker-compose.yml 中修改下 ES 的密码，当然还有 elasticsearch/config，kibana/config, logstash/config 中都有密码需要修改。由于是在本地学习，所以只是简单设置了下密码。生产环境建议参考文档，生成复杂的密码 运行 docker-compose up [-d] 即可启动 关闭 docker-compose down -v 注意事项： 配置文件并非动态加载，每次变更后需要重启对应的组件 端口映射说明： 9200: ES HTTP 9300: ES TCP 5000: Logstash TCP input 5601: Kibana 启动成功后，可以打开 Kibana 开始探索啦~ Elasticsearch 简介Elasticsearch 是一个分布式搜索和分析引擎，ELK 栈的核心组成部分。而 Logstash 和 Beats 用于收集、聚合、转换数据，并将其存储在 Elasticsearch 当中。而 Kibana 则让我们能够便捷探索、查看并分享数据，同时也用来管理 ELK 栈。 ES 提供了实时的搜索和分析能力，支持多种数据类型（结构化、非结构化、数字、地理位置等），ES 会高效地存储并索引这些数据，从而支持快速搜索。由于分布式的特点，随着数据集的增加，可以轻松地进行水平扩展来提高服务可靠性和性能。 ES 支持的使用场景包括： 为我们的 App 或网站提供搜索支持 可以存储分析日志（analyze logs）、指标数据（metrics）、安全事件数据（security event data） 基于机器学习根据数据实时建模 可以用作 GIS 系统（地理信息系统），用于管理、集成并分析空间信息 可以用于生物学研究工具，存储并处理基因数据 文档和索引ES 本质上还是一个分布式文档存储服务（类比 Mongo？），实际在索引中存储的是 JSON 格式的文档。在 ES 集群中，文档会被分布到整个集群存储的，并且能够从任意一个节点立刻访问到。 一旦新的文档存储到索引后，几乎可以立刻被搜索到（1s 以内），因此可以构建近乎实时的搜索引擎。那么 ES 究竟是如何做到的呢？简单来说，它使用了倒排索引（inverted index）这种数据结构来支持全文本搜索。所谓的倒排索引就是对文本进行分词，然后记录每个分词所在的文档 id（当然还有词频等信息），这样在查询时可以基于分词快速定位所在的文档。 在 ES 中，索引是一个很重要的概念（回顾下 MySQL InnoDB 的聚簇索引，表中的记录存储在 B-Tree Node 上，基于 B+ Tree 这种数据结构快速定位记录所在的页），但是这里的索引和在关系数据库中提到的索引有所差别。总结下特点： ES 的索引（index）可以看成文档（document）的集合； 每个文档（document）可以看成字段（field）（类比下字典中的 key-value）的集合； 默认设置下，ES 会为文档中的每个字段建立索引，并且每个字段都会匹配专门优化的数据结构以达到高效存储和快速搜索的目的。比如：文本使用倒排索引，数字和地理位置使用 BKD 树。 ES 支持 schema-less，这样我们就不用为每个字段显式指定索引方式。当我们启用动态映射（dynamic mapping）时（这个是默认设置），ES 会自动检测到新增字段，自动将文档中的 bool 值、浮点数、整数、日期、字符串等映射成合适的 ES 数据类型。 当然，某些情况下，我们可能想要关闭动态映射的功能，这时可以自定义映射规则，从而控制每个字段存储和索引的方式。自定义映射带可以： 区分全文本字符串字段和精确匹配的字符串字段； 执行特定语言的文本分析； 优化部分匹配； 使用自定义日期格式； 使用一些无法自动检测到的数据类型（如 geo_point, geo_shape）。 此外，ES 可以为相同的字段建立不同的索引，以满足不同的需求场景。 搜索与分析ES 提供了非常简单易于使用的 REST API，可以利用它们管理集群、索引和搜索数据。我们既可以在 Kibana 控制台中和 ES 交互，也可以使用各个语言（支持 Java, JavaScript, Go, .Net, PHP, Perl, Python, Ruby 等）的客户端进行交互。 搜索数据目前支持两种查询方式：JSON Query DSL 和 SQL。 ES API 允许我们使用结构化查询、全文本查询或者二者组合： 结构化查询：类似 SQL 那样，我们可以搜索某几个字段，基于某字段排序等； 全文本查询：返回匹配关键词的文档，返回的结果基于相关性排序。 此外，还支持单独分词（individual terms）查询，我们可以执行短语搜索（phrase searches）、相似度搜索（similarity searches）和前缀搜索（prefix searches），甚至可以得到自动补全的建议。当然，对于地理位置或者数字类型的数据，ES 也可以提供高效的查询功能。 分析数据ES 允许我们执行聚合（aggregation）操作，从而对关键的指标、 增长趋势等有更为深刻的认识。ES 高效聚合的能力，可以让我们能够实时地分析和可视化数据。我们可以把搜索和聚合联合在一起使用，这样就可以在搜索、过滤文档的同时，对相同的结果进行分析。 此外，ES 还提供了自动分析时序数据的功能，也就是利用机器学习来发现数据中的异常，不过这块属于高级功能了，有兴趣的话可以自行研究下~ 高可用、可伸缩与可靠性 既然是分布式搜索引擎，高可用和可伸缩的能力自然是 ES 必备技能。我们可以按需给集群增加服务器（节点）实现扩容。ES 会自动将数据和查询负载均衡到可用节点上，以实现伸缩和高可用。 那么，ES 是如何存储和维护索引的呢？简单来说，每个 ES 索引（index）其实是一个到多个物理分片（physical shards） 所组成的逻辑分组（logical group）；每个分片实际是自包含索引（self-contained index）。通过将索引放到多个分片存储，然后将分片分布到多个节点上，ES 可以为分片提供冗余备份，从而达到水平扩展和高可用的目的。随着集群的扩容（或缩容），ES 会自动再均衡，必要时也会合并分片。 关于分片（shards）分片分为两种类型： 主分片（primary shard）：索引中的每个文档都属于某个主分片。 副本分片（replicas）：副本分片其实就是主分片的拷贝，一方面实现数据冗余，另一方面也对外提供读服务（搜索、获取文档等）。 需要注意的是，索引的主分片数在创建后就不能修改了，只能重建靠重建索引来扩展主分片数，但是副本分片数可以随时修改，不会打断索引和查询操作。 那么问题来了，索引的主分片数越多越好吗？显然不是这样的。我们需要考虑索引的数据量大小，尽可能保证每个分片不要太大，分片数量不要过多。 我们先来看看分片数过多会导致的问题吧： 每个分片其实都是一个 Lucene 索引，会占用更多的文件描述符、内存和 CPU 资源； 搜索会被分配到各个分片上，如果分片都位于不同节点还好，要是集中在某个节点，则会出现热点问题，资源竞争激烈，性能也会下降； 过多的分片也会导致过多的分片请求，会产生一定的网络开销等； ES 使用词频来统计匹配的相关性，统计会被分配到各个分片上，如果大量分片上只维护了很少的数据，则会导致最终的文档的相关性较差。 如果每个分片过大，则会导致集群再均衡办时，搬迁数据更耗时。总而言之，我们需要通过测试来确定最佳的配置。起初可以这样： 保证每个分片的大小在 GB 到几十 GB 范围。对于常见的时序数据，分片大小在 20GB ~ 40GB 也很常见。参考文献中给出的大小限制为 30GB。 避免过大的分片问题。每个节点可容纳的分片数量和可用的堆空间成正比，每 GB 堆空间分片数应该小于 20。 灾备考虑性能的因素，通常集群中的节点应该位于相同的网络环境。跨数据中心均衡分片非常耗时，可靠性也会降低。但是高可用架构设计就是要保证我们不要把鸡蛋放在一个篮子里，这样一旦某处的服务器宕机，位于其它位置的服务器可以接替继续提供服务。 ES 为我们提供了 CCR 功能（跨集群复制，Cross-cluster replication），这样可以将主集群的索引同步到远程的集群作为热备，同时也可以基于地理位置使用其它集群提供读请求。所有的写入操作都在主集群完成，其它的副本集群都是只读的 Followers。 架构 实践生产环境创建索引模板： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152PUT /_template/km_server_warehouse_template&#123; "order": 1, "index_patterns": [ "km_server_warehouse*" ], "settings": &#123; "index": &#123; "analysis": &#123; "analyzer": &#123; "znlp-coarse": &#123; "type": "custom", "tokenizer": "znlp-fine" &#125; &#125; &#125;, "number_of_shards": "1", "translog": &#123; "sync_interval": "5s", "durability": "async" &#125;, "number_of_replicas": "4", "similarity": &#123; "scripted_bm25": &#123; "type": "scripted", "script": &#123; "source": "double k1 = 1.2; double b = 0.75; double tfNorm = doc.freq * (k1 + 1) / (doc.freq + k1 * (1 - b + b * doc.length / (1.0 * field.sumTotalTermFreq/field.docCount))); return query.boost * tfNorm;" &#125; &#125; &#125; &#125; &#125;, "mappings": &#123; "contents": &#123; "dynamic": false, "properties": &#123; "content_basic": &#123; "type": "nested", "properties": &#123; "sku_id": &#123; "type": "long" &#125;, "business_id": &#123; "type": "long" &#125;, "business_type": &#123; "type": "keyword" &#125;, "producer": &#123; "type": "keyword" &#125;, "svip_right": &#123; "type": "nested", "properties": &#123; "free": &#123; "type": "boolean" &#125;, "discount": &#123; "type": "short" &#125; &#125; &#125;, "instabook_right": &#123; "type": "nested", "properties": &#123; "free": &#123; "type": "boolean" &#125;, "discount": &#123; "type": "short" &#125; &#125; &#125;, "svip_privileges": &#123; "type": "boolean" &#125;, "title": &#123; "similarity": "scripted_bm25", "analyzer": "znlp-fine", "type": "text" &#125;, "authors": &#123; "type": "keyword" &#125;, "right_list": &#123; "type": "keyword" &#125;, "serial_status": &#123; "type": "short" &#125;, "public_status": &#123; "type": "short" &#125;, "online_time": &#123; "type": "long" &#125;, "categories": &#123; "type": "nested", "properties": &#123; "id": &#123; "type": "long" &#125;, "level": &#123; "type": "short" &#125;, "weight": &#123; "type": "short" &#125;, "name": &#123; "type": "text", "fields": &#123; "keyword": &#123; "ignore_above": 256, "type": "keyword" &#125; &#125; &#125;, "name_en": &#123; "type": "text", "fields": &#123; "keyword": &#123; "ignore_above": 256, "type": "keyword" &#125; &#125; &#125; &#125; &#125;, "is_test": &#123; "type": "boolean" &#125; &#125; &#125;, "content_aggregation": &#123; "type": "nested", "properties": &#123; "interest_count": &#123; "type": "long" &#125; &#125; &#125;, "created_at": &#123; "type": "long" &#125;, "updated_at": &#123; "type": "long" &#125; &#125; &#125; &#125;, "aliases": &#123;&#125;&#125; 参考 ES 介绍 Query DSL Elasticsearch系统概念及架构图 倒排索引 聊聊 ELASTICSEARCH 的集群状态的管理和维护 THE COMPLETE GUIDE TO THE ELK STACK ELK Stack Tutorial – Discover, Analyze And Visualize Your Data Efficiently Lucene BKD树-动态磁盘优化BSP树 聊聊 ES 分片优化]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>ELK</tag>
        <tag>搜索引擎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快递网点抓取杂记]]></title>
    <url>%2F2019%2F12%2F29%2Fcraw-dilivery-network-distribution%2F</url>
    <content type="text"><![CDATA[引言应求开发一个简单的爬虫，用于从快递 100 抓取快递网点的分布，输入省份+城市+区县，然后是快递公司名称，抓取其对应的快递网点的信息（包括名称、地址、电话、坐标等）。说起来，开发这样一个简单的爬虫其实没什么难度，也没什么技术含量（没有时间要求、不需要分布式抓取、没什么反反爬策略加持等），不过这期间也遇到一些比较有趣的问题，特此记录下。 另外就是第一次接触了 pyecharts 这个数据可视化工具，用起来还挺方便的。样式配置好，还是会带来很好的视觉冲击的！当然，关键是利用这种工具有助于增加对抓取数据的理解（看具体需要的分析维度了）。 整个过程还是挺有趣的，虽然定位某些元素的时候很麻烦，写 XPath 表达式也比较枯燥（不要指望浏览器自动生成的 XPath，通常都不够通用）。但是完成整个任务后，还是有些收获的。下面开始吧~ 确定方案尝试 API 直接获取快递 100 对外公开的 API 文档在此，但是并没有开放网点查询的接口，故无法使用。直接通过 API 查询是最省心的方式，但是目前这条路行不通。 尝试分析网页请求，间接使用 API 请求网点查询的主页，可以根据选择的城市和快递公司，页面内容自动切换。此时，还是尝试分析其 API 请求，因为这个通常是抓取网站最简单的方式。 打开 Chrome 浏览器的调试模式，通过点击页面上的筛选项，查看网络请求，确定请求了什么接口，传递的参数是什么，返回的参数是什么，从而能够模拟其请求方式来获取数据。接下来演示的是查询上海地区的某快递公司的网点。 截图 1：请求方式为 POST，URL 为 www.kuaidi100.com/network/searchapi.do 截图 2：以表单的形式，提交了请求的参数，也就是页面点击的筛选项。 截图 3：当完成请求后，可以看到其返回结果为 JSON 结构，其中的 netList 正是想要找的网点数据。 尝试分析网页结构，采用传统的方式抓取一般在进行网站数据抓取时，能通过其 API 获取，就尽可能去利用。使用 API 请求数据的好处有这么几点： 省去了分析网页 HTML 结构的时间，可以直接解析接口返回的数据，提取想要的信息并存储即可； API 请求方式最为简单可靠灵活，且能适应较高的抓取频率； 相对于分析网页 HTML 结构，提取信息的方式，API 抓取通常不用像担心前端页面频繁改版而导致爬虫程序也要即使更新的困境，方便维护。 不过只是通过 API 来抓取，感觉不是很有趣，在 Selenium 的帮助下，以可视化的方式抓取页面貌似更有趣点。这里的思路如下： 安装 Selenium + Chrome Web Driver，通过操纵浏览器模拟人类访问页面的方式来抓取数据； 编写爬虫程序，控制浏览器打开网点查询的首页：https://www.kuaidi100.com/network/ 接收输入的城市和快递公司名称作为参数，然后操纵浏览器点击下拉框，选择城市；然后操纵浏览器点击指定的快递公司； 接下来开始解析页面结构，提取快递网点数据转换为 JSON 格式（地理位置坐标通过百度地图 API 获得），存储在指定路径下；然后不断控制浏览器翻页，完成剩余页面解析，至此对应的网点信息抓取完成。 准备开发环境 Python 3.7 环境； selenium-python，其使用文档参考此处； chromedriver 下载，并解压得到可执行文件； Anaconda 环境安装，并且需要保证 Jupter Notebook 能够正常工作； 依赖的重要 Python 包安装： pyecharts echarts-countries-pypkg echarts-china-provinces-pypkg echarts-china-cities-pypkg echarts-china-counties-pypkg echarts-china-misc-pypkg requests 记得安装 Chrome 浏览器。 页面关键元素定位根据上述抓取思路，需要做的是定位一些关键元素，并且能够从 HTML 中抽取出需要的信息。页面元素定位，需要了解下 XPath 语法，摘取想要的元素。 小技巧，可以在 Chrome 控制台通过 $x(&#39;xpath-expression&#39;) 验证选择器是否正常： 省份选择下拉框元素 id 为 provinceSelect： 定位省份位置（拷贝其 XPATH） 小结其它关键元素确定方式类似，主要以 XPath 的方式查找。得到最终需要的 XPath 表达式如下： 1234567891011121314151617class XPathExpression: # 省份下拉框 Tab PROVINCE_TAB = '//*[@id="provinces"]/div/ul/li[2]' # 具体某个省份 PROVINCE_ITEM = '//*[contains(@class, "place province") and contains(text(), "&#123;&#125;")]' # 具体某个城市 CITY_ITEM = '//*[contains(@class, "place city") and contains(text(), "&#123;&#125;")]' # 具体某个区县 COUNTY_ITEM = '//*[contains(@class, "place county") and contains(text(), "&#123;&#125;")]' # 右侧查询按钮 QUERY_BUTTON = '//*[contains(@class, "btn-query")]' # 快递公司选择 PROVIDER_ITEM = '//ul[@id="companyCount"]/li/*[contains(text(), "&#123;&#125;")]' # 下一页 NEXT_PAGE_BUTTON = '//*[contains(@class, "page-down-active")]' # 页面中的快递公司信息条目 QUERY_ITEMS = '//*[@id="queryResult"]/dl' 写代码main 函数是关键入口，它会调用爬虫类搜索指定位置指定公司的快递网点信息，并将返回的数据存储到指定的路径下，使用 json line 格式（即每一行都是 json 格式字符串）存储。 123456789101112131415def main(province, city, provider='全部'): spider = DeliveryNetworkSpider( driver_path=os.path.join(PROJECT_DIR, 'dep/mac/chromedriver')) try: results = spider.search(province=province, city=city, provider=provider) except Exception as err: print(err) else: for result in results: print(result) store_result(os.path.join(PROJECT_DIR, 'results', f'&#123;province&#125;-&#123;city&#125;-&#123;provider&#125;.jl'), result) finally: spider.close() 核心爬虫类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151class DeliveryNetworkSpider(object): """基于快递 100 的快递网点查询爬虫 """ def __init__(self, driver_path): """ 初始化快递网点爬虫，关键参数是要指定 webdriver 路径，否则 无法控制浏览器进行模拟查询。当前仅支持 Chrome 浏览器。 :param driver_path: 默认是 Mac 版本所在的路径，如果是 win 版本，需要自行修改路径。 """ # Windows 下需要替换成对应的 chromedriver，可以在 dep 目录下新建 win # 目录，将 windows 版本的放到目录下，并修改 mac-&gt;win self._driver = webdriver.Chrome(executable_path=driver_path) self._driver.implicitly_wait(10) # 隐式等待元素出现 def close(self): try: self._driver.close() except: pass def search(self, province, city, county='暂不选择', provider='全部'): """执行网点查询的核心方法。 :param province: 省份（一定要是快递 100 上有的名字） :param city: 城市（一定要是快递 100 上有的名字） :param county: 区县，默认为全部区县 :param provider: 快递服务商名字，不传则查询所有快递公司 """ self._open_home_page() self._select_location(province, city, county) self._select_provider(provider) while True: yield from self._parse_page(province, city) if self._has_next_page(): time.sleep(.5) # 防止翻页太快被抓到 self._visit_next_page() else: break def _open_home_page(self): self._driver.get('https://www.kuaidi100.com/network/') def _select_location(self, province, city, county): # 找到输入下拉框位置 elem = self._driver.find_element_by_id('provinceSelect') self.__highlight(elem) elem.click() # 定位选择省份 Tab elem = self._driver.find_element_by_xpath(XPathExpression.PROVINCE_TAB) self.__highlight(elem) elem.click() # 接下来选择省份 elem = self._driver.find_element_by_xpath( XPathExpression.PROVINCE_ITEM.format(province)) self.__highlight(elem) elem.click() # 紧接着选择城市 elem = self._driver.find_element_by_xpath( XPathExpression.CITY_ITEM.format(city)) self.__highlight(elem) elem.click() # 选择所有区域 elem = self._driver.find_element_by_xpath( XPathExpression.COUNTY_ITEM.format(county)) self.__highlight(elem) elem.click() # 定位到查询按钮，并点击查询跳转页面 elem = self._driver.find_element_by_xpath(XPathExpression.QUERY_BUTTON) self.__highlight(elem) elem.click() def _select_provider(self, provider): elem = self._driver.find_element_by_xpath( XPathExpression.PROVIDER_ITEM.format(provider)) self.__highlight(elem) elem.click() def _has_next_page(self): try: self._driver.find_element_by_xpath(XPathExpression.NEXT_PAGE_BUTTON) except NoSuchElementException: return False else: return True def _visit_next_page(self): elem = self._driver.find_element_by_xpath(XPathExpression.NEXT_PAGE_BUTTON) self.__highlight(elem) elem.click() def __highlight(self, elem): """高亮操作的元素""" self._driver.execute_script( "arguments[0].setAttribute('style',arguments[1]);", elem, "outline:2px solid red;") time.sleep(.2) def _parse_page(self, province, city): try: elements = self._driver.find_elements_by_xpath(XPathExpression.QUERY_ITEMS) except NoSuchElementException: return [] else: for el in elements: yield self._extract(el.text, province, city) @staticmethod def _extract(text, province, city): item = dict( province=province, city=city, name='', # 名称 address='', # 地址 contact_phone='', # 联系电话 pickup_phone='', # 取件电话 check_phone='', # 查件电话 complaint_phone='', # 投诉电话 location=dict( lng=0.0, # 经度 lat=0.0, # 纬度 ) ) if not text: return item # 提取出纯文本后换行解析 lines = [l.strip() for l in text.splitlines() if l.strip()] def __(k): r = [l for l in lines if l.startswith(k)] return r[0].replace(k, '') if r else '' item['name'] = lines[0] item['address'] = __('公司地址：') item['contact_phone'] = __('联系电话：') item['pickup_phone'] = __('取件电话：') item['check_phone'] = __('查件电话：') item['complaint_phone'] = __('投诉电话：') item['location'] = get_location( item['address'], city=u"&#123;&#125;&#123;&#125;".format(province, city)) return item 坐标查询123456789101112131415161718192021222324BASE_API = 'http://api.map.baidu.com'LOCATION_API = '/geocoding/v3/?address=&#123;&#125;&amp;city=&#123;&#125;&amp;output=json&amp;ak=&#123;&#125;'# 加缓存，避免重复查询@filecache(YEAR)def get_location(addr, city=''): """ 文档参考：http://lbsyun.baidu.com/index.php?title=webapi/guide/webservice-geocoding """ if not addr: return dict(lng=0.0, lat=0.0) url = _get_query_url(LOCATION_API.format(addr, city, AK)) r = requests.get(url) result = r.json() assert result['status'] == 0, u"获取经纬度信息失败！请求：&#123;&#125;，返回结果：&#123;&#125;".format(url, result) return result['result']['location']def _get_query_url(query_str): query_str = query_str.replace('#', '') # 去除特殊字符 # 对 query_str 进行转码，safe 内的保留字符不转换 qs = quote(query_str, safe="/:=&amp;?#+!$,;'@()*[]") sn = hashlib.md5(quote_plus(qs + SK).encode('utf8')).hexdigest() return BASE_API + query_str + f'&amp;sn=&#123;sn&#125;' 控制抓取数据比如，下面就是抓取中通快递在北京各个地区的网点。启动后，会通过 Selenuium 控制 Chrome 浏览器访问查询网站，并点击对应的元素，完成数据的抓取。 1main(province='北京', city='北京', provider='中通') 整个工作过程演示参见 百度网盘（提取码: kaun）。抓取到的数据示例如下： 绘制简单的热点地图这里就需要使用关键的 pyecharts 了，具体怎么安装和配置就不多说了，它有非常完善的中文文档，以及一些 Demo 可以学习。以下就是利用上述抓到的数据，做个简单的演示，看看这些快递网点的具体分布热点是怎么样的。 我们需要切换到爬虫目录下，并启动 Jupter Notebook： 12cd path/to/kuaidi100/srcjupter notebook # 启动服务 紧接着，选择 src/heatmap.ipynb 文件打开： 菜单栏 Cell-&gt;Run All 执行所有代码，可以看到简单的热点地图如下所示： 总结至此，整个折腾的过程就完结咯。主要时间花费在确定爬重的方案，以及使用灵活的方式定位元素上。在实际测试中，也遇到一些小问题，并做了部分优化： 比如某些情况下元素 click 会失败，这时为了保证爬虫的健壮性，需要做异常捕获；页面加载未完成时，可能无法查找到指定元素，导致爬虫程序挂了，这里就需要配置 Selenium 隐式等待 10s。 为了方便观察 Selenium 正在操纵的元素，这里借助了 driver.execute_script() 的方式给选中的元素添加红色边框。 另外，考虑到爬取频率过快，可能导致触发反爬策略，这里简单做了延迟等待（time.sleep()）。 整体而言，写得比较简单，所以这里也就简单记录下。完整的代码仓库参见：kuaidi100-spider。 参考 pyecharts 地理图标文档 pyecharts 在地图上根据经纬度和量值，画出散点图/热力图 百度地图文档 XPath 语法]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>Python</tag>
        <tag>数据可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解文件描述符与文件句柄]]></title>
    <url>%2F2019%2F12%2F19%2Funderstand-file-descriptor-and-file-description%2F</url>
    <content type="text"><![CDATA[引言在《Linux 系统编程手册》5.4 节，关于文件描述符和打开的文件关系是这样描述的：「内核为所有打开的文件维护了一个系统级的描述表（open file description table），有时也称之为打开文件表（open file table），并将表中的每个条目称为打开文件句柄（open file handle）。而针对每个进程，内核又为其维护了打开文件的描述符表（open file descriptor table）」。 后来在这篇文章 Linux 文件句柄的这些技术内幕，只有 1% 的人知道 中，看到了这样的的描述：「简单来说，每个进程都有一个打开的文件表（fdtable)。表中的每一项是struct file类型，包含了打开文件的一些属性比如偏移量，读写访问模式等，这是真正意义上的文件句柄」。 那么这里提到的「打开的文件表」又是什么呢，怎么又变成了每个进程都有的呢？《Linux 系统编程手册》中不是说「打开文件表（open file table）」是独立于进程的系统级表吗？是不是觉得有点困惑和矛盾呢？ 为了能够解答困惑，加深对文件描述符的理解，特地深扒了下 Linux 内核的相关源码。接下来，我们将会看到上文提到的描述表（open file description table）、打开文件表（open file table）、打开文件句柄（open file handle）这三种抽象的数据结构具体是怎么实现的？以便能够更好地理解书中的概念。 文件描述符与打开的文件关系在区分这些概念前，我们先来看看 open() 系统调用的 man page 中提到的一段说明： A call to open() creates a new open file description, an entry in thesystem-wide table of open files. The open file description recordsthe file offset and the file status flags (see below). A filedescriptor is a reference to an open file description; this referenceis unaffected if pathname is subsequently removed or modified torefer to a different file… 在看完上面的介绍后，结合《Linux 系统编程手册》提到的名词，我们可以作出这样的映射： open file description: 打开的文件句柄（open file handle），它才会关联到真正地文件 inode table of open files: 就是书中提到的系统级描述表（open file table） file descriptor: 其实就是一个针对文件句柄的引用 好啦，下面来看看与文件描述符相关的实现细节，并了解几个重要的系统调用 实现。 实现细节以下代码摘自 Linux Kernel 5.4，考虑到内核代码非常复杂，处理细节也很多，这里并没有把每个函数或数据结构所有代码都贴出来，只保留了一些和本文焦点有关的代码行。 Linux 内核中相关的数据结构每个进程都关联指向了一个 files_struct，即打开的文件信息： 12345678struct task_struct &#123; // ... /* Filesystem information*/ struct fs_struct *fs /* Open file information*/ struct files_struct *files; // ...&#125; 那么，打开的文件信息长什么样呢？ 123456789101112131415161718192021struct files_struct &#123; /* * read mostly part */ // 引用计数，可以和其它 task 共享 atomic_t count; bool resize_in_progress; wait_queue_head_t resize_wait; // fdtable 是每个进程相关的文件描述符表 struct fdtable __rcu *fdt; struct fdtable fdtab; /* * written part on a separate cache line in SMP */ spinlock_t file_lock ____cacheline_aligned_in_smp; unsigned int next_fd; unsigned long close_on_exec_init[1]; unsigned long open_fds_init[1]; unsigned long full_fds_bits_init[1]; struct file __rcu * fd_array[NR_OPEN_DEFAULT];&#125;; 而关于 fdtable （这个可以理解为进程独立的打开文件的描述符表（open file descriptor table））的定义如下： 1234567891011struct fdtable &#123; unsigned int max_fds; // 这里 fd 数组，维护了进程关联的文件描述符及其文件句柄的指针 // 文件句柄可以共享（比如，dup 系统调用） // 但是在使用 open 系统调用的时候会创建新的 file，即文件句柄 struct file __rcu **fd; /* current fd array */ unsigned long *close_on_exec; unsigned long *open_fds; unsigned long *full_fds_bits; struct rcu_head rcu;&#125;; 再来看看文件句柄（即 open file description）是什么？它维护了和打开文件有关的重要信息： 123456789101112131415161718192021222324252627struct file &#123; // ... // 文件路径 struct path f_path; // 指向真正的文件，inode 指针 struct inode *f_inode; /* cached value */ // 文件相关的操作 const struct file_operations *f_op; /* * Protects f_ep_links, f_flags. * Must not be taken from IRQ context. */ spinlock_t f_lock; enum rw_hint f_write_hint; // 引用计数，只有 count 为 0 时，才会被真正地回收 atomic_long_t f_count; unsigned int f_flags; fmode_t f_mode; struct mutex f_pos_lock; // 文件偏移 loff_t f_pos; struct fown_struct f_owner; const struct cred *f_cred; struct file_ra_state f_ra; u64 f_version; // ...&#125; 画了一个图，方便了解上述数据结构关系： 三个重要的系统调用实现openopen() 系统调用会分配新的文件句柄（file description），用来维护与打开文件相关的元信息（如偏移量、路径、操作方法等），并会给进程返回一个文件描述符（其实就是个小整数）。它对应的实现流程如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// fs/open.clong do_sys_open(int dfd, const char __user *filename, int flags, umode_t mode)&#123; struct open_flags op; // 不要被名字 fd 迷惑了，其实这里返回的是错误信息（非 0 表示出错了！） int fd = build_open_flags(flags, mode, &amp;op); struct filename *tmp; if (fd) return fd; tmp = getname(filename); if (IS_ERR(tmp)) return PTR_ERR(tmp); // 分配文件描述符 fd = get_unused_fd_flags(flags); if (fd &gt;= 0) &#123; // 分配文件句柄 struct file *f = do_filp_open(dfd, tmp, &amp;op); if (IS_ERR(f)) &#123; put_unused_fd(fd); fd = PTR_ERR(f); &#125; else &#123; fsnotify_open(f); // 注册到进程的 fdtable 中 fd_install(fd, f); &#125; &#125; putname(tmp); return fd;&#125;// fs/namei.cstruct file *do_filp_open(int dfd, struct filename *pathname, const struct open_flags *op)&#123; // ... struct file *filp; filp = path_openat(&amp;nd, op, flags | LOOKUP_RCU); // ... return filp;&#125;static struct file *path_openat(struct nameidata *nd, const struct open_flags *op, unsigned flags)&#123; struct file *file; file = alloc_empty_file(op-&gt;open_flag, current_cred()); // ... return file&#125;void fd_install(unsigned int fd, struct file *file)&#123; __fd_install(current-&gt;files, fd, file);&#125;void __fd_install(struct files_struct *files, unsigned int fd, struct file *file)&#123; struct fdtable *fdt; // ... rcu_assign_pointer(fdt-&gt;fd[fd], file);&#125; dupdup() 系统调用实际上是会分配一个新的文件描述符，但是底层还是会指向传入的文件描述符关联的文件句柄（file description）。 123456789101112131415161718192021222324252627282930313233// fs/file.cSYSCALL_DEFINE1(dup, unsigned int, fildes)&#123; int ret = -EBADF; // 基于传入的文件描述，查找到关联的文件句柄 // 隐藏了一些错误判断逻辑 // fget_raw 会调用 __fget 函数 struct file *file = fget_raw(fildes); ret = get_unused_fd_flags(0); fd_install(ret, file); return ret;&#125;// fs/file.cstatic struct file *__fget(unsigned int fd, fmode_t mask, unsigned int refs)&#123; // 得到当前进程关联的打开文件表（Open file info table） struct files_struct *files = current-&gt;files; struct file *file; // 查找 fd -&gt; 文件句柄 file = fcheck_files(files, fd); if (file) &#123; /* File object ref couldn't be taken. * dup2() atomicity guarantee is the reason * we loop to catch the new file (or NULL pointer) */ if (file-&gt;f_mode &amp; mask) file = NULL; else if (!get_file_rcu_many(file, refs)) goto loop; &#125; return file;&#125; closeclose() 系统调会回收文件描述符，同时会给文件描述符指向的文件句柄（file description）的引用计数减 1，并在需要的时候进行回收。该系统调用的实现流程总结如下： 其对应的代码实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162SYSCALL_DEFINE1(close, unsigned int, fd)&#123; int retval = __close_fd(current-&gt;files, fd); // ...&#125;// fs/file.c// __close_fd 关闭文件描述符，其中 `files` 指向的是当前进程关联的// 打开文件描述符表。int __close_fd(struct files_struct *files, unsigned fd)&#123; struct file *file; struct fdtable *fdt; spin_lock(&amp;files-&gt;file_lock); fdt = files_fdtable(files); // 判断传入的 file descriptor 有效性 if (fd &gt;= fdt-&gt;max_fds) goto out_unlock; // 查找到关联的 file description，即文件句柄 file = fdt-&gt;fd[fd]; // 回收 file descriptor rcu_assign_pointer(fdt-&gt;fd[fd], NULL); __put_unused_fd(files, fd); spin_unlock(&amp;files-&gt;file_lock); // 关闭 file description return filp_close(file, files);out_unlock: spin_unlock(&amp;files-&gt;file_lock); return -EBADF;&#125;// filp_close 关闭指向的 file description，其中 id 为// POSIX 线程 ID。int filp_close(struct file *filp, fl_owner_t id)&#123; int retval = 0; // 如果文件引用计数为 0，说明存在错误，无法关闭 if (!file_count(filp)) &#123; printk(KERN_ERR "VFS: Close: file count is 0\n"); return 0; &#125; if (filp-&gt;f_op-&gt;flush) retval = filp-&gt;f_op-&gt;flush(filp, id); // 可能会回收 file description，但是会考虑其引用计数 fput(filp); return retval;&#125;// 以下定义在：fs/file_table.cvoid fput(struct file *file)&#123; // 给 file description 的引用计数减 1 fput_many(file, 1);&#125;void fput_many(struct file *file, unsigned int refs)&#123; // 原子操作：&amp;file-&gt;f_count -= refs if (atomic_long_sub_and_test(refs, &amp;file-&gt;f_count)) &#123; // ... &#125;&#125; 总结本文介绍了下文件描述符和打开文件的关系，并简要讲解了 Linux 内核中关于这些抽象概念的具体实现。同时，还简单介绍了下 open(), dup() 和 close() 系统调用的实现。相信在看完这些后，能够更加深入和清晰地理解这三个概念：系统级打开文件表（open file table）/描述表（open file description table）、文件句柄（open file handle）/文件描述（file description）以及文件描述符（file descriptor）。 最后，回答下本文开头提到的问题。其实，站在进程的角度来看，作者在 Linux 文件句柄的这些技术内幕，只有 1% 的人知道 中提到「每个进程都有一个打开的文件表（fdtable)」这样的说法其实也没什么问题。只是此处打开的文件表（fdtable)和《Linux 系统编程》中提到的系统级打开文件表（open file table）并非一个概念。作者提到的打开的文件表（fdtable)其实正是抽象的进程文件描述符（file descriptor）表。当然，我们没必要为此纠结，咬文嚼字也没什么意义，不过对于困惑的东西还是能够搞清楚才好。 参考 Linux 文件句柄的这些技术内幕，只有 1% 的人知道 Linux 内核文件描述符表的演变 man open(2) Linux IO核心数据结构之一]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>文件描述符</tag>
        <tag>文件句柄</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go 语言实现 Redis 字典]]></title>
    <url>%2F2019%2F12%2F17%2Fimplement-redis-dict-in-go%2F</url>
    <content type="text"><![CDATA[引言 字典在 Redis 中是一个非常重要的数据结构，因为 Redis 本身就是一个键值数据库。我们先来回顾下在 Redis 源码学习之基本数据结构 中提到的 Redis 字典实现的一些特点： 支持海量 &lt;key, value&gt; 存储； 使用渐进式 Rehash 策略，避免因为需要迁移的 buckets 太多导致阻塞时间过久（Redis 核心处理逻辑是单线程模型）； 默认使用 SipHash 算法计算键的 hash 值； 对于哈希冲突问题，采用了常见的链地址法，且新加入的节点会插入到链表的头部； 字典内部维护了两张哈希表，其中第二个哈希表会在扩容期间（Rehash）使用； 提供了安全和非安全的迭代器，方便对整个字典进行迭代。 在看了 Redis 字典源码，搞懂它的工作原理后，有没有想要自己实现下呢？所以，本文将介绍如何使用 Go 语言来山寨一个 Redis 字典实现，虽然「容貌」有异，但「内核」还是基本一致的。为了简单起见，我们在实现的时候先不考虑 goroutine 安全问题，焦点放在 Redis 字典实现的核心思想上。所以后面的实现，都假设只有一个 goroutine 在对字典进行操作。由于 Go 语言自带 GC，所以使用它来实现就不用烦心内存管理的问题了（在 Redis dict.c 实现中，还有很多代码是涉及内存申请和释放的），这样就能让我们更加容易地理解核心的实现策略。 一点说明正所谓「入乡随俗」嘛，所以在使用 Go 语言实现的字典中，并没有照搬原先 Redis 中字典的接口，而是提供了一组类似于标准库 sync.Map 的接口。 另外，什么样的 key 可以作为字典的键呢？首先，必须要是方便计算哈希值的；其次，方便进行直接比较。我们知道在 Redis 的字典实现中提供了一组接口，供实际使用字典存储的数据类型实现。之所以这样做，也是为了更好的扩展性。 12345678typedef struct dictType &#123; uint64_t (*hashFunction)(const void *key); void *(*keyDup)(void *privdata, const void *key); void *(*valDup)(void *privdata, const void *obj); int (*keyCompare)(void *privdata, const void *key1, const void *key2); void (*keyDestructor)(void *privdata, void *key); void (*valDestructor)(void *privdata, void *obj);&#125; dictType; 不过为了简单起见，在使用 Go 语言实现时字典时，传入的 key 和 value 均为 interface{} 类型，并没有强制的接口实现要求。另外，针对 key 将只支持 string 和 int 类型及其变种。这种可以满足基本的使用场景，同时也能够拥有和 sync.Map 一样的接口签名。 最后，来看下字典的接口设计： 123456789101112131415161718192021222324252627282930// Store 向字典中添加新的 key-valuefunc (d *Dict) Store(key interface&#123;&#125;, value interface&#123;&#125;)// Load 从字典中获取指定 key 对应的值func (d *Dict) Load(key interface&#123;&#125;) (value interface&#123;&#125;, ok bool)// LoadOrStore 用于根据指定 key 先查找对应值，如果存在则返回对应值；// 否则，会将给定 key-value 存储到字典中，并返回传入的 value。func (d *Dict) LoadOrStore(key, value interface&#123;&#125;) (actual interface&#123;&#125;, loaded bool)// Delete 删除指定的 keyfunc (d *Dict) Delete(key interface&#123;&#125;)// Len 返回字典的元素个数func (d *Dict) Len() uint64// Cap 返回字典的容量func (d *Dict) Cap() uint64// Range 模拟 Redis 字典普通迭代器行为，不支持非安全的操作func (d *Dict) Range(fn func(key, value interface&#123;&#125;) bool)// RangeSafely 模拟 Redis 字典安全迭代器行为，迭代期间不做 rehash 操作func (d *Dict) RangeSafely(fn func(key, value interface&#123;&#125;) bool)// Resize 用于调整字典容量（扩容或缩容，但是 rehash 还是渐进式的）func (d *Dict) Resize() error// RehashForAWhile 执行一段时间的 rehashfunc (d *Dict) RehashForAWhile(duration time.Duration) 实现细节数据结构1234567891011121314151617type Dict struct &#123; hashTables []*hashTable rehashIdx int64 iterators uint64&#125;type hashTable struct &#123; buckets []*entry size uint64 sizemask uint64 used uint64&#125;type entry struct &#123; key, value interface&#123;&#125; next *entry&#125; 字典初始化1234567891011// New 实例化一个字典。func New() *Dict &#123; return &amp;Dict&#123; // 初始化的时候，准备两张哈希表，默认使用哈希表 1 // 在进行扩容时，会将哈希表 1 中的所有元素迁移到 // 哈希表 2。 hashTables: []*hashTable&#123;&#123;&#125;, &#123;&#125;&#125;, rehashIdx: -1, iterators: 0, &#125;&#125; 在哈希表中查找指定的键下面这个函数将基于指定的 key 计算出对应的 hash 值（使用 SipHash 算法，Redis 字典中默认使用的哈希算法），并且通过查询哈希表来确定对应的 key 是否存在于字典中。这个函数比较重要，在后面的 Load 和 Store 函数中都有应用，下面来看看它的具体实现吧： 123456789101112131415161718192021// keyIndex 基于指定的 key 获得对应的 bucket 索引// 如果 key 已经存在于字典中，则直接返回关联的 entryfunc (d *Dict) keyIndex(key interface&#123;&#125;) (idx uint64, existed *entry) &#123; hash := SipHash(key) for i := 0; i &lt; 2; i++ &#123; ht := d.hashTables[i] idx = ht.sizemask &amp; hash for ent := ht.buckets[idx]; ent != nil; ent = ent.next &#123; if ent.key == key &#123; return idx, ent &#125; &#125; if !d.isRehashing() &#123; break &#125; &#125; // 如果字典处于 rehashing 中，上面的循环可以保证最后的 idx 一定位于 // 第二个哈希表，从而保证依赖该接口的地方存储的新键一定进入到新的哈希表 return idx, nil&#125; 查询键值对12345678910111213// Load 从字典中加载指定的 key 对应的值。func (d *Dict) Load(key interface&#123;&#125;) (value interface&#123;&#125;, ok bool) &#123; if d.isRehashing() &#123; d.rehashStep() &#125; _, existed := d.keyIndex(key) if existed != nil &#123; return existed.value, true &#125; return nil, false&#125; 存储键值对1234567891011121314151617181920212223242526272829303132333435// Store 向字典中添加 key-value。func (d *Dict) Store(key interface&#123;&#125;, value interface&#123;&#125;) &#123; ent, loaded := d.loadOrStore(key, value) if loaded &#123; ent.value = value // 直接更新 value 即可 &#125; // 否则，上述函数调用会自动添加 (key, value) 到字典中&#125;// loadOrStore 先尝试使用 key 查找，如果查找到则直接返回对应 entry，// 否则，会添加新的 entry 到字典中，同时返回 nil，表示之前不存在。func (d *Dict) loadOrStore(key, value interface&#123;&#125;) (ent *entry, loaded bool) &#123; if d.isRehashing() &#123; d.rehashStep() &#125; _ = d.expandIfNeeded() // 这里简单起见，假设一定是可以扩容成功的，忽略了错误 idx, existed := d.keyIndex(key) ht := d.hashTables[0] if d.isRehashing() &#123; ht = d.hashTables[1] &#125; if existed != nil &#123; return existed, true &#125; else &#123; // 否则，需要在指定 bucket 添加新的 entry // 对于哈希冲突的情况，采用链地址法，在插入新的 entry 时， // 采用头插法，保证最近添加的在最前面 entry := &amp;entry&#123;key: key, value: value, next: ht.buckets[idx]&#125; ht.buckets[idx] = entry ht.used++ &#125; return nil, false&#125; 删除键值对删除操作值得一提的是，在查找到要删除的 Entry 后，需要记得调整哈希桶的头指针，可能被删除的 Entry 恰好就是头节点。代码实现比较简单，如下： 12345678910111213141516171819202122232425262728293031323334353637383940// Delete 从字典中删除指定的 key，如果 key 不存在，则什么也// 不做。// 实现描述：// 1. 遍历哈希表，定位到对应的 buckets// 2. 删除 buckets 中匹配的 entry。func (d *Dict) Delete(key interface&#123;&#125;) &#123; if d.Len() == 0 &#123; // 不要做无畏的挣扎！ return &#125; if d.isRehashing() &#123; d.rehashStep() &#125; hash := SipHash(key) for i := 0; i &lt; 2; i++ &#123; ht := d.hashTables[i] idx := ht.sizemask &amp; hash var prevEntry *entry for ent := ht.buckets[idx]; ent != nil; ent = ent.next &#123; if ent.key == key &#123; // 此时需要释放 ent 节点 if prevEntry != nil &#123; prevEntry.next = ent.next &#125; else &#123; // 说明待释放的节点是头节点，需要调整 buckets[idx] 指向下一个节点 ht.buckets[idx] = ent.next &#125; ent.next = nil ht.used-- return &#125; prevEntry = ent &#125; if !d.isRehashing() &#123; break &#125; &#125;&#125; 扩容和缩容在给字典添加键值对时，会调用 loadOrStore 方法，而在该方法内部调用了一次 d.expandIfNeeded() 方法尝试给字典按需扩容。那么，字典扩容的时机是什么呢？扩容的策略又是怎样的呢？且看源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566const ( _initialHashtableSize uint64 = 4)func (d *Dict) expandIfNeeded() error &#123; if d.isRehashing() &#123; // 此时表明扩容已经成功，正在进行迁移（rehash） return nil &#125; if d.hashTables[0].size == 0 &#123; // 第一次扩容，需要一定的空间存放新的 keys return d.resizeTo(_initialHashtableSize) &#125; // 否则，根据负载因子判断是否需要进行扩容 // 扩容策略简单粗暴，至少要是已有元素个数的二倍 if d.hashTables[0].used == d.hashTables[0].size &#123; return d.resizeTo(d.hashTables[0].used * 2) &#125; return nil&#125;func (d *Dict) resizeTo(size uint64) error &#123; // 这里主要是要保证扩容大小符合要求，至少要比现有元素个数多 if d.isRehashing() || d.hashTables[0].used &gt; size &#123; return errors.New("failed to resize") &#125; size = d.nextPower(size) if size == d.hashTables[0].size &#123; return nil &#125; // 准备开始扩容 var ht *hashTable if d.hashTables[0].size == 0 &#123; // 第一次执行扩容，给 ht[0] 准备好，接下来 keys 可以直接放进来 ht = d.hashTables[0] &#125; else &#123; ht = d.hashTables[1] // 表明需要开始进一步扩容，迁移 ht[0] -&gt; ht[1] d.rehashIdx = 0 &#125; ht.size = size ht.sizemask = size - 1 ht.buckets = make([]*entry, ht.size) return nil&#125;// nextPower 找到匹配 size 的扩容大小// 2^2 -&gt; 2^3 -&gt; 2^4 -&gt; 2^5 -&gt; ...func (d *Dict) nextPower(size uint64) uint64 &#123; if size &gt;= math.MaxUint64 &#123; return math.MaxUint64 &#125; i := _initialHashtableSize for i &lt; size &#123; i &lt;&lt;= 1 // i*= 2 &#125; return i&#125; 我们知道了扩容是何时进行的了， 但是看起来并没有在删除元素时执行缩容操作呢？那缩容会在什么时候执行呢？在 Redis 中，是由字典的使用者来确定缩容的时机的，比如在删除键值对后，或者在 serverCron 中执行（具体调用链路为：serverCron-&gt;databasesCron-&gt;tryResizeHashTables-&gt;dictResize）。该方法的实现很简单，用 Go 语言表达如下： 123456789101112131415// Resize 让字典扩容或者缩容到一定大小。// 注意，这里只是会准备好用于扩容的第二个哈希表，但真正的迁移还是分散// 在多次 Rehash 操作中。func (d *Dict) Resize() error &#123; if d.isRehashing() &#123; return errors.New("dict is rehashing") &#125; size := d.hashTables[0].used if size &lt; _initialHashtableSize &#123; size = _initialHashtableSize &#125; return d.resizeTo(size)&#125; 渐进式 rehash渐进式 Rehash 的思想很简单，就是将大量的工作分成很多步完成。在上面的源码中可以看到，Load, Store, Delete 方法中，都有调用 d.rehashStep()，进而又会调用 d.rehash(1)。下面我们来看看渐进式 Rehash 是怎么实现的： 123456789101112131415161718192021222324252627282930313233343536373839404142434445// rehash 实现渐进式 Rehash 策略。基本思想就是，每次对最多// steps 个 buckets 进行迁移。另外，考虑到可能旧的哈希表中// 会连续遇到较多的空 buckets，导致耗费时间不受限制，这里还// 限定最多遇到 10 * steps 个空 buckets 就退出。func (d *Dict) rehash(steps uint64) (finished bool) &#123; if !d.isRehashing() &#123; return true &#125; maxEmptyBucketsMeets := 10 * steps src, dst := d.hashTables[0], d.hashTables[1] for ; steps &gt; 0 &amp;&amp; src.used != 0; steps-- &#123; // 扫描哈希表直到遇到非空的 bucket for src.buckets[d.rehashIdx] == nil &#123; d.rehashIdx++ maxEmptyBucketsMeets-- if maxEmptyBucketsMeets &lt;= 0 &#123; return false &#125; &#125; // 把整个 bucket 上所有的 entry 都迁移走 for ent := src.buckets[d.rehashIdx]; ent != nil; &#123; next := ent.next idx := SiphHash(ent.key) &amp; dst.sizemask ent.next = dst.buckets[idx] dst.buckets[idx] = ent src.used-- dst.used++ ent = next &#125; src.buckets[d.rehashIdx] = nil // 清空旧的 bucket d.rehashIdx++ &#125; // 如果迁移完毕，需要将 ht[0] 指向迁移后的哈希表 if src.used == 0 &#123; d.hashTables[0] = dst d.hashTables[1] = &amp;hashTable&#123;&#125; d.rehashIdx = -1 return true &#125; return false&#125; 字典迭代器迭代器的数据结构定义如下： 12345678910111213141516171819// iterator 实现了一个对字典的迭代器。// 不过考虑到我们将为字典提供 `Range` 方法，故该迭代器就不往外暴露了。type iterator struct &#123; d *Dict tableIndex int safe bool fingerprint int64 entry *entry bucketIndex uint64 waitFirstIteration bool&#125;func newIterator(d *Dict, safe bool) *iterator &#123; return &amp;iterator&#123; d: d, safe: safe, waitFirstIteration: true, &#125;&#125; 在 Redis 的字典中，提供了两种类型的迭代器，分别通过 dictGetIterator 和 dictGetSafeIterator 获得。普通迭代器只能执行和字典关联的 dictNext 方法，不允许执行 dictFind，dictAdd 等操作，这主要是因为这些操作可能会引起 Rehash，从而导致在迭代期间可能会扫描到重复的键值对（比如在执行 Rehash 期间，某些键值对被迁移到了新的哈希表，但是我们是优先扫描第一个哈希表，然后再扫描第二个哈希表，而此时可能会遇到之前扫描过的元素）。当然，Redis 的普通迭代器是没法阻止你在迭代期间执行不安全的操作的，但是它会通过计算迭代前后字典的指纹信息，并在最后进行比对，若指纹不匹配，则无法通过 assert(iter-&gt;fingerprint == dictFingerprint(iter-&gt;d)) 断言。 那么安全迭代器又是如何做到可以允许 dictFind 和 dictAdd 等操作执行的呢？其实它是通过阻止字典 rehash 实现的，正因为如此，它才可以放心大胆地扫描哈希表中的 Entries，而不用担心遇到重复的 Entries。在上面的代码中可以看到，在 Load、Store 和 Delete 中都有直接或间接地调用 d.rehashStep() 方法，它的实现如下： 12345func (d *Dict) rehashStep() &#123; if d.iterators == 0 &#123; d.rehash(1) &#125;&#125; 最后，我们来看看迭代器最重要的 next() 方法实现，就可以看到安全迭代器和普通迭代器的区别了： 1234567891011121314151617181920212223242526272829303132333435363738// next 会依次扫描字典中哈希表的所有 buckets，并将其中的 entry 一一返回。// 如果字典正在 rehash，那么会在扫描完哈希表 1 后，继续扫描哈希表 2。需要// 注意的是，如果在迭代期间，继续向字典中添加数据可能没法被扫描到！func (it *iterator) next() *entry &#123; for &#123; if it.entry == nil &#123; if it.waitFirstIteration &#123; // 第一次迭代，要做点特别的事情~ if it.safe &#123; // 告诉 dict，有正在运行的安全迭代器，进而阻止某些操作时的 Rehash 操作 it.d.iterators++ &#125; else &#123; it.fingerprint = it.d.fingerprint() &#125; it.waitFirstIteration = false &#125; ht := it.d.hashTables[it.tableIndex] if it.bucketIndex &gt;= ht.size &#123; if !it.d.isRehashing() || it.tableIndex != 0 &#123; return nil &#125; // 切换到第二个哈希表继续扫描 it.tableIndex = 1 it.bucketIndex = 0 ht = it.d.hashTables[1] &#125; it.entry = ht.buckets[it.bucketIndex] it.bucketIndex++ &#125; else &#123; it.entry = it.entry.next &#125; if it.entry != nil &#123; return it.entry &#125; &#125;&#125; 使用示例12345678910111213func main() &#123; d := dict.New() d.Store("hello", "world") d.Store(100, 200) fmt.Println(d.Load("hello")) fmt.Println(d.LoadOrStore("language", "Eng")) d.Range(func(key, value interface&#123;&#125;) bool &#123; fmt.Println(key, "=&gt;", value) return true &#125;) _ = d.Resize() d.RehashForAWhile(1 * time.Microsecond)&#125; 总结好啦，关于 Redis 字典的实现介绍就到此为止啦。相信看完上面的代码后，应该可以了解到 Redis 字典的扩容机制、渐进式 Rehash 策略，以及哈希冲突解决方案。完整的实现代码及其单元测试参见 go-redis-dict。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Go</tag>
        <tag>Redis</tag>
        <tag>字典</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 源码学习之基本数据结构]]></title>
    <url>%2F2019%2F12%2F15%2Fredis-low-level-data-structures%2F</url>
    <content type="text"><![CDATA[引言 Redis 底层的基础数据结构包括：动态字符串（sds）、跳表（skiplist）、压缩列表（ziplist）、字典（dict）、整数集合（intset），快速链表（quicklist）等，t_hash，t_set, t_zset, t_list 等对外类型的内部实现都依赖于这些数据结构，所以非常值得学习。 在学习每种数据结构时，需要重点关注如下几个问题： 为什么这样设计，做了什么样的权衡？比如，有些数据结构是为了节约内存而设计的，所以会牺牲一定的查找效率； 每种数据结构的基本特点是什么？具体在什么场景下应用到？ 一些数据结构接口的平均时间复杂度是什么？ 很多数据结构在上层使用时，会根据需要选择，必要时会进行转换。需要了解转换的时机和触发的条件是什么？ 某些数据结构内部会按需扩容或者缩容，需要关注它们扩容或者缩容的策略如何？什么情况下触发？ 本文的源码学习笔记是基于 Redis 5.0.7 版本做的，自己做了些中文注释，推送到了 redis comment-src 分支，参考书籍为《Redis 5 源码设计与分析》。 做了一个简单的思维导图，简单总结了各个数据结构的基本特点和一些值得阅读源码的 APIs，如果想要快速了解的话，可以直接跳到本文最后一节查看~ 动态字符串动态字符串（SDS, Simple Dynamic String）是 Redis 中最常用的数据类型之一，可以用来存储字符串和整数。并且它是二进制安全的，还兼容 C 语言字符串的结束符 ‘\0’，所以部分 C 标准库中的字符串函数也可以对 SDS 进行操作。 动态字符串元信息及存储字符串的 buf 是由 sdshdr* 维护的，其定义如下： 12345678910111213141516171819202122// __attribute__ ((__packed__)) 使用这种方式，要求编译器编译时，按照实际的字节数进行对齐。// 这样做的好处有两个：// 1. 节约内存（否则不同的 sdshdr* 因为不同的字节对齐方式，而导致占据较多内存）// 2. 通过 header 获得 buf 地址时，不用考虑繁琐的字节对齐问题而导致计算复杂struct __attribute__ ((__packed__)) sdshdr5 &#123; // flags 的低三位表示类型，高三位表示字符串长度 unsigned char flags; /* 3 lsb of type, and 5 msb of string length */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr8 &#123; // len 字符串长度 uint8_t len; /* used */ // alloc 表示柔性数组分配的长度（不包含 header 和字符串终止符号） uint8_t alloc; /* excluding the header and null terminator */ // flags 低三位表示类型，高 5 位保留 unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;// 此外还有 sdshdr16, sdshdr32, sdshdr64，区别仅在于 len, alloc 使用的整数字节长度 关于 SDS 的几个问题： 如何兼容 C 语言字符串标准？ SDS 返回的就是指向存储字符串 buf 的指针，且以 ‘\0’ 结尾。 如何节约内存？ SDS 中根据字符串长度，提供了不同类型的结构体表示（sdshdr5, sdshdr8, sdshdr16, sdshdr32, sdshdr64），并且结构体中的字段按照单字节对齐（((__packed__))）进一步减少因默认字节对齐方式带来了内存消耗；同时按照单字节对齐，也方便基于 header 指针计算出柔性数组的指针。 如何做到二进制安全？ SDS Header 结构体中拥有 len 字段，记录了实际字符串的长度（不含结束符），因此在读取的时候可以确切地知道在哪儿停止，不会受到中间的 ‘\0’ 影响。 SDS 在创建空字符串时，为何将 sdshdr5 转成 sdshdr8？ 考虑到 sdshdr5 可能需要频繁扩容，导致内存复制开销。使用 sdshdr8 可以有效缓解。 SDS 对于短字符串为何使用 sdshdr5？ 很简单，还是为了节省内存空间，多数的字符串可能都是短字符串（长度 32 以内）。 SDS 在写入时可能会扩容，那么它的扩容策略是怎样的？它的策略比较简单，如果 buf 剩余空间（alloc-len）能够放下新增的字符串长度，则不会有实质的扩容发生；如果剩余空间不够，则需要看 len+newLen 的长度值，如果小于 1MB，则按照 2 倍扩容；否则每次增加 1MB。在扩容后，还要看新的 header 类型（flags 字段表示）是否和之前一样，如果一样，则直接使用 realloc 原地扩容即可；否则需要使用 malloc 开辟新空间，并使用 memcopy 复制数据。完成扩容后，需要更新 SDS 的一些统计信息，并返回新的 buf 指针（也可能指向原来位置，具体看扩容时的策略执行）。 核心源码详细的源码注释参见 这里 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109// sdsnewlen 创建一个新的 sds 对象，并使用 init 指向的内容初始化sds sdsnewlen(const void *init, size_t initlen) &#123; void *sh; sds s; char type = sdsReqType(initlen); // 空字符串创建通常都需要执行 append 追加字符串。使用 type 8 比较适合， // type 5 可能空间不足，还需要执行扩容。 if (type == SDS_TYPE_5 &amp;&amp; initlen == 0) type = SDS_TYPE_8; int hdrlen = sdsHdrSize(type); // 根据数据类型确定 header 长度 unsigned char *fp; /* flags pointer. */ sh = s_malloc(hdrlen+initlen+1); // 分配 sds 内存，+1 为了存储 '\0' if (init==SDS_NOINIT) init = NULL; else if (!init) memset(sh, 0, hdrlen+initlen+1); // 内存初始化为 0 if (sh == NULL) return NULL; s = (char*)sh+hdrlen; // 拿到指向 buf 的指针 fp = ((unsigned char*)s)-1; // point to flag, 注意 flag 其实是 unsigned char 类型 switch(type) &#123; case SDS_TYPE_5: &#123; // type 5 的 flag 比较特殊，类型保留在低 3 位 *fp = type | (initlen &lt;&lt; SDS_TYPE_BITS); break; &#125; case SDS_TYPE_8: &#123; SDS_HDR_VAR(8,s); sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; // SDS_TYPE_16, SDS_TYPE_32, SDS_TYPE_64... &#125; if (initlen &amp;&amp; init) memcpy(s, init, initlen); // 将用户指定区域的数据拷贝过来，不考虑 \0，二进制安全 s[initlen] = '\0'; // C 语言字符串以 '\0' 结尾 return s;&#125;void sdsfree(sds s) &#123; if (s == NULL) return; // s 实际指向的是 buf 位置，这里需要计算出 header 指针 // flag 始终位于 buf 前面，所以 s[-1] 可以得到 flag，进而 // 确定 type，从而可以计算出 header 长度 s_free((char*)s-sdsHdrSize(s[-1]));&#125;sds sdsMakeRoomFor(sds s, size_t addlen)&#123; void *sh, *newsh; size_t avail = sdsavail(s); // 确定 buf 剩余的空间（alloc-len） size_t len, newlen; char type, oldtype = s[-1] &amp; SDS_TYPE_MASK; int hdrlen; /* Return ASAP if there is enough space left. */ // 如果剩余空间足够，则直接返回 if (avail &gt;= addlen) return s; // 确定现有字符串长度 len = sdslen(s); // 获得字符串对应的 sdshdr 指针 sh = (char *)s - sdsHdrSize(oldtype); // 这里的新长度是后面扩容策略执行的依据 newlen = (len + addlen); if (newlen &lt; SDS_MAX_PREALLOC) // 目前是 1MB 以内，2 倍扩容 newlen *= 2; else // 否则都是加 1MB newlen += SDS_MAX_PREALLOC; type = sdsReqType(newlen); /* Don't use type 5: the user is appending to the string and type 5 is * not able to remember empty space, so sdsMakeRoomFor() must be called * at every appending operation. */ if (type == SDS_TYPE_5) type = SDS_TYPE_8; hdrlen = sdsHdrSize(type); if (oldtype == type) &#123; // 如果类型不变，则执行扩容 newsh = s_realloc(sh, hdrlen + newlen + 1); if (newsh == NULL) return NULL; // 获取新的 sds 指向 s = (char *)newsh + hdrlen; &#125; else &#123; /* Since the header size changes, need to move the string forward, * and can't use realloc */ // 由于 header 大小发生了变化，这里需要使用 malloc 开辟空间了 newsh = s_malloc(hdrlen + newlen + 1); if (newsh == NULL) return NULL; // 将 sds 中的内容拷贝到新的空间，包括 \0 memcpy((char *)newsh + hdrlen, s, len + 1); // 释放旧的内存 s_free(sh); // 获取新的 sds 指针 s = (char *)newsh + hdrlen; // 更新 flags s[-1] = type; // 更新长度信息 sdssetlen(s, len); &#125; // 更新分配的空间大小 sdssetalloc(s, newlen); return s;&#125; 跳表（skiplist）跳表是 Redis 集合（zset）底层的实现方式之一（另一种是 ziplist）。跳表的特点如下： 原理简单，实现难度远低于平衡树（红黑树）； 对于查找、插入和删除，平均 O(logN) 时间复杂度，效率和红黑树相当； 内存开销相对平衡树并没有特别大； 特别容易实现 Redis zset 中范围查询。 跳表核心要素：分层 + 有序链表。 跳表查找过程描述：从最上层依次向后查找，如果本层的 next 节点大于要查找的值，或者 next 节点为 NULL，则从本节点开始，降低一层继续往后查找。如果找到目标节点，则返回；否则返回 NULL。 此前使用 Go 语言尝试实现了下 Redis 跳表，相关文章参见 Go 语言实现 Redis 跳表，源码及注释参见 此处。感兴趣的童鞋可以阅读下~ Redis 跳表实现特点 最多有 64 层，可以表示 2^64 个元素； 拥有 backward 后退指针，方便反向遍历； 添加了 span 字段，记录 forward 指向的节点和当前节点的间隔。span 越大，跳过的节点会越多。在计算排名（rank）时，就可以通过 span 计算得到； 新增节点时，层高是通过 zlsRandomLevel() 函数随机生成的，范围是 [1, 64]。但是该函数会保证越高 level 值的出现的概率越低。节点的层高确定后，将不会改边； 节点中的 score 允许重复。 跳表的具体应用zset 会使用跳表存储数据，但是它会根据配置 zset-max-ziplist-entries 128 和 zset-max-ziplist-value 64 值来确定该使用跳表还是 ziplist。另外，在新增元素时，如果原先是 ziplist，当临界条件达到时，会被转换成 skiplist，而且转变后就不可逆了。 核心源码与跳表相关的几个重要的函数作了注释，参见 此处。需要重点关注的函数如下：12345zskiplist *zslCreate(void)zskiplistNode *zslInsert(zskiplist *zsl, double score, sds ele)void zslDeleteNode(zskiplist *zsl, zskiplistNode *x, zskiplistNode **update)int zslDelete(zskiplist *zsl, double score, sds ele, zskiplistNode **node)zskiplistNode *zslUpdateScore(zskiplist *zsl, double curscore, sds ele, double newscore) 在看源码时，会经常看到 update[] 数组，这个数组是用来存放每一层需要被更新的节点（在增加、删除节点时会用到），把它看成 pending_update_nodes 或许会更好理解点。另外，在增、删、改的时候，都会涉及到 span 的更新，需要仔细斟酌计算逻辑，一不小心就算错了。 压缩列表（ziplist）压缩表本质上就是一个字节数组，是一种为节约内存而设计的数据结构。可以存储多个元素，且每个元素可以是整数或者字符串（这里其实也可以理解为二进制安全的字节数组）。两端操作（pop/push）时间复杂度为 O(1)，但考虑到它每次插入或删除元素时，都需要调整内存（扩容或者缩小内存占用），所以实际的时间复杂度和它占用的内存有关。 ziplist 在散列表、列表和有序集合中均有（直接或间接地）应用。我们可以通过 object encoding &lt;key&gt; 来查看具体的使用的数据结构： 123&gt; zadd visitors 1.0 a&gt; object encoding visitors&quot;ziplist&quot; 内存布局在 Redis 的 ziplist.c 中，作者在注释中给出了压缩列表存储布局，并且给出了非常详细的说明和示例，值得阅读。整体来看，压缩列表的内存布局如下： 字段名 类型 说明 zlbytes uint32_t 压缩表字节长度（包括 zlbytes 自己） zltail uint32_t 尾元素相对于压缩列表起始地址的偏移，如此方便快速 pop 最后一个元素 zllen uint16_t 表示 entries 的个数，最大有效值为 2^16-2，一旦超出，该值固定为 2^16-1，并且需要遍历整个列表才能得到准确的长度 zlend uint8_t 固定为 0xff，表示压缩列表的结尾 Entry接下来，我们看看每个 entry 究竟是什么样子的，如下所示： 其中，prevlen 表示前一个 entry 的字节数，便于从后向前遍历；encoding 则表示当前 entry 的编码（整数类型？字符串类型？）；而 entry-data 则是真实存储内容的部分。当然，为了节约内存，这里的 prevlen 和 encoding 都是变长的，而 entry-data 则可能没有（比如存储小整数 0~12 时）。 默认情况下，prevlen 采用 uint8_t 类型，可表示最多 253 字节长度，超出 253 后，将会使用 5 个字节。 1234// 常规情况下&lt;prevlen from 0 to 253&gt; &lt;encoding&gt; &lt;entry&gt;// 长度超过 253 后0xFE &lt;4 字节，小端序 prevlen&gt; &lt;encoding&gt; &lt;entry&gt; encoding 字段也比较有趣，它占用多少个字节，和实际要存储的内容有关： 如果是字符串类型，则 encoding 的前两位表示类型，剩下的则表示字符串的长度： |00pppppp|：表示长度小于 64 字节的字符串，pppppp 表示 6 位无符号整数 |01pppppp|qqqqqqqq| - 2 字节：表示长度小于 2^14 字节的字符串 |10000000|qqqqqqqq|rrrrrrrr|ssssssss|tttttttt| - 5 字节：表示长度小于 2^32 的字符串 如果是整数类型，则 encoding 的前两位总是 1，紧接着的两位则表示具体的整数类型： |11000000|：int16 |11010000|：int32 |11100000|：int64 |11110000|：24 位有符号整数 |11111110|：8 位有符号整数 |1111xxxx|：表示 4 位立即整数（imediate integer），0~12 无符号整数，此时没有 entry-data 字段了 小结根据上面描述的 ziplist 编码，我们来看看什么条件下它会占用较多内存？为什么说 ziplist 适合存储个数较少，且长度较短的元素呢？ 通过 zzlen 可知，如果元素个数超出 2^16-2 时，需要遍历整个 ziplist 元素才可以知道具体的长度，效率自然会降低很多； 通过 prevlen 可知，如果前一个 entry 超出其表示的范围时（253 字节），就需要由原来的 1 个字节变成 5 字节表示； 通过 encoding 可知，对于字符串类型元素，长度越长，encoding 需要占用的字节越多。尤其是在超出 2^14-1 时，新的 encoding 还要浪费第一个字节中的后 6 位，而使用后面的 32 位整数来表示字符串长度。 综上所述，影响内存占用和执行效率的主要因素如下： 元素个数； 元素类型； 元素长度。 核心源码为了方便获得每个 entry 相关的元信息，在 ziplist.c 中定义了一个 zlentry 结构体，但需要注意的是该结构体并非 entry 实际编码的布局。其定义如下：12345678910111213141516171819202122232425262728293031// zlentry 存在的目的就是保存每个 entry 解码后的元信息。因为实际每次对 length, encoding// 等进行解码是比较复杂的运算，这里缓存下来也便于后续操作。// 所以，需要注意的是，zlentry 并非真实的 entry 编码结构。typedef struct zlentry &#123; // prevrawlensize 表示 `prevlen` 占用了几个字节来表示前一个 entry 的长度 unsigned int prevrawlensize; /* Bytes used to encode the previous entry len*/ // prevrawlen 表示前一个 entry 的实际长度 unsigned int prevrawlen; /* Previous entry len. */ // lensize 表示 `encoding` 占用了几个字节 unsigned int lensize; /* Bytes used to encode this entry type/len. For example strings have a 1, 2 or 5 bytes header. Integers always use a single byte.*/ // len 表示 entry 内容真正的长度。如果是字符串，就表示字符串长度；如果是整数 // 则可能的值为 0（4 位小整数），1，2，3，4，8（和具体的 int 类型有关） unsigned int len; /* Bytes used to represent the actual entry. For strings this is just the string length while for integers it is 1, 2, 3, 4, 8 or 0 (for 4 bit immediate) depending on the number range. */ // headersize 表示整个 header 部分长度：&lt;prevlen&gt; + &lt;encoding&gt; unsigned int headersize; /* prevrawlensize + lensize. */ // encoding 表示具体的编码方式，如果 `ZIP_STR_*`,`ZIP_INT_*` // 这里需要注意的是，如果是小整数，还要做范围检查 unsigned char encoding; /* Set to ZIP_STR_* or ZIP_INT_* depending on the entry encoding. However for 4 bits immediate integers this can assume a range of values and must be range-checked. */ // p 指向元素开头的指针，实际指向的就是 `prevlen` 位置 unsigned char *p; /* Pointer to the very start of the entry, that is, this points to prev-entry-len field. */&#125; zlentry; 为了方便理解，画一个示例图如下： ziplist 相关的源码参见 此处。值得重点关注的几个函数如下： 12345unsigned char *ziplistNew(void);unsigned char *ziplistPush(unsigned char *zl, unsigned char *s, unsigned int slen, int where);unsigned char *ziplistInsert(unsigned char *zl, unsigned char *p, unsigned char *s, unsigned int slen);unsigned char *ziplistDelete(unsigned char *zl, unsigned char **p);unsigned char *ziplistFind(unsigned char *p, unsigned char *vstr, unsigned int vlen, unsigned int skip); ziplist 中比较晦涩或者枯燥的部分是编码、解码操作；其次，每次增加或者移除元素时，都涉及到很多内存操作（分配空间、内存拷贝）以及 entry header 的调整。想要写出可靠的代码来，还是需要心思缜密，逻辑清晰才可以，大佬们的编码能力实在是太强悍了！ 这里需要提一点的是，元素的插入和删除，可能会产生连锁更新问题。也就是说，可能会导致自插入点（或删除点）后续的 entry prevlen 都需要修改（还记得前面提到的 entry prevlen 是变长的吗，所以可能需要将 prevlen 增长到 5 字节容纳更大的值；但是反过来，并没有允许缩容）。不过这种情况，只有在后续元素的大小接近于 ZIP_BIG_PREVLEN 才可能发生，概率比较低，所以实际上也没做什么优化。具体策略的实现可以参考 __ziplistCascadeUpdate()： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758unsigned char *__ziplistCascadeUpdate(unsigned char *zl, unsigned char *p)&#123; size_t curlen = intrev32ifbe(ZIPLIST_BYTES(zl)), rawlen, rawlensize; size_t offset, noffset, extra; unsigned char *np; zlentry cur, next; // 遍历所有元素 while (p[0] != ZIP_END) &#123; // 计算当前 entry 长度存储需要的字节数：rawlensize zipEntry(p, &amp;cur); rawlen = cur.headersize + cur.len; rawlensize = zipStorePrevEntryLength(NULL, rawlen); if (p[rawlen] == ZIP_END) break; zipEntry(p + rawlen, &amp;next); // 如果长度不变，则直接退出 if (next.prevrawlen == rawlen) break; if (next.prevrawlensize &lt; rawlensize) &#123; // 下一个元素的 prevlen 需要更多字节来存储 prevrawlen 值 offset = p - zl; extra = rawlensize - next.prevrawlensize; // 扩容以支持存储更长的 rawlen zl = ziplistResize(zl, curlen + extra); // 增加 extra 空间 p = zl + offset; np = p + rawlen; noffset = np - zl; // 更新 tail 偏移，最后一个元素会被移动到新的位置 if ((zl + intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))) != np) &#123; ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl)) + extra); &#125; // 将后续 entry 搬移，腾挪出空间存放新的长度值 memmove(np + rawlensize, np + next.prevrawlensize, curlen - noffset - next.prevrawlensize - 1); // next entry prevlen 记录下之前 entry 的长度值 zipStorePrevEntryLength(np, rawlen); // ...继续下一个元素，每次都可能涉及到内存的扩容和元素的 memmove 操作 &#125; else &#123; // 阻止进行缩容，目的是为了防止后续插入时，可能频繁地 shrink 或者 grow 导致 // 更多地开销。 if (next.prevrawlensize &gt; rawlensize) &#123; /* This would result in shrinking, which we want to avoid. * So, set "rawlen" in the available bytes. */ zipStorePrevEntryLengthLarge(p + rawlen, rawlen); &#125; else &#123; zipStorePrevEntryLength(p + rawlen, rawlen); &#125; break; &#125; &#125; return zl;&#125; 字典（dict）字典在 Redis 中是一个非常重要的数据结构，因为 Redis 本身就是一个 Key-Value 数据库。Redis 中的字典实现特点如下： 可以支持海量的 key-value 映射； key 的类型可以是字符串、整数等类型（void *）；value 可以是复杂的数据类型（string, hash, list, set, sorted set）或者是整数、浮点数等； 为了避免哈希冲突，采用了链地址法，将冲突的 Entry 串联了起来； 为了避免在进行扩容或者缩容时，需要对海量 keys 进行 rehash 而导致阻塞时间过久，采用了渐进式 rehash 策略； 提供了安全和非安全的迭代器，方便对整个字典进行迭代； 对于 keys 非常大的字典，提供了 dictScan 方法，间断迭代，避免因为普通迭代时阻塞其它操作。 数据结构1234567891011121314151617181920212223242526272829303132333435363738typedef struct dictEntry &#123; void *key; union &#123; void *val; uint64_t u64; int64_t s64; double d; &#125; v; struct dictEntry *next;&#125; dictEntry;typedef struct dictType &#123; uint64_t (*hashFunction)(const void *key); void *(*keyDup)(void *privdata, const void *key); void *(*valDup)(void *privdata, const void *obj); int (*keyCompare)(void *privdata, const void *key1, const void *key2); void (*keyDestructor)(void *privdata, void *key); void (*valDestructor)(void *privdata, void *obj);&#125; dictType;/* This is our hash table structure. Every dictionary has two of this as we * implement incremental rehashing, for the old to the new table. */typedef struct dictht &#123; dictEntry **table; unsigned long size; // 哈希表真正的大小 unsigned long sizemask; // sizemask = size-1，这里用于 hash &amp; sizemask 计算出 slot unsigned long used; // 哈希表中的 keys 个数&#125; dictht;typedef struct dict &#123; dictType *type; // 依赖数据抽象的操作接口 void *privdata; // 私有数据，配合 type 字段指向的函数使用 dictht ht[2]; // 有两个 hash table // rehashidx 表示 rehash 的进度 long rehashidx; /* rehashing not in progress if rehashidx == -1 */ // iterators 当前正在运行的迭代器数量 unsigned long iterators; /* number of iterators currently running */&#125; dict; 字典整体结构可以用下图来表示： 扩容与缩容在执行 dictAddRaw() 时，会尝试进行扩容，调用流程如下： 12345dictAddRaw() _dictKeyIndex() _dictExpandIfNeeded() dictExpand() _dictNextPower() 所以扩容或者缩容的核心逻辑在 dictExpand() 函数，我们来看看该函数实现： 1234567891011121314151617181920212223242526272829303132333435int dictExpand(dict *d, unsigned long size)&#123; // 确保我们要扩容的大小可以容纳目前的元素 if (dictIsRehashing(d) || d-&gt;ht[0].used &gt; size) return DICT_ERR; // 得到目标扩容大小 unsigned long realsize = _dictNextPower(size); /* Rehashing to the same table size is not useful. */ // 扩容时比较耗时的操作，避免无效扩容 if (realsize == d-&gt;ht[0].size) return DICT_ERR; // 初始化新的哈希表 dictht n; n.size = realsize; n.sizemask = realsize-1; n.table = zcalloc(realsize*sizeof(dictEntry*)); n.used = 0; // ht[1] 指向的哈希表供渐进式 rehash 使用。 d-&gt;ht[1] = n; d-&gt;rehashidx = 0; // 表示 rehash 准备完毕，进度为 0 return DICT_OK;&#125;// 扩容策略：4 -&gt; 4 * 2 -&gt; 4 * 2 * 2 -&gt; ...// 按照 2 的倍数增加，直到第一个可以容纳 size 大小的数找到为止static unsigned long _dictNextPower(unsigned long size)&#123; unsigned long i = DICT_HT_INITIAL_SIZE; // 4 if (size &gt;= LONG_MAX) return LONG_MAX + 1LU; while (1) &#123; if (i &gt;= size) return i; i *= 2; &#125;&#125; 在需要的时候，Redis 可以对字典执行缩容操作，具体可以调用 dictResize() 函数实现： 1234567int dictResize(dict *d)&#123; int minimal = d-&gt;ht[0].used; if (minimal &lt; DICT_HT_INITIAL_SIZE) minimal = DICT_HT_INITIAL_SIZE; return dictExpand(d, minimal);&#125; 渐进式 Rehash为了避免在 rehash 期间，因为要迁移的 keys 太多，导致阻塞其它操作时间太久，Redis 的字典实现中，使用了渐进式 rehash 的策略，从而将对大量 keys 的迁移分散在 N 次操作中，直到最终完成，具体实现参见 dictRehash()。 采用了渐进式 rehash 策略后，每次在执行查找、插入、更新、删除以及 Redis 服务器空闲时，可以执行一部分 keys 的 rehash 操作。具体执行时机如下： _dictRehashStep() -&gt; dictRehash(d, 1)： dictAddRaw() dictDelete() dictUnlink() dictFind() dictGetRandomKey() dictGetSomeKeys() incrementallyRehash() -&gt; dictRehashMilliseconds(d, 1) -&gt; dictRehash(d, 100)：Server 处于空闲时执行 1ms 的 rehash 工作。 普通迭代器与安全迭代器迭代器是一种常见的设计模式，它可以方便我们对容器中的元素进行遍历，但不需要了解容器内部实现细节。Redis 的字典也我们提供了迭代器数据结构，其定义如下： 1234567891011121314typedef struct dictIterator &#123; dict *d; long index; // table 指向的当前在迭代 table，safe 表明是否为安全的迭代器 int table, safe; dictEntry *entry, *nextEntry; // fingerprint 用来检查非安全迭代器在使用期间是否执行了不允许的操作 long long fingerprint;&#125; dictIterator;dictIterator *dictGetIterator(dict *d);dictIterator *dictGetSafeIterator(dict *d);dictEntry *dictNext(dictIterator *iter);void dictReleaseIterator(dictIterator *iter); 安全迭代器和普通迭代器的区别： 安全迭代器允许我们在迭代期间，执行查找、删除、新增等对 dict 有副作用的操作（如执行 keys * 命令时会创建安全迭代器）； 普通迭代器则只能允许我们执行 dictNext() 进行迭代，其它操作是不允许的（如执行 sort 会创建非安全迭代器）。 那么，为什么会有这样的限制呢？这主要是因为在迭代期间，如果有执行查找、添加、删除等操作，可能会发生 rehash，进而导致扫描到重复的 entry。 普通迭代器在迭代开始时，计算出当前 dict 的指纹，并在迭代结束时再次计算 dict 的指纹，从而确定 dict 在此期间是否发生过修改过，相关实现如下：12345678910111213141516171819202122232425dictEntry *dictNext(dictIterator *iter) &#123; while (1) &#123; if (iter-&gt;entry == NULL) &#123; dictht *ht = &amp;iter-&gt;d-&gt;ht[iter-&gt;table]; if (iter-&gt;index == -1 &amp;&amp; iter-&gt;table == 0) &#123; // 开始迭代，计算下 fp iter-&gt;fingerprint = dictFingerprint(iter-&gt;d); &#125; iter-&gt;index++; // ... &#125; // ... &#125; return NULL;&#125;void dictReleaseIterator(dictIterator *iter) &#123; if (!(iter-&gt;index == -1 &amp;&amp; iter-&gt;table == 0)) &#123; if (iter-&gt;safe) iter-&gt;d-&gt;iterators--; else assert(iter-&gt;fingerprint == dictFingerprint(iter-&gt;d)); &#125; zfree(iter);&#125; 那么，安全迭代器又是如何做到安全的呢？其实策略很简单，就是在执行对 dict 有副作用的操作时，阻止其进行 rehash 即可，这样可以保证底层的 hash tables 不会有 keys 的迁移。具体实现如下： 迭代器初始化时，safe 字段置 1； 初次迭代时，执行 iter-&gt;d-&gt;iterators++，告诉 dict 当前存在安全的迭代器在运行； _dictRehashStep 时，如果 dict-&gt;iterators != 0 则不会执行 rehash。 间断迭代器为了避免扫描所有的 keys 而造成长时间的阻塞（事实上，我们的生产环境是禁用 keys 命令的），Redis 在 2.8 之后加入了 scan 操作，从而能够间断地迭代整个字典。zscan 和 hscan 底层都会执行间断迭代操作，它的具体实现参见 dictScan，核心是围绕一个游标进行的，关于它的具体策略可以参见源码的详细描述。 这里总结下 dictScan 算法的主要特点： 迭代器本身是无状态的（和上面的两个相比），迭代位置是基于游标计算的，而游标会返回给用户，由用户保存，并在迭代时传入； 可能会迭代到重复的元素，但由于采用了 reverse binary iteration 算法，能够保证不漏遍历且尽可能不重复遍历； 每次迭代会返回多个元素，这主要是因为避免 rehash 的影响，每次会将一个 bucket 上所有的 keys 都返回出去。 整数集合（intset）顾名思义，intset 是转门用于存储整数的集合。它实际上也是为了节约内存而设计的，随着元素中最大的元素的类型发生变化，它也会按需扩容。intset 还有个特点是有序且不重复（可以想到查找时就可以光明正大地利用二分算法了）。 intset 实际上是 Redis 集合类型底层使用的数据结构之一，当元素为 64 位以内有符号整数（支持 int16_t, int32_t, int64_t），且元素个数不多（取决于 set_max_intset_entries 设置）时使用。当元素个数超出设定值，或者新增元素类型非整数，intset 就会被转换成 hashtable，也就是使用 dict 来存储。具体可以看下面的代码： 1234567891011121314151617181920212223242526272829robj *setTypeCreate(sds value) &#123; if (isSdsRepresentableAsLongLong(value,NULL) == C_OK) return createIntsetObject(); return createSetObject();&#125;int setTypeAdd(robj *subject, sds value)&#123; long long llval; if (subject-&gt;encoding == OBJ_ENCODING_HT) &#123; /*...*/ &#125; else if (subject-&gt;encoding == OBJ_ENCODING_INTSET) &#123; if (isSdsRepresentableAsLongLong(value, &amp;llval) == C_OK) &#123; uint8_t success = 0; subject-&gt;ptr = intsetAdd(subject-&gt;ptr, llval, &amp;success); if (success) &#123; // 元素个数超出范围，需要转换成字典存储 if (intsetLen(subject-&gt;ptr) &gt; server.set_max_intset_entries) setTypeConvert(subject, OBJ_ENCODING_HT); return 1; &#125; &#125; else &#123; // 非整数类型，转换成字典 setTypeConvert(subject, OBJ_ENCODING_HT); // ... &#125; &#125; return 0;&#125; 数据结构12345typedef struct intset &#123; uint32_t encoding; // 整数长度：INTSET_ENC_INT16, INTSET_ENC_INT32, INTSET_ENC_INT64 uint32_t length; // 整数个数 int8_t contents[];&#125; intset; 简单画了个内存布局图如下，相信可以直观地表达这个数据结构的特点： 核心源码intset 的核心 API 比较少，且实现比较简单，很容易看懂，所以在这里不多赘述了，相关源码中文注释直接看 这里。 12345678intset *intsetNew(void);intset *intsetAdd(intset *is, int64_t value, uint8_t *success); // O(N)intset *intsetRemove(intset *is, int64_t value, int *success); // O(N)uint8_t intsetFind(intset *is, int64_t value); // O(logN)int64_t intsetRandom(intset *is); // O(1)uint8_t intsetGet(intset *is, uint32_t pos, int64_t *value); // O(1)uint32_t intsetLen(const intset *is); // O(1)size_t intsetBlobLen(intset *is); // O(1) 快速链表（quicklist）快速链表（quicklist）本质上也是一个双向链表，但是它的每个节点存储的元素位于 ziplist 中，并且中间节点的 ziplist 还可以使用 LZF 算法进行压缩，进一步节省内存。总的来说，quicklist 是一个综合了双向链表和 ziplist 优点的数据结构。ziplist 最大的特点是节约内存，但不适宜存储过多的元素；而链表则便于从头部或者尾部执行插入或查找。 因此，quicklist 算是为 Redis 列表类型 t_list 特别定制的数据结构，兼顾了时间和空间效率。我们通常使用的 LPUSH, LPOP, RPUSH, RPOP 命令，实际上只需要操作列表两端即可，而 qucklist 恰好维护了 head 和 tail 的节点指针，方便快速定位。 数据结构1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374// quicklist 是对快速链表这种数据结构的抽象，其中存储了一些元信息。typedef struct quicklist &#123; // head, tail 指向链表的头尾 quicklistNode *head; quicklistNode *tail; // count 记录了所有 ziplists 的元素个数之和 unsigned long count; /* total count of all entries in all ziplists */ // len 记录了有多少个 Nodes unsigned long len; /* number of quicklistNodes */ // fill 表示每个节点最多可以包含的数据项，正数表示最多可以含有的元素个数 // 负数则表示每个节点 ziplist 的最大长度（字节数）： // -1, 4KB // -2, 8KB // -3, 16KB // -4, 32KB // -5, 64KB int fill : 16; /* fill factor for individual nodes */ // compress 表示两端不被压缩的节点个数。一般对于 list 的操作通常是在两端进行的 // 所以，为了方便 LPUSH/LPOP/RPUSH/RPOP 命令，这里可以选择对两端不做压缩。 // 但是为了节约内存，会对中间节点进行压缩（ziplist 已经够节约内存了，但是还是要压缩 // 更进一步地节约内存），代价就是消耗点 CPU 时间用于压缩或者解压缩。 unsigned int compress : 16; /* depth of end nodes not to compress;0=off */&#125; quicklist;// quicklistNode 实际上是对 ziplist 的描述，元素存储于 ziplist 中。// 为什么需要在 quicklistNode 中位于 ziplist 的一些元信息呢？这主要是因为// 节点指向的 ziplist 可以被压缩，这样就不能快速获取一些元信息了（元素个数等）。typedef struct quicklistNode &#123; // 双向链表，自然需要前后关联 struct quicklistNode *prev; struct quicklistNode *next; // 指向 ziplist 指针（如果是压缩节点，实际指向的是 quicklistLZF） unsigned char *zl; // ziplist 的大小（bytes） unsigned int sz; /* ziplist size in bytes */ // ziplist 中存储的元素个数 unsigned int count : 16; /* count of items in ziplist */ // 表示 ziplist 进行了压缩编码，RAW=1 表示没有压缩；2 表示使用了 LZF 算法压缩 unsigned int encoding : 2; /* RAW==1 or LZF==2 */ // 容器类型 unsigned int container : 2; /* NONE==1 or ZIPLIST==2 */ // 当前节点是否被压缩过？如果压缩过还需要在使用前进行解压 unsigned int recompress : 1; /* was this node previous compressed? */ // 当前节点太小了，无法压缩 unsigned int attempted_compress : 1; /* node can't compress; too small */ unsigned int extra : 10; /* more bits to steal for future usage */&#125; quicklistNode;// quicklistLZF 表示 ziplist 压缩后的数据结构，它是一个 4+N 字节大小的结构体。typedef struct quicklistLZF &#123; // sz 表示 LZF 压缩后的数据大小 unsigned int sz; /* LZF size in bytes*/ // compressed 存储压缩后的数据 char compressed[];&#125; quicklistLZF;// quicklistEntry 是对 quicklistNode 下 ziplist 某个元素的抽象，// 方便我们获取元素的内容。typedef struct quicklistEntry &#123; // quicklist 指向 quicklist 的指针 const quicklist *quicklist; // quicklistNode 当前 entry 关联的节点 quicklistNode *node; // zi 关联的 ziplist unsigned char *zi; // value 指向 string 类型的元素位置 unsigned char *value; // longvalue 元素转换为整数的值 long long longval; // sz 表示 value 的有效长度（string 类型编码时，encoding 中的长度部分就是这个） unsigned int sz; // offset 表示在当前 ziplist 中的偏移量 int offset;&#125; quicklistEntry; 通过下图可以对 quicklist 有个直观的感受，便于理解这种数据结构： 核心源码quicklist 的源码比较多，就不再本文中赘述了，详细的源码注释可以在 此处 查看。值得重点关注的几个函数如下： 12345678910// n 为 quicklist 节点个数，m 表示内部 ziplist 的元素个数quicklist *quicklistCreate(void); // O(1)int quicklistPushHead(quicklist *quicklist, void *value, const size_t sz); // O(m)int quicklistPushTail(quicklist *quicklist, void *value, const size_t sz); // O(m)void quicklistPush(quicklist *quicklist, void *value, const size_t sz, int where); // O(m)void quicklistInsertAfter(quicklist *quicklist, quicklistEntry *node, void *value, const size_t sz); // O(m)void quicklistInsertBefore(quicklist *quicklist, quicklistEntry *node, void *value, const size_t sz); // O(m)int quicklistIndex(const quicklist *quicklist, const long long index, quicklistEntry *entry); // O(n+m)int quicklistPop(quicklist *quicklist, int where, unsigned char **data, unsigned int *sz, long long *slong); // O(m) 总结这里就不多废话了，对于基本的数据结构做了点总结，放在下面的思维导图中。其中 APIs 分支并非每个数据结构全部的接口，而是一些比较有趣，值得阅读源码的接口，有兴趣地话可以欣赏下它们的内部实现。如果有任何问题，欢迎留言指正~ 参考 Redis 为什么用跳表而不用平衡树？ 《Redis 5 设计与源码分析》]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>源码学习</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go 语言实现 Redis 跳表]]></title>
    <url>%2F2019%2F12%2F11%2Fimplement-redis-skiplist-in-go%2F</url>
    <content type="text"><![CDATA[引言读过 Redis 源码的童鞋，想必会知道 zset 实现时，使用了「跳表」（Skiplist）这种数据结构吧。它的原理非常容易理解，如果对链表比较熟悉，那么也会很容易理解「跳表」的工作原理（核心：有序链表 + 分层）。当然，本文并不会详细讲解「跳表」的工作原理，以及对于 Redis 跳表源码的详细分析。因为已经有前辈们产出了非常丰富的文章来讲解 Redis 跳表，需要的话，推荐阅读 这篇文章 了解更多细节。 总的来说，Redis 的 zset 实现中，选用「跳表」的主要原因如下： 原理清晰易懂，且容易实现，方便维护：对比下平衡树或者红黑树（可能就像 Raft v.s. Paxos 的感觉一样），不管是原理还是实现都简单了很多。平衡树或者红黑树在实现时，还要时刻维护节点关系，必要时还需要执行树的左旋或者右旋来保持平衡； 拥有媲美平衡树或者红黑树的查询效率：插入、删除、查找的平均时间复杂度可以达到 O(logN)。 当然，相对于 William Pugh 在他的论文中所描述的「跳表」算法而言，作者在实现 Redis 中的「跳表」时，给它加了点「料」： 允许重复的分数存在； 在进行比较时，不仅会比较 score，还会考虑关联的数据； 添加了一个回退指针，从而构成了一个双向链表（level[0]），便于倒序遍历链表（ZREVRANGE）使用。 好了，废话完毕。接下来进入正题，看看如何使用 Go 语言来实现「跳表」吧（贴代码模式开启~）。 跳表实现以下仅仅列出了几个比较有趣且关键的方法实现，即：插入、删除和更新分数。完整的实现源码可以参考 这里 或者 这里，包含了比较详细的单元测试。 数据结构定义需要说明的是，为了简单起见，假设存储的元素是字符串类型（要是使用 interface{} 的话，又得加些代码支持元素之间的比较了）。但是在 Redis 中，实际的 element 类型是 sds。 123456789101112131415161718192021222324const ( MaxLevel = 64 // 足以容纳 2^64 个元素 P = 0.25)type Node struct &#123; elem string score float64 backward *Node level []skipLevel&#125;type skipLevel struct &#123; // forward 每层都要有指向下一个节点的指针 forward *Node // span 间隔定义为：从当前节点到 forward 指向的下个节点之间间隔的节点数 span int&#125;type Skiplist struct &#123; header, tail *Node level int // 记录跳表的实际高度 length int // 记录跳表的长度（不含头节点）&#125; 辅助方法考虑到在实现时，经常需要比较 score 和 element，所以这里直接给 Node 实现了一些比较方法，便于使用。 12345678910111213141516171819202122232425func (node *Node) Compare(other *Node) int &#123; if node.score &lt; other.score || (node.score == other.score &amp;&amp; node.elem &lt; other.elem) &#123; return -1 &#125; else if node.score &gt; other.score || (node.score == other.score &amp;&amp; node.elem &gt; other.elem) &#123; return 1 &#125; else &#123; return 0 &#125;&#125;func (node *Node) Lt(other *Node) bool &#123; return node.Compare(other) &lt; 0&#125;func (node *Node) Lte(other *Node) bool &#123; return node.Compare(other) &lt;= 0&#125;func (node *Node) Gt(other *Node) bool &#123; return node.Compare(other) &gt; 0&#125;func (node *Node) Eq(other *Node) bool &#123; return node.Compare(other) == 0&#125; 插入元素12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485// Insert 向跳表中插入一个新的元素。// 步骤：// 1. 查找插入位置// 2. 创建新节点，并在目标位置插入节点// 3. 调整跳表 backward 指针等func (sl *Skiplist) Insert(score float64, elem string) *Node &#123; var ( // update 用于记录每层待更新的节点 update [MaxLevel]*Node // rank 用来记录每层经过的节点记录（可以看成到头节点的距离） rank [MaxLevel]int // 构建一个新节点，用于下面的大小判断，其 level 在后面设置 node = &amp;Node&#123;score: score, elem: elem&#125; ) cur := sl.header for i := sl.level - 1; i &gt;= 0; i-- &#123; if cur == sl.header &#123; rank[i] = 0 &#125; else &#123; rank[i] = rank[i+1] &#125; // 与同层的后一个节点比较，如果后一个比目标值小，则可以继续向后 // 否则下降到一层查找。注意这里的大小比较是按照 score 和 // elem 综合计算得到的。 for cur.level[i].forward != nil &amp;&amp; cur.level[i].forward.Lt(node) &#123; rank[i] += cur.level[i].span // 同层继续往后查找 cur = cur.level[i].forward &#125; update[i] = cur &#125; // 调整跳表高度 level := sl.randomLevel() if level &gt; sl.level &#123; // 初始化每层 for i := level - 1; i &gt;= sl.level; i-- &#123; rank[i] = 0 update[i] = sl.header update[i].level[i].span = sl.length &#125; sl.level = level &#125; // 更新节点 level，并插入新节点 node.setLevel(level) for i := 0; i &lt; level; i++ &#123; // 更新每层的节点指向 node.level[i].forward = update[i].level[i].forward update[i].level[i].forward = node // 更新 span 信息 node.level[i].span = update[i].level[i].span - (rank[0] - rank[i]) update[i].level[i].span = (rank[0] - rank[i]) + 1 &#125; // 针对新增节点 level &lt; sl.level 的情况，需要更新上面没有扫到的层 span for i := level; i &lt; sl.level; i++ &#123; update[i].level[i].span++ &#125; // 调整 backward 指针 // 如果前一个节点是头节点，则 backward 为 nil // 否则 backward 指向之前节点 if update[0] != sl.header &#123; // update[0] 就是和新增节点相邻的前一个节点 node.backward = update[0] &#125; // 如果新增节点是最后一个，则需要更新 tail 指针 if node.level[0].forward == nil &#123; sl.tail = node &#125; else &#123; // 中间节点，需要更新后一个节点的回退指针 node.level[0].forward.backward = node &#125; sl.length++ return node&#125;// randomLevel 对于新增节点，返回一个随机的 level// 返回的 level 范围为 [1, MaxLevel]。并且，采用的// 算法会保证，更大的 level 返回的概率越低。// 每个 level 出现的概率计算：(1-p) * p^(level-1)func (sl *Skiplist) randomLevel() int &#123; level := 1 for rand.Float64() &lt; P &amp;&amp; level &lt; MaxLevel &#123; level++ &#125; return level&#125; 删除元素12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// Delete 用于删除跳表中指定的节点。func (sl *Skiplist) Delete(score float64, elem string) *Node &#123; // 第一步，找到需要删除节点 var ( update [MaxLevel]*Node targetNode = &amp;Node&#123;elem: elem, score: score&#125; ) cur := sl.header for i := sl.level - 1; i &gt;= 0; i-- &#123; for cur.level[i].forward != nil &amp;&amp; cur.level[i].forward.Lt(targetNode) &#123; cur = cur.level[i].forward &#125; update[i] = cur &#125; // 目标节点找到后，这里需要判断下 elem 是否相等 // score 可以重复，所以必须要谨慎 nodeToBeDeleted := update[0].level[0].forward if nodeToBeDeleted == nil || !nodeToBeDeleted.Eq(targetNode) &#123; return nil &#125; sl.deleteNode(update, nodeToBeDeleted) return nodeToBeDeleted&#125;func (sl *Skiplist) deleteNode(update [64]*Node, nodeToBeDeleted *Node) &#123; // 这时我们要删除的节点就是 nodeToBeDeleted // 调整每层待更新节点，修改 forward 指向 for i := 0; i &lt; sl.level; i++ &#123; if update[i].level[i].forward == nodeToBeDeleted &#123; update[i].level[i].forward = nodeToBeDeleted.level[i].forward update[i].level[i].span += nodeToBeDeleted.level[i].span - 1 &#125; else &#123; update[i].level[i].span-- &#125; &#125; // 调整回退指针： // 1. 如果被删除的节点是最后一个节点，需要更新 sl.tail // 2. 如果被删除的节点位于中间，则直接更新后一个节点 backward 即可 if sl.tail == nodeToBeDeleted &#123; sl.tail = nodeToBeDeleted.backward &#125; else &#123; nodeToBeDeleted.level[0].forward.backward = nodeToBeDeleted.backward &#125; // 调整层数 for sl.header.level[sl.level-1].forward == nil &#123; sl.level-- &#125; // 减少节点计数 sl.length-- nodeToBeDeleted.backward = nil nodeToBeDeleted.level[0].forward = nil&#125; 更新分数12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// UpdateScore 用于更新节点的分数。该函数会保证更新分数后，// 节点的有序性依然可以维持。// 策略如下：// 1. 快速判断能否原节点修改，如果可以则直接修改并返回；// 2. 采用更加昂贵的操作：删除再添加。func (sl *Skiplist) UpdateScore(curScore float64, elem string, newScore float64) *Node &#123; var ( update [MaxLevel]*Node targetNode = &amp;Node&#123;elem: elem, score: curScore&#125; ) cur := sl.header // 第一步，找到符合条件的目标节点 for i := sl.level - 1; i &gt;= 0; i-- &#123; for cur.level[i].forward != nil &amp;&amp; cur.level[i].forward.Lt(targetNode) &#123; cur = cur.level[i].forward &#125; update[i] = cur &#125; node := cur.level[0].forward if node == nil || !node.Eq(targetNode) &#123; return nil &#125; if sl.canUpdateScoreFor(node, newScore) &#123; node.score = newScore return node &#125; else &#123; // 需要删除旧节点，增加新节点 sl.deleteNode(update, node) return sl.Insert(newScore, node.elem) &#125;&#125;// canUpdateScoreFor 确定能否直接在原有的节点上进行修改// 什么条件才可以直接原地更新 score 呢？// 1. node 是唯一一个数据节点（node.backward == NULL &amp;&amp; node-&gt;level[0].forward == NULL）// 2. node 是第一个数据节点，且新的分数要比 node 之后节点分数要小（这样才能保证有序）// 即：node.backward == NULL &amp;&amp; node-&gt;level[0].forward-&gt;score &gt; newScore）// 3. node 是最后一个数据节点，且 node 之前节点的分数要比新改的分数小// 即：node-&gt;backward-&gt;score &lt; newScore &amp;&amp; node-&gt;level[0].forward == NULL// 4. node 是修改的后的分数恰好还能保证位于前一个和后一个节点分数之间// 即：node-&gt;backward-&gt;score &lt; newscore &amp;&amp; node-&gt;level[0].forward-&gt;score &gt; newscorefunc (sl *Skiplist) canUpdateScoreFor(node *Node, newScore float64) bool &#123; if (node.backward == nil || node.backward.score &lt; newScore) &amp;&amp; (node.level[0].forward == nil || node.level[0].forward.score &gt; newScore) &#123; return true &#125; return false&#125; 总结俗话说，「说起来容易，做起来难」。在实现「跳表」的时候感受颇深，似乎看完 Redis 的「跳表」源码和网上诸多前辈编写的文章后，自以为懂得了原理（可能确实懂了），但是在具体实现的时候还是踩了不少坑。比如，空指针引起 panic；i-- 写成了 i++ 导致查找失败；一些边界情况的判断等。总之，细节决定成败，需要在保持思路清晰的同时，更加谨慎一些才能写出足够健壮的代码来。当然，这期间自然少不了单元测试的助攻，否则有很多问题可能都没法暴露出来~ 参考 漫画：什么是跳表？ Redis 为什么用跳表而不用平衡树？]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Go</tag>
        <tag>Redis</tag>
        <tag>跳表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 5 源码初探]]></title>
    <url>%2F2019%2F12%2F08%2Fprimitive-exploration-of-redis5%2F</url>
    <content type="text"><![CDATA[引言Redis, REmote DIctionary Server 因其高效、简单、丰富的数据结构支持、高性能、持久化和集群支持等特性得到了程序员们的青睐，并被广泛部署和应用在众多互联网公司。而因为它采用了比较简单的文本协议，使得客户端实现比较简单，因此也拥有众多编程语言实现的客户端；甚至也有一些其它类型的 K-V 数据库兼容了 Redis 协议！ 结合我们目前的业务来看，有非常多的场景使用到了 Redis： 记录用户通知、短信发送标志，避免重复发送； 使用 Redis 集合维护一些白名单用户表； 为支持快速获得用户会员时长等基本信息，将这些信息在 Redis 集群中也维护了一份，并采取相关措施维持与 MySQL 数据库的最终一致性。 当然还有很多场景可以例举，但就我们常使用的 Redis 数据结构来看，主要就是字符串、集合（有序/无序）、字典、列表等。虽说 Redis 给我们提供了其它丰富的内存数据结构，但是我们在生产环境用到的并不多。 既然 Redis 这么重要，自然很有必要花时间去研究下 Redis，并阅读它的源码来学习它的一些设计思想，编程风格等。不得不说，Redis 官方文档非常给力，源码注释很充分，代码风格、质量都是非常一流的。 我们已经了解了 Redis 是什么？为什么那么重要？接下来就是怎么来学习它？然后是期望达成什么样的目标？ 首先，《Redis 设计与实现》 和 《Redis 5 设计与源码分析》 将作为学习 Redis 源码的主要参考书籍（「站在巨人的肩膀上」）；其次是阅读下 Redis 官方文档中比较重要的部分；当然，最后且最重要的是自己要认真阅读源码。 最后一个问题，期望在学习完 Redis 达成的目标，我想主要有如下几点： 培养阅读知名开源项目源码的耐心，掌握阅读源码的技巧和工具； 加深对 Redis 的理解，了解它的架构设计； 掌握 Redis 常用的数据结构设计思想，并能在实际项目中合理运用各种数据结构实现需求； 吸收精髓，提升自身的技术水平，业余时间还可以尝试折腾个简单的数据库。 Redis 特点第一个值得称道的特点就是高性能，Redis 的高性能得益于如下几点原因： 它是基于内存的数据库，内存的读写速度很快； 拥有合理设计的内存数据结构，增删改查很简单，并且能够高效利用内存； 使用了 I/O 多路复用的机制（select, poll, epoll, kqueue），高效处理高并发的网络连接； 采用了单进程模型（Redis Server 会有多个线程），且只有一个线程专门处理网络请求，避免线程调度带来的上下文切换开销、多线程同步开销（如加锁、释放锁等）。 除此之外，还有如下特点： &lt;key, value&gt; 中的 value 除了普通的字符串，还支持复杂的数据类型（如集合、字典、位图等）； 支持数据持久化，可在重启后恢复，支持 AOF、RDB 和 AOF + RDB 三种持久化方案； 支持主从结构，从节点可做数据备份，也可对外提供读服务； 支持集群。 源码概览后面的源码学习会基于 Redis 最新的稳定版 5.0.7，参见仓库：https://github.com/iFaceless/redis/tree/5.0，源码注释会推送到该仓库的 comment-src 分支下。 关于 Redis 源码的结构，在 Redis 的 README.md 中有所介绍。具体来说，有如下几个重要的目录： src: Redis 核心实现（C 语言） tests: 单元测试代码（Tcl 语言） deps: Redis 依赖的一些库。其中包含 jemalloc 源码，它是 Redis 在 Linux 下默认的内存分配库，用来替代标准库 malloc，以期减少内存分配碎片 server.hserver.h 中定义了 Redis Server 需要用到的一些数据结构，其中 struct redisServer 维护了 Redis 服务端配置和共享状态，几个比较重要的字段如下： db: 表示 Redis 数据库，用来存储数据 commands: 命令表 clients: 连接到当前服务器的客户端链表 master: replica 节点 master 客户端 另外一个重要的数据结构是 redisClient，用来表示客户端。这里给介绍几个重要的字段： 12345678910111213struct client &#123; int fd; // 存放客户端请求 sds querybuf; int argc; robj **argv; redisDb *db; int flags; // reply &amp; buf 维护服务端要发给客户端的回复队列，当底层的 fd 可写时，会以渐进地方式发送缓冲区数据 list *reply; char buf[PROTO_REPLY_CHUNK_BYTES]; ... many other fields ...&#125; 还有一个比较重要的数据结构是 robj，它表示一个 Redis 对象，在 Redis 内部实现中有很多地方在使用，它的定义如下： 1234567891011// redisObject 基本上可以表示所有常用的 Redis 数据类型（lists, sets, strings 等）typedef struct redisObject &#123; // type 表示具体的数据类型 unsigned type:4; unsigned encoding:4; unsigned lru:LRU_BITS; /* lru time (relative to server.lruclock) */ // refcount 表示对象引用次数，借助引用计数的方式，避免为重复对象分配内存 int refcount; // ptr 指向底层的真正的对象表示，结合 `encoding` 进行解析 void *ptr;&#125; robj; server.cRedis Server 启动的入口定义在此处（参见 main 函数）。下面是 Redis Server 启动时需要进行的重要步骤： initServerConfig() 用来配置 struct server 的默认值 initServer() 分配一些必要的数据结构、配置监听的 socket 等 aeMain() 启动 Event Loop，监听新的连接 Event Loop 中会周期调用的两个特殊函数如下： serverCron() 会被周期调用（参考 server.hz 配置的频率），执行一些周期性的任务，如检查客户端超时等 beforeSleep() 会在每次进入事件驱动库主循环时调用，也就是在睡眠等待 ready 的文件描述符之前 在 server.c 中还有几个函数专门处理其它类型的重要任务： call() 会在指定的客户端上下文中执行指定命令时被使用 activeExpireCycle() 用来处理过期的 keys freeMemoryIfNeeded() 当 Redis 内存使用超过 maxmemory 指定的值，且有新的写入进来时，会执行该函数清理内存 redisCommandTable 维护了所有 Redis 命令，其中包含每个命令的名称、回调函数、参数个数及其它属性 networking.c在这个文件中定义了所有的 I/O 函数，用来和客户端、master 及 replicas 交互： createClient() 初始化新的客户端 addReply*() 函数族用于给客户端添加响应数据 writeToClient() 用于将输出缓冲区的数据发送给客户端，它会被 sendReplyToClient() 调用 readQueryFromClient() 用于聚集从客户端读取的数据到查询缓冲区 processInputBuffer() 是从客户端查询缓冲区（query buffer）根据 Redis 协议解析查询命令的入口函数。一旦命令可以处理了，就会调用 processCommand() 来真正执行命令 freeClient() 释放客户端 aof.c 和 rdb.c顾名思义，这是 Redis 两种持久化方案的具体实现文件。Redis 的持久化模型比较有趣，它会通过 fork() 系统调用创建一个单独的线程，并能访问主线程共享的内存区域；接下来这个备份线程会将内存内容持久化到磁盘中。rdb.c 在创建快照时会使用这种机制；aof.c 在执行 AOF 重写（避免 Append Only 文件过大）时也会用到这个机制。 db.cdb.c 中定义了一些通用的操作命令，它们都是针对 key 进行的操作，而非对应的数据，比如 DEL 和 EXPIRE 等。此外，db.c 中还提供了一些特殊的 API 用于在 Redis 数据集上执行某些操作时，不用访问内部具体的数据结构。 以下是许多命令实现中都会用到的函数： lookupKeyRead() 和 lookupKeyWrite() 用于基于指定 key 得到对应值的指针，如果 key 不存在，则返回 NULL dbAdd() 及更抽象的函数 setKey() 是用来在 Redis 中创建新的 key dbDelete() 移除 key 及关联的 value emptyDb() 移除指定的数据库或者所有的数据库 object.cstruct robj 是 Redis 对象的定义，在 object.c 中有很多应用于 Redis 对象的操作，其中比较关键的函数如下： incrRefcount() 和 decrRefCount() 维护对象的引用计数。当引用值为 0 时才会真正释放对象 createObject() 用于分配新的对象。此外，还有一些针对特殊内容分配字符串对象的函数，如 createStringObjectFromLongLong() 等 replication.creplication.c 文件中实现了 master 和 replica 角色。但这块内容比较复杂，建议对 Redis 其它部分代码有所了解后再来学习它。 该文件中有个比较重要的函数 replicationFeedSlaves()，它用来将命令发送给从节点，从而保证和主节点数据同步。在该文件中还实现了 SYNC 和 PSYNC 命令，它们用于从节点初次初始化同步，或者在连接断开并重连后继续保持同步。 其它 t_hash.c, t_list.c, t_set.c, t_string.c 和 t_zset.c 是 Redis 数据类型的底层实现 ae.c Redis 事件循环实现 sds.c Redis 动态变长字符串 anet.c 对内核提供的网络接口做了封装，从而能够以更加简单的方式使用 POSIX 网络接口 dict.c 非阻塞、渐进 rehash 字典实现 scripting.c 实现了 Luc 脚本 cluster.c Redis 集群实现。在了解这块代码前，记得参考下 Redis 集群说明 思维导图 构建 &amp; 调试Redis 官方文档中有关于构建和运行它的详细说明，我们也可以使用 gdb 进行调试。但是，作为一个 IDE 死忠党，自然是要在 Clion 中构建和调试 Redis 的。需要注意的是，Clion 使用了 cmake 来管理项目，所以我们需要在 Redis 源码根目录下为它创建好 CMakeLists.txt 才能进行构建。具体可参考 使用 Clion 来调试 Redis 源码 这篇文章~ 在完成上一步后，切到 src 目录下，执行 ./mkreleasehdr.sh 脚本生成 src/release.h 文件，否则构建可能会失败。然后在源码目录下执行： 1cmake . 接下来，我们可以在 Clion 打开 src/server.c ，并找到 main 函数，点击工具栏中的运行或调试按钮，或者点击 main 函数左侧的按钮选择运行或调试。 Redis 服务启动时，默认会使用 6379 端口，也可以在 Clion 中配置参数，使用自定义的端口等： 至此，我们已经可以使用 Clion 来阅读、运行或者调试 Redis 代码啦。有了神器助攻，便于我们通过调试工具追踪调用链，并了解执行步骤中各个中间状态。 参考 Redis README Clion 调试 Redis 源码 使用 Clion 来调试 Redis 源码 《Redis 5 设计与源码分析》]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>源码学习</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gcache 源码学习]]></title>
    <url>%2F2019%2F12%2F03%2Fgcache-code-analysis%2F</url>
    <content type="text"><![CDATA[引言Redis, REmote DIctionary Server 因其高效、简单、丰富的数据结构支持、高性能、持久化和集群支持等特性得到了程序员们的青睐，并被广泛部署和应用在众多互联网公司。而因为它采用了比较简单的文本协议，使得客户端实现比较简单，因此也拥有众多编程语言实现的客户端；甚至也有一些其它类型的 K-V 数据库兼容了 Redis 协议！ 结合我们目前的业务来看，有非常多的场景使用到了 Redis： 记录用户通知、短信发送标志，避免重复发送； 使用 Redis 集合维护一些白名单用户表； 为支持快速获得用户会员时长等基本信息，将这些信息在 Redis 集群中也维护了一份，并采取相关措施维持与 MySQL 数据库的最终一致性。 当然还有很多场景可以例举，但就我们常使用的 Redis 数据结构来看，主要就是 string, set, zset, list, hash map。虽说 Redis 给我们提供了其它丰富的内存数据结构，但是我们在生产环境用到的并不多。 既然 Redis 这么重要，自然很有必要花时间去研究下 Redis，并阅读它的源码来学习它的一些设计思想，编程风格等。不得不说，Redis 官方文档非常给力，源码注释很充分，代码风格、质量都是非常一流的。 我们已经了解了 Redis 是什么？为什么那么重要？接下来就是怎么来学习它？然后是期望达成什么样的目标？ 首先，《Redis 设计与实现》 和 《Redis 5 设计与源码分析》 将作为学习 Redis 源码的主要参考书籍（「站在巨人的肩膀上」）；其次是阅读下 Redis 官方文档中比较重要的部分；当然，最后且最重要的是自己要认真阅读源码。 最后一个问题，期望在学习完 Redis 达成的目标，我想主要有如下几点： 培养阅读知名开源项目源码的耐心，掌握阅读源码的技巧和工具； 加深对 Redis 的理解，了解它的架构设计； 掌握 Redis 常用的数据结构设计思想，并能在实际项目中合理运用各种数据结构实现需求； 吸收精髓，提升自身的技术水平，业余时间还可以尝试折腾个简单的数据库。 Redis 特点Redis 之所以能够有很高的性能，主要有如下几点原因： 它是基于内存的数据库，内存的读写速度很快； 拥有合理设计的内存数据结构，增删改查很简单，并且能够高效利用内存； 使用了 I/O 多路复用的机制（select, poll, epoll, kqueue），高效处理高并发的网络连接； 采用了单进程模型（Redis Server 会有多个线程），且只有一个线程专门处理网络请求，避免线程调度带来的上下文切换开销、多线程同步开销（如加锁、释放锁等）。 除此之外，还有如下特点： &lt;key, value&gt; 中的 value 除了普通的字符串，还支持复杂的数据类型（如集合、字典、位图等）； 支持数据持久化，可在重启后恢复，支持 AOF、RDB 和 AOF + RDB 三种持久化方案； 支持主从结构，从节点可做数据备份，也可对外提供读服务； 支持集群。 源码概览后面的源码学习会基于 Redis 最新的稳定版 5.0.7，参见仓库：https://github.com/iFaceless/redis/tree/5.0，源码注释会推送到该仓库的 comment-src 分支下。 关于 Redis 源码的结构，在 Redis 的 README.md 中有所介绍。具体来说，有如下几个重要的目录： src: Redis 核心实现（C 语言） tests: 单元测试代码（Tcl 语言） deps: Redis 依赖的一些库。其中包含 jemalloc 源码，它是 Redis 在 Linux 下默认的内存分配库，用来替代标准库 malloc，以期减少内存分配碎片 server.hserver.h 中定义了 Redis Server 需要用到的一些数据结构，其中 struct redisServer 维护了 Redis 服务端配置和共享状态，几个比较重要的字段如下： db: 表示 Redis 数据库，用来存储数据 commands: 命令表 clients: 连接到当前服务器的客户端链表 master: replica 节点 master 客户端 另外一个重要的数据结构是 redisClient，用来表示客户端。这里给介绍几个重要的字段： 12345678910111213struct client &#123; int fd; // 存放客户端请求 sds querybuf; int argc; robj **argv; redisDb *db; int flags; // reply &amp; buf 维护服务端要发给客户端的回复队列，当底层的 fd 可写时，会以渐进地方式发送缓冲区数据 list *reply; char buf[PROTO_REPLY_CHUNK_BYTES]; ... many other fields ...&#125; 还有一个比较重要的数据结构是 robj，它表示一个 Redis 对象，在 Redis 内部实现中有很多地方在使用，它的定义如下： 1234567891011// redisObject 基本上可以表示所有常用的 Redis 数据类型（lists, sets, strings 等）typedef struct redisObject &#123; // type 表示具体的数据类型 unsigned type:4; unsigned encoding:4; unsigned lru:LRU_BITS; /* lru time (relative to server.lruclock) */ // refcount 表示对象引用次数，借助引用计数的方式，避免为重复对象分配内存 int refcount; // ptr 指向底层的真正的对象表示，结合 `encoding` 进行解析 void *ptr;&#125; robj; server.cRedis Server 启动的入口定义在此处（参见 main 函数）。下面是 Redis Server 启动时需要进行的重要步骤： initServerConfig() 用来配置 struct server 的默认值 initServer() 分配一些必要的数据结构、配置监听的 socket 等 aeMain() 启动 Event Loop，监听新的连接 Event Loop 中会周期调用的两个特殊函数如下： serverCron() 会被周期调用（参考 server.hz 配置的频率），执行一些周期性的任务，如检查客户端超时等 beforeSleep() 会在每次进入事件驱动库主循环时调用，也就是在睡眠等待 ready 的文件描述符之前 在 server.c 中还有几个函数专门处理其它类型的重要任务： call() 会在指定的客户端上下文中执行指定命令时被使用 activeExpireCycle() 用来处理过期的 keys freeMemoryIfNeeded() 当 Redis 内存使用超过 maxmemory 指定的值，且有新的写入进来时，会执行该函数清理内存 redisCommandTable 维护了所有 Redis 命令，其中包含每个命令的名称、回调函数、参数个数及其它属性 networking.c在这个文件中定义了所有的 I/O 函数，用来和客户端、master 及 replicas 交互： createClient() 初始化新的客户端 addReply*() 函数族用于给客户端添加响应数据 writeToClient() 用于将输出缓冲区的数据发送给客户端，它会被 sendReplyToClient() 调用 readQueryFromClient() 用于聚集从客户端读取的数据到查询缓冲区 processInputBuffer() 是从客户端查询缓冲区（query buffer）根据 Redis 协议解析查询命令的入口函数。一旦命令可以处理了，就会调用 processCommand() 来真正执行命令 freeClient() 释放客户端 aof.c 和 rdb.c顾名思义，这是 Redis 两种持久化方案的具体实现文件。Redis 的持久化模型比较有趣，它会通过 fork() 系统调用创建一个单独的线程，并能访问主线程共享的内存区域；接下来这个备份线程会将内存内容持久化到磁盘中。rdb.c 在创建快照时会使用这种机制；aof.c 在执行 AOF 重写（避免 Append Only 文件过大）时也会用到这个机制。 db.cdb.c 中定义了一些通用的操作命令，它们都是针对 key 进行的操作，而非对应的数据，比如 DEL 和 EXPIRE 等。此外，db.c 中还提供了一些特殊的 API 用于在 Redis 数据集上执行某些操作时，不用访问内部具体的数据结构。 以下是许多命令实现中都会用到的函数： lookupKeyRead() 和 lookupKeyWrite() 用于基于指定 key 得到对应值的指针，如果 key 不存在，则返回 NULL dbAdd() 及更抽象的函数 setKey() 是用来在 Redis 中创建新的 key dbDelete() 移除 key 及关联的 value emptyDb() 移除指定的数据库或者所有的数据库 object.cstruct robj 是 Redis 对象的定义，在 object.c 中有很多应用于 Redis 对象的操作，其中比较关键的函数如下： incrRefcount() 和 decrRefCount() 维护对象的引用计数。当引用值为 0 时才会真正释放对象 createObject() 用于分配新的对象。此外，还有一些针对特殊内容分配字符串对象的函数，如 createStringObjectFromLongLong() 等 replication.creplication.c 文件中实现了 master 和 replica 角色。但这块内容比较复杂，建议对 Redis 其它部分代码有所了解后再来学习它。 该文件中有个比较重要的函数 replicationFeedSlaves()，它用来将命令发送给从节点，从而保证和主节点数据同步。在该文件中还实现了 SYNC 和 PSYNC 命令，它们用于从节点初次初始化同步，或者在连接断开并重连后继续保持同步。 其它 t_hash.c, t_list.c, t_set.c, t_string.c 和 t_zset.c 是 Redis 数据类型的底层实现 ae.c Redis 事件循环实现 sds.c Redis 动态变长字符串 anet.c 对内核提供的网络接口做了封装，从而能够以更加简单的方式使用 POSIX 网络接口 dict.c 非阻塞、渐进 rehash 字典实现 scripting.c 实现了 Luc 脚本 cluster.c Redis 集群实现。在了解这块代码前，记得参考下 Redis 集群说明 思维导图 构建 &amp; 调试Redis 官方文档中有关于构建和运行它的详细说明，我们也可以使用 gdb 进行调试。但是，作为一个 IDE 死忠党，自然是要在 Clion 中构建和调试 Redis 的。需要注意的是，Clion 使用了 cmake 来管理项目，所以我们需要在 Redis 源码根目录下为它创建好 CMakeLists.txt 才能进行构建。具体可参考 使用 Clion 来调试 Redis 源码 这篇文章~ 在完成上一步后，切到 src 目录下，执行 ./mkreleasehdr.sh 脚本生成 src/release.h 文件，否则构建可能会失败。然后在源码目录下执行： 1cmake . 接下来，我们可以在 Clion 打开 src/server.c ，并找到 main 函数，点击工具栏中的运行或调试按钮，或者点击 main 函数左侧的按钮选择运行或调试。 Redis 服务启动时，默认会使用 6379 端口，也可以在 Clion 中配置参数，使用自定义的端口等： 至此，我们已经可以使用 Clion 来阅读、运行或者调试 Redis 代码啦。有了神器助攻，便于我们通过调试工具追踪调用链，并了解执行步骤中各个中间状态。 参考 Redis README Clion 调试 Redis 源码 使用 Clion 来调试 Redis 源码 《Redis 5 设计与源码分析》]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>缓存</tag>
        <tag>LRU</tag>
        <tag>LFU</tag>
        <tag>ARC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go 语言中如何以优雅的姿势实现对象序列化？]]></title>
    <url>%2F2019%2F11%2F28%2Fportal%2F</url>
    <content type="text"><![CDATA[引言在我们的 Web 后端项目中，通常将数据源获取相关的结构体定义放在 models.go 中，不管其关联的数据是来自于数据库、Redis 还是 RPC，总之都是收敛在这一层以提供更好的复用性。 而针对不同的场景，如 C 端 HTTP API 要求返回的数据，则定义对应的 Schema struct，从而聚合需要的数据下发出去。当然，对于 Admin API 和 RPC API 也会根据需要定义不同的 Schema struct。但是，它们都会复用相同的 models。想必这些应该都是比较常规的操作了吧。但在实际使用中，也遇到了诸多问题： API Schema 的字段类型和 Model 中定义的不同（比如我们使用发号器获得的 ID 在 Model struct 中定义的是 int64，但是为了避免 json.Marshal 时溢出（浏览器截断），统一返回了 string 类型的 ID），就需要手动进行类型转换； API Schema 的字段名称和 Model 中定义的可能不同； 支持灵活的 Schema 字段过滤比较麻烦，不同的项目实现可能不同； 在某些情况下，如课程 API Schema 关联的一些数据来自于其它服务（需要通过 RPC 调用），这时如果能够并发加载就有提高接口响应速度的可能，但是需要每次在应用层重新实现（当然可以再抽一层出来，不过还是很麻烦，会有心智负担）。 …… 那么，有没有更加优雅的解决办法呢？ 怎么解决？ 🤔我们之前在使用 Python 项目开发时，使用到了 marshmallow 这个轻量级的对象序列化框架。当然，它不仅仅提供序列化的能力，还有反序列化以及字段校验的能力。如果能够恰当的使用它，是可以提升开发效率的。如果在 Go 语言社区中存在这样一个框架的话，它是可以解决上面提到的一些问题的。 在经过一番思想斗争后，斗胆实现了一个类似的框架 portal 用于解决上面提到的一些问题。portal 聚焦于以优雅且一致的方式处理对象序列化的问题；而对于 Struct Fields 的校验问题，我们可以直接使用已有的第三方库如 go-playground/validator 或 asaskevich/govalidator。 目前来说，核心功能均已按照最初的设计实现了，主要功能如下： 提供简洁易用的 API 接口 支持非常灵活的字段过滤能力（任意深度的嵌套字段过滤） 自动尝试类型转换，远离手动编写太多没什么灵魂的类型转换代码（早点下班不好吗？） 支持并发填充字段值： 可手动指定哪些字段异步加载 可设置全局的 goroutine 池大小 使用 PORTAL可以通过下面的方式安装该包： 1get get -u github.com/ifaceless/portal 第一步：定义 Model 结构体 12345678910111213141516171819202122232425262728293031323334353637type NotificationModel struct &#123; ID int Title string Content string&#125;type UserModel struct &#123; ID int&#125;func (u *UserModel) Fullname() string &#123; // 名称甚至可以来自 RPC 调用等，只是一个示例 return fmt.Sprintf("user:%d", u.ID)&#125;// Notifications 返回用户关联的一些通知信息列表func (u *UserModel) Notifications() (result []*NotificationModel) &#123; for i := 0; i &lt; 1; i++ &#123; result = append(result, &amp;NotificationModel&#123; ID: i, Title: fmt.Sprintf("title_%d", i), Content: fmt.Sprintf("content_%d", i), &#125;) &#125; return&#125;type TaskModel struct &#123; ID int UserID int Title string&#125;// User 返回 Task 关联的用户是谁func (t *TaskModel) User() *UserModel &#123; return &amp;UserModel&#123;t.UserID&#125;&#125; 第二步：定义 API Schema 结构体 以下 Schema 在定义时，都添加了 json tag，并且标记为 omitempty。这样做的目的是，当我们选择过滤某些字段的时候，portal 就不会填充对应的 Schema Fields。因此，标记了 omitempty 的字段在 json.Marshal 后就不会出现，从而达到字段过滤的目的。 12345678910111213141516171819202122232425262728293031type NotiSchema struct &#123; ID string `json:"id,omitempty"` Title string `json:"title,omitempty"` Content string `json:"content,omitempty"`&#125;type UserSchema struct &#123; ID string `json:"id,omitempty"` // 名称是从 User.Fullname() 方法中获取，我们把它称为 User 的一个属性，使用 `attr` 标记 Name string `json:"name,omitempty" portal:"attr:Fullname"` // nested 表明该字段的值是一个复合类型，portal 会自动将 notifications 数据填充到对应的 schema 列表 Notifications []*NotiSchema `json:"notifications,omitempty" portal:"nested"` AnotherNotifications []*NotiSchema `json:"another_notifications,omitempty" portal:"nested;attr:Notifications"`&#125;type TaskSchema struct &#123; ID string `json:"id,omitempty"` Title string `json:"title,omitempty"` Description string `json:"description,omitempty" portal:"meth:GetDescription"` // UserSchema is a nested schema User *UserSchema `json:"user,omitempty" portal:"nested"` // We just want `Name` field for `SimpleUser`. // Besides, the data source is the same with `UserSchema` SimpleUser *UserSchema `json:"simple_user,omitempty" portal:"nested;only:Name;attr:User"`&#125;// GetDescription 我们可以通过自定义方法来提供想要的数据// 一个常见的场景是，我们可以在自定义方法中根据用户状态返回不同的文案func (ts *TaskSchema) GetDescription(model *model.TaskModel) string &#123; return "Custom description"&#125; 第三步：按需序列化1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package mainimport ( "encoding/json" "github.com/ifaceless/portal")func main() &#123; // log debug info portal.SetDebug(true) // set max worker pool size portal.SetMaxPoolSize(1024) // make sure to clean up. defer portal.CleanUp() // write to a specified task schema var taskSchema schema.TaskSchema portal.Dump(&amp;taskSchema, &amp;taskModel) // data: &#123;"id":"1","title":"Finish your jobs.","description":"Custom description","user":&#123;"id":"1","name":"user:1","notifications":[&#123;"id":"0","title":"title_0","content":"content_0"&#125;],"another_notifications":[&#123;"id":"0","title":"title_0","content":"content_0"&#125;]&#125;,"simple_user":&#123;"name":"user:1"&#125;&#125; data, _ := json.Marshal(taskSchema) // select specified fields portal.Dump(&amp;taskSchema, &amp;taskModel, portal.Only("Title", "SimpleUser")) // data: &#123;"title":"Finish your jobs.","simple_user":&#123;"name":"user:1"&#125;&#125; data, _ := json.Marshal(taskSchema) // select fields with alias defined in the json tag. // actually, the default alias tag is `json`, `portal.FieldAliasMapTagName("json")` is optional. portal.Dump(&amp;taskSchema, &amp;taskModel, portal.Only("title", "SimpleUser"), portal.FieldAliasMapTagName("json")) // data: &#123;"title":"Finish your jobs.","simple_user":&#123;"name":"user:1"&#125;&#125; data, _ := json.Marshal(taskSchema) // you can keep any fields for any nested schemas // multiple fields are separated with ',' // nested fields are wrapped with '[' and ']' portal.Dump(&amp;taskSchema, &amp;taskModel, portal.Only("ID", "User[ID,Notifications[ID],AnotherNotifications[Title]]", "SimpleUser")) // data: &#123;"id":"1","user":&#123;"id":"1","notifications":[&#123;"id":"0"&#125;],"another_notifications":[&#123;"title":"title_0"&#125;]&#125;,"simple_user":&#123;"name":"user:1"&#125;&#125; data, _ := json.Marshal(taskSchema) // ignore specified fields portal.Dump(&amp;taskSchema, &amp;taskModel, portal.Exclude("Description", "ID", "User[Name,Notifications[ID,Content],AnotherNotifications], SimpleUser")) // data: &#123;"title":"Finish your jobs.","user":&#123;"id":"1","notifications":[&#123;"title":"title_0"&#125;]&#125;&#125; data, _ := json.Marshal(taskSchema) // dump multiple tasks var taskSchemas []schema.TaskSchema portal.Dump(&amp;taskSchemas, &amp;taskModels, portal.Only("ID", "Title", "User[Name]")) // data: [&#123;"id":"0","title":"Task #1","user":&#123;"name":"user:100"&#125;&#125;,&#123;"id":"1","title":"Task #2","user":&#123;"name":"user:101"&#125;&#125;] data, _ := json.Marshal(taskSchema)&#125; 以上仅仅是 PORTAL 的一些简单场景的应用，详细可以查看完整示例，在使用指南中提供了一些详细的使用说明。 核心 API123456func New(opts ...Option) (*Chell, error)func Dump(dst, src interface&#123;&#125;, opts ...Option) error func DumpWithContext(ctx context.Context, dst, src interface&#123;&#125;, opts ...Option)func SetDebug(v bool)func SetMaxPoolSize(size int)func CleanUp() 关于并发加载的策略 当某个 Schema 结构体字段标记了 portal:&quot;async&quot; 标签时会异步填充字段值； 当序列化 Schema 列表时，会分析 Schema 中有无标记了 async 的字段，如果存在的话，则使用并发填充策略；否则只在当前 goroutine 中完成序列化； 可以在 Dump 时添加 portal.DisableConcurrency() 禁用并发序列化的功能。 FAQQ: 为什么需要全局 worker pool 存在？A: 考虑到在 Web 服务中，每个请求过来都会启动一个新的 goroutine 处理。而在处理请求中，如果不限制 PORTAL 并发加载字段值时的 goroutine 数量，可能会导致非常严重的资源消耗问题。所以这里使用了 ants 框架。 Q: 性能 v.s 开发效率？A:其实引入这种框架，势必会对接口处理时的内存占用，处理性能产生影响。因为内部实现中也不可避免地大量使用了反射。所以，如果你追求的是高性能的话，那还是不推荐使用了。就我们的应用场景来说，很多接口的 QPS 并不高（尤其是一些后台接口），不管是 CPU 还是内存资源都是充足的。这个时候使用 PORTAL 是可以有效提高开发效率的（个人愚见），毕竟可以少写一些代码，让机器干些蠢活脏活。 Q: 实际项目中是如何使用 portal 的？有什么体会？带来了什么收益？A:历经将近一个月的实际项目实践，portal 目前已经趋于稳定，并且修复了大量问题，发布了 22 个版本。目前该工具包应应用在多个线上服务中（包括 HTTP RESTful API 和 RPC 中 Model 到 thrift 定义类型的映射），整体感受就是开发体验成倍提高，而且带来了性能影响并没有最开始认为的那么大。 总结个人认为，框架的引入正是为了提高开发效率，提升项目质量的。框架层的抽象和封装可以让我们不用每次都在业务代码层编写重复机械式的代码，同时能够保证编写方式的一致性，提升项目的可维护性。所谓的性能问题，也许根本不是问题；所谓的提前优化，也许只是过度优化。我们应该用 20% 时间解决 80% 的常规问题，并且是高效率高质量的那种。而剩下 20% 的难题，完全可以用别的方法解决。切勿本末倒置！]]></content>
      <categories>
        <category>Web 开发</category>
      </categories>
      <tags>
        <tag>Go</tag>
        <tag>对象序列化</tag>
        <tag>Web API</tag>
        <tag>portal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文学习之 Linux 调度器]]></title>
    <url>%2F2019%2F11%2F17%2Fguide-to-linux-scheduler%2F</url>
    <content type="text"><![CDATA[引言Linux Kernel Development 一书中，关于 Linux 的进程调度器并没有讲解的很深入，只是提到了 CFS 调度器的基本思想和一些实现细节；并没有 Linux 早期的调度器介绍，以及最近这些年新增的在内核源码树外维护的调度器思想。所以在经过一番搜寻后，看到了这篇论文 A complete guide to Linux process scheduling，对 Linux 的调度器历史进行了回顾，并且相对细致地讲解了 CFS 调度器。整体来说，虽然比较啰嗦，但是对于想要知道更多细节的我来说非常适合，所以就有了翻译它的冲动。当然，在学习过程也参考了其它论文。下面开启学习之旅吧~ 需要注意的是，在 Linux 中，线程和进程都是由同一个结构体（task_struct，即任务描述符）表示的，所以文中会交叉使用进程、线程和任务等术语，可以将它们视作同义词。当然，也可以将线程（任务）称为最小执行单元。但 Linux 的调度算法（如 CFS）可以应用更加通用的调度单元（如线程、cgroup、用户等）。总之，不要过度纠结这里的术语，重要的是了解每种调度算法的思想！ 为什么需要调度Linux 是一个多任务的操作系统，这就意味着它可以「同时」执行多个任务。在单核处理器上，任意时刻只能有一个进程可以执行（并发）；而在多核处理器中，则允许任务并行执行。然而，不管是何种硬件类型的机器上，可能同时还有很多在内存中无法得到执行的进程，它们正在等待运行，或者正在睡眠。负责将 CPU 时间分配给进程的内核组件就是「进程调度器」。 调度器负责维护进程调度顺序，选择下一个待执行的任务。如同多数其它的现代操作系统，Linux 实现了抢占式多任务机制。也就是说，调度器可以随时决定任意进程停止运行，而让其它进程获得 CPU 资源。这种违背正在运行的进程意愿，停止其运行的行为就是所谓的「抢占」。抢占通常可以在定时器中断时发生，当中断发生时，调度器会检查是否需要切换任务，如果是，则会完成进程上下文切换。每个进程所获得的运行时间叫做进程的时间片（timeslice）。 任务通常可以区分为交互式（I/O 密集型）和非交互式（CPU 密集型）任务。交互式任务通常会重度依赖 I/O 操作（如 GUI 应用），并且通常用不完分配给它的时间片。而非交互式任务（如数学运算）则需要使用更多的 CPU 资源。它们通常会用完自己的时间片之后被抢占，并不会被 I/O 请求频繁阻塞。 当然，现实中的应用程序可能同时包含上述两种分类任务。例如，文本编辑器，多数情况下，它会等待用户输入，但是在执行拼写检查时也会需要占用大量 CPU 资源。 操作系统的调度策略就需要均衡这两种类型的任务，并且保证每个任务都能得到足够的执行资源，而不会对其它任务产生明显的性能影响。 Linux 为了保证 CPU 利用率最大化，同时又能保证更快的响应时间，倾向于为非交互式任务分配更大的时间片，但是以较低的频率运行它们；而针对 I/O 密集型任务，则会在较短周期内频繁地执行。 调度有关的进程描述符进程描述符（task_struct）中的很多字段会被调度机制直接使用。以下仅列出一些核心的部分，并在后文详细讨论。1234567891011struct task_struct &#123; int prio, static_prio, normal_prio; unsigned int rt_priority; const struct sched_class *sched_class; struct sched_entity se; struct sched_rt_entity rt; … unsigned int policy; cpumask_t cpus_allowed; …&#125;; 关于这些字段的说明如下： prio 表示进程的优先级。进程运行时间，抢占频率都依赖于这些值。rt_priority 则用于实时（real-time）任务； sched_class 表示进程位于哪个调度类； sched_entity 的意义比较特殊。通常把一个线程（Linux 中的进程、任务同义词）叫作最小调度单元。但是 Linux 调度器不仅仅只能够调度单个任务，而且还可以将一组进程，甚至属于某个用户的所有进程作为整体进行调度。这就允许我们实现组调度，从而将 CPU 时间先分配到进程组，再在组内分配到单个线程。当引入这项功能后，可以大幅度提升桌面系统的交互性。比如，可以将编译任务聚集成一个组，然后进行调度，从而不会对交互性产生明显的影响。这里再次强调下，**Linux 调度器不仅仅能直接调度进程，也能对调度单元（schedulable entities）进行调度。这样的调度单元正是用 struct sched_entity 来表示的。需要说明的是，它并非一个指针，而是直接嵌套在进程描述符中的。当然，后面的谈论将聚焦在单进程调度这种简单场景。由于调度器是面向调度单元设计的，所以它会将单个进程也视为调度单元，因此会使用 sched_entity 结构体操作它们。sched_rt_entity 则是实时调度时使用的。 policy 表明任务的调度策略：通常意味着针对某些特定的进程组（如需要更长时间片，更高优先级等）应用特殊的调度决策。Linux 内核目前支持的调度策略如下： SCHED_NORMAL：普通任务使用的调度策略； SCHED_BATCH：不像普通任务那样被频繁抢占，可允许任务运行尽可能长的时间，从而更好地利用缓存，但是代价自然是损失交互性能。这种非常适合批量任务调度（批量的 CPU 密集型任务）; SCHED_IDLE：它要比 nice 19 的任务优先级还要低，但它并非真的空闲任务; SCHED_FIFO 和 SCHED_RR 是软实时进程调度策略。它们是由 POSIX 标准定义的，由 &lt;kernel/sched/rt.c&gt; 里面定义的实时调度器负责调度。RR 实现的是带有固定时间片的轮转调度方式；SCHED_FIFO 则使用的是先进先出的队列机制。 cpus_allowed：用来表示任务的 CPU 亲和性。用户空间可以通过 sched_setaffinity 系统调用来设置。 优先级 Priority进程优先级普通任务优先级所有的类 Unix 操作系统都实现了优先级调度机制。它的核心思想就是给任务设定一个值，然后通过该值决定任务的重要程度。如果任务的优先级一致，则一次重复运行它们。在 Linux 中，每一个普通任务都被赋予了一个 nice 值，它的范围是 -20 到 +19，任务默认 nice 值是 0。 nice 值越高，任务优先级越低（it’s nice to others）。Linux 中可以使用 nice(int increment) 系统调用来修改当前进程的优先级。该系统调用的实现位于 &lt;kernel/shced/core.c&gt; 中。默认情况下，用户只能为该用户启动的进程增加 nice 值（即降低优先级）。如果需要增加优先级（减少 nice 值），或者修改其它用户进程优先级，则必须以 root 身份操作。 实时任务优先级在 Linux 中，除了普通任务外，还有一类任务属于实时任务。实时任务是确保它们能够在一定时间范围内执行的任务，有两类实时任务，列举如下： 硬实时任务：会有严格的时间限制，任务必须在时限内完成。比如直升机的飞控系统，就需要及时响应驾驶员的操控，并做出预期的动作。然而，Linux 本身并不支持硬实时任务，但是有一些基于它修改的版本，如 RTLinux（它们通常被称为 RTOS）则是支持硬实时调度的。 软实时任务：软实时任务其实也会有时间限制，但不是那么严格。也就是说，任务晚一点运行任务，并不会造成不可挽回的灾难性事故。实践中，软实时任务会提供一定的时间限制保障，但是不要过度依赖这种特性。例如，VOIP 软件会使用软实时保障的协议传来送音视频信号，但是即便因为操作系统负载过高，而产生一点延迟，也不会造成很大影响。无论如何，软实时任务总会比普通任务的优先级更高。 Linux 中实时任务的优先级范围是 0~99，但是有趣的是，它和 nice 值的作用刚好相反，这里的优先级值越大，就意味着优先级越高。 类似其它的 Unix 系统，Linux 也是基于 POSIX 1b 标准定义的 「Real-time Extensions」实现实时优先级。可以通过如下的命令查看系统中的实时任务： 1$ ps -eo pid, rtprio, cmd 也可通过 chrt -p pid 查看单个进程的详情。Linux 中可以通过 chrt -p prio pid 更改实时任务优先级。这里需要注意的是，如果操作的是一个系统进程（通常并不会将普通用户的进程设置为实时的），则必须有 root 权限才可以修改实时优先级。 内核视角下的进程优先级实时上，内核看到的任务优先级和用户看到的并不相同，在计算和管理优先级时也需要考虑很多方面。Linux 内核中使用 0~139 表示任务的优先级，并且，值越小，优先级越高（注意和用户空间的区别）。其中 0~99 保留给实时进程，100~139（映射成 nice 值就是 -20~19）保留给普通进程。 我们可以在 &lt;include/linux/sched/prio.h&gt; 头文件中看到内核表示进程优先级的单位（scale）和宏定义（macros），它们用来将用户空间优先级映射到到内核空间。1234567891011121314151617181920212223#define MAX_NICE 19#define MIN_NICE -20#define NICE_WIDTH (MAX_NICE - MIN_NICE + 1)…#define MAX_USER_RT_PRIO 100#define MAX_RT_PRIO MAX_USER_RT_PRIO#define MAX_PRIO (MAX_RT_PRIO + NICE_WIDTH)#define DEFAULT_PRIO (MAX_RT_PRIO + NICE_WIDTH / 2)/** Convert user-nice values [ -20 ... 0 ... 19 ]* to static priority [ MAX_RT_PRIO..MAX_PRIO-1 ],* and back.*/#define NICE_TO_PRIO(nice) ((nice) + DEFAULT_PRIO)#define PRIO_TO_NICE(prio) ((prio) - DEFAULT_PRIO)/** 'User priority' is the nice value converted to something we* can work with better when scaling various scheduler parameters,* it's a [ 0 ... 39 ] range.*/#define USER_PRIO(p) ((p)-MAX_RT_PRIO)#define TASK_USER_PRIO(p) USER_PRIO((p)-&gt;static_prio)#define MAX_USER_PRIO (USER_PRIO(MAX_PRIO)) 优先级计算在 task_struct 中有几个字段用来表示进程优先级：12int prio, static_prio, normal_prio;unsigned int rt_priority; static_prio 是由用户或系统设定的「静态」优先级映射成内核表示的优先级：1p-&gt;static_prio = NICE_TO_PRIO(nice_value); normal_prio 存放的是基于 static_prio 和进程调度策略（实时或普通）决定的优先级，相同的静态优先级，在不同的调度策略下，得到的正常优先级是不同的。子进程在 fork 时，会继承父进程的 normal_prio。 prio 则是「动态优先级」，在某些场景下优先级会发生变动。一种场景就是，系统可以通过给某个任务优先级提升一段时间，从而抢占其它高优先级任务，一旦 static_prio 确定，prio 字段就可以通过下面的方式计算：12345678910111213141516171819202122232425262728293031p-&gt;prio = effective_prio(p);// kernel/sched/core.c 中定义了计算方法static int effective_prio(struct task_struct *p)&#123; p-&gt;normal_prio = normal_prio(p); /* * If we are RT tasks or we were boosted to RT priority, * keep the priority unchanged. Otherwise, update priority * to the normal priority: */ if (!rt_prio(p-&gt;prio)) return p-&gt;normal_prio; return p-&gt;prio;&#125;static inline int normal_prio(struct task_struct *p)&#123; int prio; if (task_has_dl_policy(p)) prio = MAX_DL_PRIO-1; else if (task_has_rt_policy(p)) prio = MAX_RT_PRIO-1 - p-&gt;rt_priority; else prio = __normal_prio(p); return prio;&#125;static inline int __normal_prio(struct task_struct *p)&#123; return p-&gt;static_prio;&#125; 负载权重（Load Weights）优先级会让一些任务比别的任务更重要，因此也会获得更多的 CPU 使用时间。nice 值和时间片的比例关系是通过负载权重（Load Weights）进行维护的，我们可以在 task_struct-&gt;se.load 中看到进程的权重，定义如下：12345678struct sched_entity &#123; struct load_weight load; /* for load-balancing */ …&#125;struct load_weight &#123; unsigned long weight; u32 inv_weight;&#125;; 为了让 nice 值的变化反映到 CPU 时间变化片上更加合理，Linux 内核中定义了一个数组，用于映射 nice 值到权重：12345678910static const int prio_to_weight[40] = &#123; /* -20 */ 88761, 71755, 56483, 46273, 36291, /* -15 */ 29154, 23254, 18705, 14949, 11916, /* -10 */ 9548, 7620, 6100, 4904, 3906, /* -5 */ 3121, 2501, 1991, 1586, 1277, /* 0 */ 1024, 820, 655, 526, 423, /* 5 */ 335, 272, 215, 172, 137, /* 10 */ 110, 87, 70, 56, 45, /* 15 */ 36, 29, 23, 18, 15,&#125;; 来看看如何使用上面的映射表，假设有两个优先级都是 0 的任务，每个都能获得 50% 的 CPU 时间（1024 / (1024 + 1024) = 0.5）。如果突然给其中的一个任务优先级提升了 1 （nice 值 -1）。此时，一个任务应该会获得额外 10% 左右的 CPU 时间，而另一个则会减少 10% CPU 时间。来看看计算结果：1277 / (1024 + 1277) ≈ 0.55，1024 / (1024 + 1277) ≈ 0.45，二者差距刚好在 10% 左右，符合预期。完整的计算函数定义在 &lt;kernel/sched/core.c&gt; 中：123456789101112131415static void set_load_weight(struct task_struct *p)&#123; int prio = p-&gt;static_prio - MAX_RT_PRIO; struct load_weight *load = &amp;p-&gt;se.load; /* * SCHED_IDLE tasks get minimal weight: */ if (p-&gt;policy == SCHED_IDLE) &#123; load-&gt;weight = scale_load(WEIGHT_IDLEPRIO); load-&gt;inv_weight = WMULT_IDLEPRIO; return; &#125; load-&gt;weight = scale_load(prio_to_weight[prio]); load-&gt;inv_weight = prio_to_wmult[prio];&#125; 调度类 Scheduling Classes虽说 Linux 内核使用的 C 语言并非所谓的 OOP 语言（没有类似 C++/Java 中的 class 概念），但是我们可以在内核代码中看到一些使用 C 语言结构体 + 函数指针（Hooks）的方式来模拟面向对象的方式，抽象行为和数据。调度类也是这样实现的（此外，还有 inode_operations, super_block_operations 等），它的定义如下（位于 &lt;kernel/shced/sched.h&gt;）：1234567891011121314151617181920212223242526// 为了简单起见，隐藏了部分代码（如 SMP 相关的）struct sched_class &#123; // 多个 sched_class 是链接在一起的 const struct sched_class *next; // 该 hook 会在任务进入可运行状态时调用。它会将调度单元（如一个任务）放到 // 队列中，同时递增 `nr_running` 变量（该变量表示运行队列中可运行的任务数） void (*enqueue_task) (struct rq *rq, struct task_struct *p, int flags); // 该 hook 会在任务不可运行时调用。它会将任务移出队列，同时递减 `nr_running` void (*dequeue_task) (struct rq *rq, struct task_struct *p, int flags); // 该 hook 可以在任务需要主动放弃 CPU 时调用，但是需要注意的是，它不会改变 // 任务的可运行状态，也就是说依然会在队列中等待下次调度。类似于先 dequeue_task， // 再 enqueue_task void (*yield_task) (struct rq *rq); // 该 hook 会在任务进入可运行状态时调用并检查是否需要抢占当前任务 void (*check_preempt_curr) (struct rq *rq, struct task_struct *p, int flags); // 该 hook 用来选择最适合运行的下一个任务 struct task_struct * (*pick_next_task) (struct rq *rq, struct task_struct *prev); // 该 hook 会在任务修改自身的调度类或者任务组时调用 void (*set_curr_task) (struct rq *rq); // 通常是在时钟中断时调用，可能会导致任务切换 void (*task_tick) (struct rq *rq, struct task_struct *p, int queued); // 当任务被 fork 时通知调度器 void (*task_fork) (struct task_struct *p); // 当任务挂掉时通知调度器 void (*task_dead) (struct task_struct *p);&#125;; 关于调度策略的具体细节的实现有如下几个模块： core.c 包含调度器的核心部分； fair.c 实现了 CFS（Comple Faire Scheduler，完全公平任务调度器） 调度器，应用于普通任务； rt.c 实现了实时调度，应用于实时任务； idle_task.c 当没有其它可运行的任务时，会运行空闲任务。内核是基于任务的调度策略（SCHED_*）来决定使用何种调度类实现，并会调用相应的方法。SCHED_NORMAL, SCHED_BATCH 和 SCHED_IDLE 进程会映射到 fair_sched_class （由 CFS 实现）；SCHED_RR 和 SCHED_FIFO 则映射的 rt_sched_class （实时调度器）。 运行队列 Run Queue所有可运行的任务是放在运行队列中的，并且等待 CPU 运行。每个 CPU 核心都有自己的运行队列，每个任务任意时刻只能处于其中一个队列中。在多处理器机器中，会有负载均衡策略，任务就会转移到其它 CPU 上运行的可能。 运行队列数据结构定义如下（位于 &lt;kernel/sched/sched.h&gt;）:1234567891011121314151617181920// 为了简单起见，隐藏了部分代码（SMP 相关）// 这个是每个 CPU 都会有的一个任务运行队列struct rq&#123; // 表示当前队列中总共有多少个可运行的任务（包含所有的 sched class） unsigned int nr_running;#define CPU_LOAD_IDX_MAX 5 unsigned long cpu_load[CPU_LOAD_IDX_MAX]; // 运行队列负载记录 struct load_weight load; // 嵌套的 CFS 调度器运行队列 struct cfs_rq cfs; // 嵌套的实时任务调度器运行队列 struct rt_rq rt; // curr 指向当前正在运行的进程描述符 // idle 则指向空闲进程描述符（当没有其它可运行任务时，该任务才会启动） struct task_struct *curr, *idle; u64 clock; int cpu;&#125; 何时运行调度器？实时上，调度函数 schedule() 会在很多场景下被调用。有的是直接调用，有的则是隐式调用（通过设置 TIF_NEED_RESCHED 来提示操作系统尽快运行调度函数）。以下三个调度时机值得关注下： 时钟中断发生时，会调用 scheduler_tick() 函数，该函数会更新一些和调度有关的数据统计，并触发调度类的周期调度方法，从而间接地进行调度。以 2.6.39 源码为例，可能的调用链路如下： 123456scheduler_tick└── task_tick └── entity_tick └── check_preempt_tick └── resched_task └── set_tsk_need_resched 当前正在运行的任务进入睡眠状态。在这种情况下，任务会主动释放 CPU。通常情况下，该任务会因为等待指定的事件而睡眠，它可以将自己添加到等待队列，并启动循环检查期望的条件是否满足。在进入睡眠前，任务可以将自己的状态设置为 TASK_INTERRUPTABLE（除了任务要等待的事件可唤醒外，也可以被信号唤醒）或者 TASK_UNINTERRUPTABLE（自然是不会理会信号咯），然后调用 schedule() 选择下一个任务运行。 睡眠的任务被唤醒。任务等待的事件可以在关联的等待队列上调用 wake_up() 函数唤醒任务：相关任务会将自己设置为可运行状态，并加入运行队列。如果当前唤醒的任务优先级比运行队列中的任何任务都高，则会设置 TIF_NEED_RESCHED 标志，从而让操作系统尽快调用 schedule() 函数。 Linux 调度器早期版本Linux 0.0.1 版本就已经有了一个简单的调度器，当然并非适合拥有特别多处理器的系统。该调度器只维护了一个全局的进程队列，每次都需要遍历该队列来寻找新的进程执行，而且对任务数量还有严格限制（NR_TASKS 在最初的版本中只有 32）。下面来看看这个调度器是如何实现的吧：1234567891011121314151617181920212223242526272829303132333435363738394041// 'schedule()' is the scheduler function. // This is GOOD CODE! There probably won't be any reason to change // this, as it should work well in all circumstances (ie gives // IO-bound processes good response etc)...void schedule(void)&#123; int i, next, c; struct task_struct **p; // 遍历所有任务，如果有信号，则需要唤醒 `TASK_INTERRUPTABLE` 的任务 for (p = &amp;LAST_TASK; p &gt; &amp;FIRST_TASK; --p) if (*p) &#123; if ((*p)-&gt;alarm &amp;&amp; (*p)-&gt;alarm &lt; jiffies) &#123; (*p)-&gt;signal |= (1 &lt;&lt; (SIGALRM - 1)); (*p)-&gt;alarm = 0; &#125; if ((*p)-&gt;signal &amp;&amp; (*p)-&gt;state == TASK_INTERRUPTIBLE) (*p)-&gt;state = TASK_RUNNING; &#125; while (1) &#123; c = -1; next = 0; i = NR_TASKS; p = &amp;task[NR_TASKS]; // 遍历所有任务，找到时间片最长的那个 while (--i) &#123; if (!*--p) continue; if ((*p)-&gt;state == TASK_RUNNING &amp;&amp; (*p)-&gt;counter &gt; c) c = (*p)-&gt;counter, next = i; &#125; if (c) break; // 遍历任务，重新设值时间片 for (p = &amp;LAST_TASK; p &gt; &amp;FIRST_TASK; --p) if (*p) (*p)-&gt;counter = ((*p)-&gt;counter &gt;&gt; 1) + (*p)-&gt;priority; &#125; // 切换到下一个需要执行的任务 switch_to(next);&#125; O(n)2.4 版本的 Linux 内核使用的调度算法非常简单和直接，由于每次在寻找下一个任务时需要遍历系统中所有的任务（链表），因此被称为 O(n) 调度器（时间复杂度）。 当然，该调度器要比 0.01 版本内核中的调度算法稍微复杂点，它引入了 epoch 概念。也就是将时间分成纪元（epochs），也就是每个进程的生命周期。理论上来说，每个纪元结束，每个进程都应该运行过一次了，而且通常用光了它当前的时间片。但实际上，有些任务并没有完全用完时间片，那么它剩余时间片的一半将会和新的时间片相加，从而在下一个纪元运行更长的时间。 我们来看下 schedule() 算法的核心源码：123456789101112131415161718192021222324// schedule() 算法会遍历所有的任务（O(N)），并且计算出每个任务的// goodness 值，且挑选出「最好」的任务来运行。// 以下是部分核心源码，主要是了解下它的思路。asmlinkage void schedule(void)&#123; // 任务（进程）描述符： // 1. prev: 当前正在运行的任务 // 2. next: 下一个将运行的任务 // 3. p: 当前正在遍历的任务 struct task_struct *prev, *next, *p; int this_cpu, c; // c 表示权重值repeat_schedule: // 默认选中的任务 next = idle_task(this_cpu); c = -1000; list_for_each(tmp, &amp;runqueue_head) &#123; p = list_entry(tmp, struct task_struct, run_list); if (can_schedule(p, this_cpu)) &#123; int weight = goodness(p, this_cpu, prev-&gt;active_mm); if (weight &gt; c) c = weight, next = p; &#125; &#125;&#125; 源码中的 goodness() 函数会计算出一个权重值，它的算法基本思想就是基于进程所剩余的时钟节拍数（时间片），再加上基于进程优先级的权重值。返回值如下： -1000 表示不要选择该进程运行 0 表示时间片用完了，需要重新计算 counters（可能会被选中运行） 正整数：表示 goodness 值（越大越好） +1000 表示实时进程，接下来就要选择它运行 最后，针对 O(n) 调度器做下总结： 算法实现非常简单，但是不高效（任务越多，遍历耗费时间越久） 没有很好的扩展性，多核处理器怎么办？ 对于实时任务调度支持较弱（无论如何作为优先级高的实时任务都需要在遍历完列表后才可以知道） O(1)Ingo Molnár 大佬在 2.6 版本的内核中加入了全新的调度算法，它能够在常数时间内调度任务，因此被称为 O(1) 调度器。我们来看看它引入的一些新特性： 全局优先级单位，范围是 0~139，数值越低，优先级越高 将任务拆分成实时（0~99）和正常（100~139）两部分。更高优先级任务获得更多时间片 即刻抢占（early preemption）。当任务状态变成 TASK_RUNNING 时，内核会检查其优先级是否比当前运行的任务优先级更高，如果是的话，则抢占当前正在运行的任务，切换到该任务 实时任务使用静态优先级 普通任务使用使用动态优先级。任务优先级会在其使用完自己的时间片后重新计算，内核会考虑它过去的行为，决定它的交互性等级。交互型任务更容易得到调度 O(n) 的调度器会在每个纪元结束后（所有任务的时间片都使用过），才会重新计算任务优先级。而 O(1) 则是在每个任务时间片配额用完后就重新计算优先级。O(1) 调度器为每个 CPU 维护了两个队列，即 active 和 expired。active 队列存放的是时间片尚未用完的任务，而 expired 则是时间片已经耗尽的任务。当一个任务的时间片用完后，就会被转到 expired 队列，而且会重新计算它的优先级。当 active 队列任务全部转移到 expired 队列后，会交换二者（让 active 指向 expired 队列，expired 指向 active 队列）。可以看到，优先级的计算，队列切换都和任务数量多寡无关，能够在 O(1) 时间复杂度下完成。 在先前介绍的调度算法中，如果想要取一个优先级最高的任务，还需要遍历整个任务链表才可以。而 O(1) 调度器则很特别，它为每种优先级提供了一个任务链表。所有的可运行任务会被分散在不同优先级队应的链表中。 接下来看看全新的 runqueue 是怎么定义的吧：123456struct runqueue &#123; unsigned long nr_running; /* 可运行的任务总数（某个 CPU） */ struct prio_array *active; /* 指向 active 的队列的指针 */ struct prio_array *expired; /* 指向 expired 的队列的指针 */ struct prio_array arrays[2]; /* 实际存放不同优先级对应的任务链表 */&#125; 通过下面的图可以直观感受下任务队列： 接下来看看 prio_array 是怎么定义的：12345struct prio_array &#123; int nr_active; /* 列表中的任务总数 */ unsigned long bitmap[BITMAP_SIZE]; /* 位图表示对应优先级链表是否有任务存在 */ struct list_head queue[MAX_PRIO]; /* 任务队列（每种优先级对应一个双向链表） */&#125;; 可以看到，在 prio_array 中存在一个位图，它是用来标记每个 priority 对应的任务链表是否存在任务的。接下来看看为何 O(1) 调度器可以在常数时间找到需要运行的任务： 常数时间确定优先级：首先会在位图中查找到第一个设置为 1 的位（总共有 140 bits，从第一个 bit 开始搜索，这样可以保证高优先级的任务先得到机会运行），如果找到了就可以确定哪个优先级有任务，假设找到后的值为 priority； 常数时间获得下一个任务：在 queue[priority] 对应的任务链表中提取第一个任务来执行（多个任务会轮转执行）。 好了，是时候总结下 O(1) 调度器的优缺点了： 设计上要比 O(n) 调度器更加复杂精妙； 相对来说扩展性更好，性能更优，在任务切换上的开销更小； 用来标记任务是否为交互类型的算法还是过于复杂，且容易出错。 StaircaseStaircase Scheduler 是 Con Kolivas 为了改善桌面系统交互应用的响应时间而实现的调度器，但它并非内核官方支持的调度器。它的整体设计思想类似于 Operating Systems: The Three Easy Pieces 中提到的 MLFQ（Multilevel Feedback Queue，多级反馈队列）。 我们来看下它的设计思想： 首先，它也是将任务按照优先级放在不同的任务链表中（类似上面的 active 队列） 调度器每次会从最高优先级的任务链表中获取一个要切换执行的任务，当任务时间片使用完毕后，会将其优先级调低一个等级，直到其优先级降到最低。 当处于最低优先级的任务用光了时间片后，它会被重新放到更高优先级的任务链表中（这个新的优先级是它之前最高优先级减 1 后的值），同时会获得两倍于之前的时间片 对于长时间睡眠的任务，会被放到最高优先级任务链表。所以交互式任务可以保持在最高优先级位置，从而保持良好的响应性能；而批处理任务则处于低优先级，但是会获得更多的执行时间。 CFS单核调度CFS 的全称是 Complete Fair Scheduler，也就是完全公平调度器。它实现了一个基于权重的公平队列算法，从而将 CPU 时间分配给多个任务（每个任务的权重和它的 nice 值有关，nice 值越低，权重值越高）。每个任务都有一个关联的虚拟运行时间 vruntime，它表示一个任务所使用的 CPU 时间除以其优先级得到的值。相同优先级和相同 vruntime 的两个任务实际运行的时间也是相同的，这就意味着 CPU 资源是由它们均分了。为了保证所有任务能够公平推进，每当需要抢占当前任务时，CFS 总会挑选出 vruntime 最小的那个任务运行。 内核版本在 2.6.38 之前，每个线程（任务）会被当成独立的调度单元，并且和系统中其它线程共享资源，这就意味着一个多线程的应用会比单线程的应用获得更多的资源。之后，CFS 不断改进，目前已经支持将一个应用中的线程打包到 cgroup 结构中，cgroup 的 vruntime 是其中所有线程的 vuntime 之和。然后 CFS 就可以将它的算法应用于cgroup 之间，从而保证公平性。当某个 cgroup 被选中后，其中拥有最小 vruntime 的线程会被执行，从而保证 cgroup 中的线程之间的公平性。cgroup 还可以嵌套，例如 systemd 会自动配置 cgroup 来保证不同用户之间的公平性，然后在用户运行的多个应用之间维持公平性。 CFS 通过在一定时间内运行调度所有的线程来避免饥饿问题。当运行的 线程数在 8 个及以下时，默认的时间周期是 48ms；而当多于 8 个线程时，时间周期就会随着线程数量而增加（6ms * 线程数，之所以选择 6ms，是为了避免频繁抢占，导致上下文切换频繁切换的开销）。由于 CFS 总是会挑选 vruntime 最小的线程执行，它就需要避免某个线程的 vruntime 太小，以至于其它线程需要等待很久才能得到调度（会有饥饿问题）。所以在实践中，CFS 会保证所有线程之间的 vruntime 之差低于抢占时间（6ms），它是通过如下两点来保证的： 当线程创建时，它的 vruntime 值等于运行队列中等待执行线程的最大 vruntime； 当线程从睡眠中唤醒时，它的 vruntime 值会被更新为大于或等于所有待调度线程中最小的 vruntime。使用最小 vruntime 还可以保证频繁睡眠的线程优先被调度，这对于桌面系统非常适合，它会减少交互应用的响应延迟。 CFS 还引入了启发式调度思想来改善高速缓存利用率。例如，当线程被唤醒时，它会检查该线程的 vruntime 和正在运行的线程 vruntime 之差是否非常显著（临界值是 1ms），如果不是的话，则不会抢占当前正在运行的任务。但是这种做法还是以牺牲调度延迟为代价的，算是一种权衡吧。 多核负载均衡在多核环境中，Linux CFS 会将工作（work）分摊到多个处理器核心中执行。但是这不等同于将线程均分到多个处理器。比如，一个 CPU 密集型的线程和 10 个频繁睡眠的线程可能分别在两个核上执行，其中一个专门执行 CPU 密集型线程；而另一个则处理那 10 个频繁睡眠的线程。 为了多个处理器上的工作量均衡，CFS 使用了 load 指标来衡量线程和处理器的负载情况。线程的负载和线程的 CPU 平均使用率相关：经常睡眠的线程负载要低于不睡眠的线程负载。类似 vruntime，线程的负载也是线程的优先级加权得到的。而处理器的负载是在该处理器上可运行线程的负载之和。CFS 会尝试均衡处理器的负载。 CFS 会在线程创建和唤醒时关注处理器的负载情况，调度器首先要决定将任务放在哪个处理器的运行队列中。这里也会涉及到启发式思想，比如，如果 CFS 检查到生产者-消费者模型，那么它会将消费者线程尽可能地分散到机器的多个处理器上，因为多数核心都适合处理唤醒的线程。 负载均衡还会周期性发生，每隔 4ms，每个处理器都会尝试从其它处理器偷取一些工作。当然，这种 work-stealing 均衡方法还会考虑机器的拓扑结构：处理器会尝试从距离它们「更近」的其它处理器上尝试窃取工作，而非距离「更远」的处理器（如远程 NUMA 节点）。当处理器决定要从其它处理器窃取任务时，它会尝试在二者之间均衡负载，并且会窃取多达 32 个线程。此外，当处理器进入空闲状态时，它也会立刻调用负载均衡器。 在大型的 NUMA 机器上，CFS 并不会粗暴地比较所有 CPU 的负载，而是以分层的方式进行负载均衡。以一台有两个 NUMA 节点的机器为例，CFS 会先在 NUMA 节点内部的处理器之间进行负载均衡，然后比较 NUMA 节点之间的负载（通过节点内部处理器负载计算得到），再决定要不要在两个节点之间进行负载均衡。如果 NUMA 节点之间的负载差距在 25% 以内，则不会进行负载均衡。总结来说，如果两个处理器（或处理器组）之间的距离越远，那么只有在不平衡性差距越大的情况下才会考虑负载均衡。 运行队列CFS 引入了红黑树（本质上是一棵半平衡二叉树，对于插入和查找都有 O(log(N)) 的时间复杂度）来维护运行队列，树的节点值是调度单元的 vruntime，拥有最小 vruntime 的节点位于树的最左下边。 接下来看看 cfs_rq 数据结构的定义（位于 &lt;kernel/sched/sched.h&gt;）：123456789101112131415struct cfs_rq&#123; // 所有任务的累计权重值 struct load_weight load; // 表示该队列中有多少个可运行的任务 unsigned int nr_running; // 运行队列中最小的 vruntime u64 min_vruntime; // 红黑树的根节点，指向运行任务队列 struct rb_root tasks_timeline; // 下一个即将被调度的任务 struct rb_node *rb_leftmost; // 指向当前正在运行的调度单元 struct sched_entity *curr;&#125; CFS 算法实际应用于调度单元（这是一个更通用的抽象，可以是线程、cgroups 等），调度单元数据结构定义如下（位于 &lt;include/linux/sched.h&gt;）：123456789101112131415161718struct sched_entity&#123; // 表示调度单元的负载权重（比如该调度单元是一个组，则该值就是该组下所有线程的负载权重的组合） struct load_weight load; /* for load-balancing */ // 表示红黑树的节点 struct rb_node run_node; // 表示当前调度单元是否位于运行队列 unsigned int on_rq; // 开始执行时间 u64 exec_start; // 总共运行的时间，该值是通过 `update_curr()` 更新的。 u64 sum_exec_runtime; // 基于虚拟时钟计算出该调度单元已运行的时间 u64 vruntime; // 用于记录之前运行的时间之和 u64 prev_sum_exec_runtime;&#125;; 虚拟时钟前面提到的 vruntime 究竟是什么呢？为什么叫作虚拟运行时间呢？接下来就要揭开它的神秘面纱。为了更好地实现公平性，CFS 使用了虚拟时钟来测量一个等待的调度单元在一个完全公平的处理器上允许执行的时间。然而，虚拟时钟并没有真实的实现，它只是一个抽象概念。 我们可以基于真实时间和任务的负载权重来计算出虚拟运行时间，该算法是在 update_cur() 函数中实现的，它会更新调度单元的时间记账信息，以及 CFS 运行队列的 min_vruntime（完整定义位于 &lt;kernel/sched/fair.c&gt;）：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647static void update_curr(struct cfs_rq *cfs_rq)&#123; struct sched_entity *curr = cfs_rq-&gt;curr; u64 now = rq_clock_task(rq_of(cfs_rq)); u64 delta_exec; if (unlikely(!curr)) return; // 计算出调度单元开始执行时间和当前之间的差值，即真实运行时间 delta_exec = now - curr-&gt;exec_start; curr-&gt;vruntime += calc_delta_fair(delta_exec, curr); update_min_vruntime(cfs_rq);&#125;static inline u64 calc_delta_fair(u64 delta, struct sched_entity *se)&#123; // 如果任务的优先级是默认的优先级（内部 nice 值是 120），那么虚拟运行时间 // 就是真实运行时间。否则，会基于 `__calc_delta` 计算出虚拟运行时间。 if (unlikely(se-&gt;load.weight != NICE_0_LOAD)) // 该计算过程基本等同于： // delta = delta_exec * NICE_0_LOAD / cur-&gt;load.weight; delta = __calc_delta(delta, NICE_0_LOAD, &amp;se-&gt;load); return delta;&#125;static void update_min_vruntime(struct cfs_rq *cfs_rq)&#123; u64 vruntime = cfs_rq-&gt;min_vruntime; if (cfs_rq-&gt;curr) // 如果此时有任务在运行，就更新最小运行时间为当前任务的 vruntime vruntime = cfs_rq-&gt;curr-&gt;vruntime; if (cfs_rq-&gt;rb_leftmost) &#123; // 获得下一个要运行的调度单元 struct sched_entity *se = rb_entry(cfs_rq-&gt;rb_leftmost, struct sched_entity, run_node); if (!cfs_rq-&gt;curr) vruntime = se-&gt;vruntime; else // 保证 min_vruntime 是二者之间较小的那个值 vruntime = min_vruntime(vruntime, se-&gt;vruntime); &#125; // 这里之所以去二者之间的最大值，是为了保证 min_vruntime 能够单调增长 // 可以想想为什么需要这样做？ cfs_rq-&gt;min_vruntime = max_vruntime(cfs_rq-&gt;min_vruntime, vruntime);&#125; 最后，来总结下使用虚拟时钟的意义： 当任务运行时，它的虚拟时间总是会增加，从而保证它会被移动到红黑树的右侧； 对于高优先级的任务，虚拟时钟的节拍更慢，从而让它移动到红黑树右侧的速度就越慢，因此它们被再次调度的机会就更大些。 选择下一个任务CFS 可以在红黑树中一直找到最左（leftmost）边的节点作为下一个运行的任务。但是真正实现 __pick_first_entity() 的函数其实并没有真正地执行查找（虽然可以在 O(log(N)) 时间内找到），我们可以看下它的定义（完整定义位于 &lt;kernel/sched/fair.c&gt;）：123456789struct sched_entity *__pick_first_entity(struct cfs_rq *cfs_rq)&#123; // 其实这里取的是缓存的 leftmost 节点 // 所以执行就会更快了 struct rb_node *left = cfs_rq-&gt;rb_leftmost; if (!left) return NULL; return rb_entry(left, struct sched_entity, run_node);&#125; 实时调度器Linux 实时任务调度器实现位于 &lt;kernel/sched/rt.c，对于系统而言，实时任务属于贵客，一旦存在实时任务需要调度，那就应当尽可能及时地为它们服务。对于实时任务而言，有两种调度策略存在： SCHED_FIFO: 这个其实就是一个先到先服务的调度算法。这类任务没有时间片限制，它们会一直运行直到阻塞或者主动放弃 CPU，亦或者被更高优先级的实时任务抢占。该类任务总会抢占 SCHED_NORMAL 任务。如果多个任务具有相同的优先级，那它们会以轮询的方式调度（也就是当一个任务完成后，会被放到队列尾部等待下次执行）； SCHED_RR: 这种策略类似于 SCHED_FIFO，只是多了时间片限制。相同优先级的任务会以轮询的方式被调度，每个运行的任务都会一直运行，直到其用光自己的时间片，或者被更高优先级的任务抢占。当任务的时间片用光后，它会重新补充能量，并被加入到队列尾部。默认的时间片是 100ms，可以在 &lt;include/linux/sched/rt.h&gt; 找到其定义。 实时任务的优先级是静态的，不会像之前提到的算法，会重新计算任务优先级。用户可以通过 chrt 命令更改任务优先级。 实现细节实时任务有自己的调度单元数据结构（位于 &lt;include/linux/sched.h&gt;），其定义如下：1234567891011struct sched_rt_entity&#123; struct list_head run_list; unsigned long timeout; unsigned long watchdog_stamp; unsigned int time_slice; struct sched_rt_entity *back; struct sched_rt_entity *parent; /* rq on which this entity is (to be) queued: */ struct rt_rq *rt_rq;&#125;; SCHED_FIFO 的时间片是 0，可以在 &lt;kernel/sched/rt.c&gt; 中看到具体定义：1234567891011121314151617181920212223242526272829303132int sched_rr_timeslice = RR_TIMESLICE;static unsigned int get_rr_interval_rt(struct rq *rq, struct task_struct *task)&#123; if (task-&gt;policy == SCHED_RR) return sched_rr_timeslice; else return 0;&#125;``` 而关于运行队列的定义如下：```c/* Real-Time classes' related field in a runqueue: */struct rt_rq&#123; // 所有相同优先级的实时任务都保存在 `active.queue[prio]` 链表中 struct rt_prio_array active; unsigned int rt_nr_running; struct rq *rq; /* main runqueue */&#125;;/** This is the priority-queue data structure of the RT scheduling class:*/struct rt_prio_array&#123; /* include 1 bit for delimiter */ // 类似 O(1) 调度器，使用位图来标记对应优先级的链表是否为空 DECLARE_BITMAP(bitmap, MAX_RT_PRIO + 1); struct list_head queue[MAX_RT_PRIO];&#125;; 类似于 CFS 中的 update_curr() 函数，update_curr_rt() 函数用来跟踪实时任务的 CPU 占用情况，收集一些统计信息，更新时间片等，但这里使用的是真实时间，而没有虚拟时间的概念。完整定义可以参考 kernel/sched/rt.c#L955。 BFS &amp; MuqSS关于 BFS 和 MuqSS 的精彩介绍可以参考 这篇文章，这里不再赘述。总体来说，BFS 是一个适用于桌面或移动设备的调度器，设计地比较简洁，用于改善桌面应用的交互性，减小响应时间，提升用户体验。它采用了全局单任务队列设计，不再让每个 CPU 都有独立的运行队列。虽然使用单个全局队列，需要引入队列锁来保证并发安全性，但是对于桌面系统而言，处理器通常都比较少，锁的开销基本可以忽略。BFS 每次会在任务链表中选择具有最小 virtual deadline 的任务运行。 MuqSS 是作者后来基于 BFS 改进的一款调度器，同样是用于桌面环境任务调度。它主要解决了 BFS 的两个问题： 每次需要在对应优先级链表中遍历查找需要执行任务，这个时间复杂度为 O(n)。所以新的调度器引入了跳表来解决该问题，从而将时间复杂度降低到 O(1)。 全局锁争夺的开销优化，采用 try_lock 替代 lock。 深入学习 《Linux 设计与实现 第三版》进程调度章节 A complete guide to Linux process scheduling Process Scheduling in Linux 内核文档：CFS Scheduler 设计 Linux 进程与线程：《Linux 系统编程手册 第 28 章及后续》 可以关注下和进程线程有关的系统调用 Pthread 线程是怎么在 Linux 中实现的 Linux 公平调度 对比了传统调度器和 CFS 的区别 简单介绍了 CFS 的实现 The Battle of Schedulers: FreeBSD ULE vs Linux CFS 重点可以看下关于 CFS 的简述 &amp; 负载均衡部分 可以简单看看 ULE 是的实现原理（interactive, batch queue），为什么可能会有饿死的情况 NUMA 架构深究 早期的 x86 是 Universal Memory Arch, UMA 架构 NUMA 架构出来后，访问不同内存地址，速度是有差别了，和硬件架构有很大关系 Kernel 调度系统 重点关注作者关于 CFS 列出的几个灵魂拷问 vruntime 在什么时候发生改变？ vruntime 初始值是怎么设定的？ 两个非常有意思的适合桌面使用的 Linux task 调度器: BFS 和 MuqSS]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>调度器</tag>
        <tag>CFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 调度器学习资料整理]]></title>
    <url>%2F2019%2F11%2F05%2Flinux-kernel-scheduler-papers%2F</url>
    <content type="text"><![CDATA[引言 系统中的 CPU 数量有限，而用户希望「同时」得到服务的进程（任务）常常会多于可用的 CPU 核数，这时就需要聪明的任务调度器来为我们实现 CPU 虚拟化，让每个进程都能得到服务。调度器需要照顾到任务的响应时间（否则用户会在敲击键盘后等很久，体验很渣），还要保证一定的周转时间（CPU 密集型的任务期望获得更多的连续运行时间，从而利用 CPU 缓存亲和性，频繁的任务切换会导致一些性能损失，尤其是现代系统 TLB miss, Page Fault 惩罚非常严重），同时还不能让某些低优先级的任务饿死。可见调度器是实现多任务的核心，现代操作系统必备。一直以来，各路 Linux Hackers 都希望能为 Linux 提供这样一个调度器，它能够在桌面系统上有较好的交互性，而在高负载的服务器上有较好的吞吐量。 以下列举一些学习资料，可以进一步了解！ 学习资料 论文：A complete guide to Linux process scheduling，这篇论文讲得比较好，准备翻译出来以供欣赏 GitBook: Process Scheduling in Linux 内核文档：Linux scheduler doc, CFS Linux 进程与线程：《Linux 系统编程手册 第 28 章及后续》 可以关注下和进程线程有关的系统调用 Pthread 线程是怎么在 Linux 中实现的 Linux 公平调度 The Battle of Schedulers: FreeBSD ULE vs Linux CFS 重点可以看下关于 CFS 的简述 &amp; 负载均衡部分 可以简单看看 ULE 是的实现原理（interactive, batch queue），为什么可能会有饿死的情况 NUMA 架构深究 早期的 x86 是 Universal Memory Arch, UMA 架构 NUMA 架构出来后，访问不同内存地址，速度是有差别了，和硬件架构有很大关系 Kernel 调度系统 重点关注作者关于 CFS 列出的几个灵魂拷问 vruntime 在什么时候发生改变？ vruntime 初始值是怎么设定的？]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>调度器</tag>
        <tag>CFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux Kernel Development 学习与总结]]></title>
    <url>%2F2019%2F10%2F30%2Flinux-kernel-dev-notes%2F</url>
    <content type="text"><![CDATA[引言最近抽时间把 Operating Systems: Three Easy Pieces 终于看完了（其实 2017 年就知道它了，没想到拖到了 2019 年 😅），全书分三个部分（虚拟化、并发、持久化）对操作系统的一些通用设计思想进行了介绍，学完后，对于进程、内存虚拟化、并发、文件系统有了更加深刻的认识。但是，真实的世界是什么样子的呢？这就是希望在阅读《Linux 设计与实现》（Linux Kernel Development）后找到想要的答案。当然，在学习中也针对很多部分搜集了不少学习资料，整理在文后，方便加深理解。在学习之前，思考了一些问题，可以在学习中探索这些问题的答案： Linux 中进程、线程是如何实现的？各种调度策略是什么样的？又是怎么实现的呢？ 并发问题肯定需要注意，Linux 中如何应对竞态条件 &amp; 数据竞争呢？各种常见的同步原语又是如何实现的？ Linux 的内存虚拟化是如何实现的？内存布局？虚拟地址空间？ 文件系统有很多，操作系统是怎么进行抽象，并对用户提供一致优雅的系统调用接口的呢？ Linux 内核中有哪些非常经典的算法和数据结构的应用？它们使用场景是什么？怎么实现的呢？ Linux 内核简介 说到 Linux，就不得不提到它的祖先 Unix 系统。Unix 在 1970 年左右被 Ken Thompson 首先在一台 PDP-7 机型上实现，而后移植到 PDP-11 机器上，1973 年它被使用 C 语言重写，提供了更加强大的可移植性。 经过多年发展，Unix 系统成为了一个强大、健壮且稳定的操作系统。其强大的根本原因如下： 简洁，仅提供数百个设计目标明确的系统调用； 所有的东西都被当作文件看待 很强的移植能力 进程创建非常迅速，拥有独特的 fork() 系统调用 拥有简单且稳定的进程间通信原语 Linux 是类 Unix 系统，它的实现和 Unix 也有一些大相径庭的方面，但是它依然继承了 Unix 的设计目标，保证了 API 的一致性（有品位的程序员都应该要学习这一思想）。 Linux 词汇一般用来指代内核。它的基础包括： 内核 C 库 工具集 系统的基本工具，如 Shell 什么是操作系统？宽泛的操作系统是指整个系统中负责完成最基本功能和系统管理的部分，包括内核、设备驱动、启动引导程序、命令行 Shell 或用户界面、文件管理工具和系统工具。内核则是那个最亮的仔，它通常由如下几个重要部分组成： 中断服务 任务调度程序 内存管理程序 网络 进程间通信等系统服务 Linux 的中断服务是不在进程上下文执行的，而是在一个与所有进程无关、专门的中断上下文执行。这样可以保证第一时间能够响应和处理中断请求，然后快速退出。 处理器在任意时间点活动可概括为以下三种之一： 运行在用户空间，执行用户进程 运行在内核空间，处于进程上下文，代表某个特定的进程执行（如某个系统调用） 运行在内核空间，处于中断上下文，与进程无关，处理特定的中断 微内核和宏内核这个是比较有趣的历史了，操作系统设计有两大主要阵营：微内核和宏内核。 微内核的功能划分成多个独立的过程，每个过程都是一个服务（C/S 模型，服务与内核交互）。系统采用 IPC 禁止互通消息，互换「服务」。服务的独立性可以避免一个服务失败殃及其它服务。模块化设计也非常适合热插拔。但是缺点就是 IPC 的开销多于函数调用（类比微服务的网络开销和在本地调用函数的开销）。 宏内核则是实用主义者喜欢的设计，它是比较简单的设计，整体上就是一个单独的过程，运行在一个单独的地址空间。内核之间的通信微不足道，性能高。 Linux 自然是宏内核设计，Linux 内核运行在单独的内核地址空间上。同时它也采纳了微内核的精华，使它成为模块化的、多线程的以及内核本身可调度的操作系统。 与传统 Unix 区别 支持动态加载内核模块（这个不是微内核宣称的好处吗？咱也有） 支持对称多处理机制（SMP） 内核可以抢占（preemptive）：任务可以有优先级 对多线程的支持很特别：内核不区分线程和一般的进程，对于内核而言，所有的进程都一样，只是其中的一些共享资源而已 具有设备类的面向对象的设备模型、热插拔事件，用户空间的设备文件系统（sysfs） 忽略了一些拙劣特性 自由：任何改变都必须要能通过简洁的设计及正确可靠的实现来解决现实中确实存在的问题 内核版本&lt;主版本&gt;.&lt;从版本&gt;.&lt;修订&gt;[.&lt;稳定版本号&gt;]，其中从版本号为偶数，则为稳定版本，否则为开发版本。 内核编译配置可以使用的配置方式如下： make config make menuconfig1 make gconfig 默认配置：make defconfig 验证和更新配置：make oldconfig 编译 直接编译：make 导出不关心的 info：make &gt;/dev/null 指定并行编译数量：make -j4 &gt;/dev/null 内核开发特点 不能使用标准 C 库 必须使用 GNU C（需要用到它的一些扩展特性） inline：通常将对时间要求比较高，函数本身比较短的定义成内联函数。在内核中，为了类型安全和易读性，优先使用 inline 函数，而非复杂的宏 内联编译：支持使用 asm() 嵌入汇编代码 分支声明：可以使用 likely() 和 unlikely() 声明分支是否经常出现或很少出现，指导编译器进行优化（要搞清楚，否则优化反而变成了拖累） 缺乏像用户空间中的内存保护机制 内核中发生内存错误会导致 oops，内核可能会死掉 内核中的内存是不分页的，每用掉一个字节，物理内存就减少一个字节 难以执行浮点数计算 不能像用户空间执行浮点数计算那样，可以通过 trap 的方式将整数模式转换到浮点数模式计算 内核不能完美支持浮点数计算，本身也无法陷入。非要执行的话，就需要手动保存和恢复浮点寄存器，非常麻烦 内核给每个进程只有一个很小的定长堆栈 用户空间的栈可以动态增长，可支持非常大的数据结构 内核栈的大小和体系结构有关（如 x86 可以是 4KB/8KB） 历史上来说，内核栈大小是两页，32 位是 8KB，64 位是 16KB；每个处理器都有自己的栈 由于要支持异步中断、抢占和 SMP，时刻需要注意并发安全和同步 考虑可移植性 保持字节序 64 位对齐 不假定字长和页面长度 进程管理进程 内核把进程的列表存放在 task list 双向链表中，每个 entry 的类型是 task_struct，被称为 process descriptor 通过 slab（更新的应该是 SLUB） 分配器分配 task_struct 结构体（对象复用和缓存着色），每个任务的 thread_info 位于内核栈的尾端，其中包含指向 task_struct 的指针及其它信息 进程通过 PID 进行区分，其值存放在 process descriptor 中。由于进程处理代码需要频繁访问 task_struct 信息，所以在 PowerPC 等机器上，有专门的寄存器存储了相应的指针；而在 x86 体系下，则是利用内核栈尾创建的 thread_info，并借助偏移计算间接查找 task_struct 结构体 进程状态： TASK_RUNNING TASK_INTERRUPTABLE TASK_UNINTERRUPTABLE __TASK_TRACED: 被其它进程跟踪的进程（如 ptrace 对调试程序进行跟踪） __TASK_STOPPED: 进程停止执行，没有投入运行也无法投入运行 所有的进程都是 PID 为 1 的 init 进程的后代，init 进程的描述符是作为 init_task 静态分配的（比较特殊） Unix 系统进程创建： 通过 fork() 拷贝当前进程创建一个子进程（区别父进程：有新的 PID，有某些资源和统计量） exec() 函数负责读取可执行文件并将其载入地址空间开始运行 写时拷贝：内核并非开始就复制整个进程地址空间，而是让父进程和子进程共享同一个拷贝，只有在需要写入的时候，数据才会被复制，从而拥有各自的拷贝。fork() 实际开销：复制父进程的页表，给子进程创建唯一的进程描述符 Linux 中的 fork() 和 vfork() 都是通过 clone() 系统调用实现的。vfork() 的特点是：不拷贝父进程的页表，且子进程作为父进程的单独线程在它的地址空间执行，父进程阻塞直到子进程退出或执行 exec() Linux 中的线程实现： 从内核角度看，没有线程的概念，所有的线程都当作进程看待，只是与其它进程共享某些资源。每个线程都拥有属于自己的 task_struct 其它系统中，线程被抽象成一种耗费资源较少的资源，运行迅速的执行单元 通过 clone(CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGHAND, 0); 创建线程 对比 fork() 实现：clone(SIGCHLD, 0) 对比 vfork() 实现：clone(CLONE_VFORK | CLONE_VM | SIGCHLD, 0) 内核线程： 内核通常需要在后台执行一些操作，这些任务可通过 kernel thread 完成。这种是运行在内核空间的标准进程 内核线程没有独立的地址空间，可被调度，可被抢占 进程终结： 通常通过 do_exit() 完成退出，期间会释放相关的资源，最终将进程状态设置为 EXIT_ZOMBIE，但是此时的内核栈、thread_info 和 task_struct 结构体还是存在的，从而给父进程提供信息 父进程获得已终结的子进程信息后（父进程可通过 wait() 系统调用收集信息），或者通知内核它不关注这些信息，才会释放剩余的内存空间 孤儿进程： 退出时永远处于僵死状态，白白浪费内存 解决办法就是在当前线程组寻找某个线程作为父亲，实在不行，就让 init 接盘 调度进程 多任务系统分为两类： 非抢占式多任务（cooperative multitasking） 抢占式多任务（preemptive multitasking） 进程调度策略会关心进程的优先级、时间片 Linux 中的进程分为普通进程和实时进程，其中前者的优先级在 (-20, +19），而后者则是 (0, 99)。此外，实时进程的优先级总是高于普通进程优先级的，所以普通进程的优先级映射过来就是 (100, 139) Linux 中可以通过 nice 调整进程的优先级，越小的值拥有越高的权重；反之，则权重越低（体现在时间片上） CFS 调度器 Linux 2.6 内核引入了 CFS 调度器（位于 sched/fair.c）作为普通进程的调度器，它是一个近乎完美的公平调度器（权衡周转时间和响应时间）。并非采用时间片进行分配，而是给进程分配了处理器使用的比重，从而确保进程调度中能够有恒定的公平性，从而将切换频率置于不断变动中 CFS 基于一个简单的理念：进程调度的效果应该等同于系统拥有一个完美的多任务处理器，每个进程都能获得 1/n_running 处理器时间 CFS 允许每个进程运行一段时间，循环轮转，总是选择 vruntime 最小的进程作为下一个执行。也就是说，是通过所有可运行经常总数为基础来计算出进程应该运行多久，而非依靠 nice 值来计算时间片（传统的做法就是这种） 调度器实现概要： sched_entity 结构体跟踪运行记账（其中包含 vruntime） 所有可运行的进程都位于一棵黑红树中（O(logN) 时间复杂度查找），并且每次都会从树的最左叶子节点上（leftmost）找到 vruntime 最小的那个进程运行（实时上，这个值是提前缓存好的） 调度器入口处会找到最高优先级的调度类，然后获取到谁是下一个该运行的进程 睡眠：进程会把自己标记成休眠状态，从可执行红黑树中溢出，并放入等待队列，调用 schedule() 执行一个其他进程 唤醒：进程被设置为可执行状态，从等待队列移除，添加到可执行红黑树 CFS 实现了如下几种调度策略： SCHED_NORMAL（以前叫做 SCHED_OTHER）：用于普通任务调度 SCHED_BATCH：并非像普通任务那样被频繁抢占，会尽可能允许任务运行足够长时间，从而利用上 CPU 亲和性以及更好地复用缓存 SCHED_IDLE：这种任务优先级比 nice 19 还要低 抢占 用户抢占（检查 need_resched 标识符）：从系统调用返回用户空间时；从中断处理返回用户空间时 内核抢占（thread_info 中存在 preemt_count 计数器，表示有没有锁被持有）：就是调度程序能够在内核任务执行期间被执行 只要重新调度是安全的（没有持有锁），内核就可以在任何时间抢占正在执行的任务 内核抢占时机： 中断处理程序正在执行，且返回内核空间之前 内核代码再次具有可抢占性时 内核任务显式调用 schedule() 内核中的任务阻塞（此时会导致调用 schedule()） 实时调度器 实时调度器是在 sched/rt.c 中实现的，它使用了 100 个运行队列（对应 1~99 任务优先级），实现了 SCHED_FIFO 和 SCHED_RR 策略。 SCHED_FIFO: 简单的先入先出调度算法，不依赖时间片 该级别任务比 SCHED_NORMAL 级别的进程先得到调度 一旦任务处于执行期间，就会一直执行下去；只有更高优先级的 SCHED_FIFO/SCHED_RR 任务才可以抢占 SCHED_RR: 类似 FIFO，但是每个任务会有分配的时间片，时间片耗尽后就要换其它任务执行 对于 FIFO 进程，高优先级始终抢占低优先级进程；低优先级进程不能抢占 SCHED_RR 进程，即便其耗尽了时间片 Linux 提供的是软实时工作方式，尽力使得进程能够在限定的时间到来前执行，但内核不保证总能满足这些进程的要求 调度器类调度器类需要实现一些 hooks，这样可以在需要的时候做合适的操作。部分 hooks 如下： enqueue_task dequeue_task yield_task check_preempt_cur pick_next_task set_curr_task task_tick 调度相关的 syscall 系统调用 描述 nice() 设置进程的 nice 值 sched_setscheduler() 设置调度策略 sched_getscheduler() 获取调度策略 sched_setparam() 设置实时优先级 sched_getparam() sched_rr_get_interval() 时间片值 sched_setaffinity() 设置处理器亲和力 sched_getaffinity() 获取进程处理器亲和力 shced_yield() 暂时让出处理器 系统调用众所周知，进程是在操作系统提供的用户空间运行的，而如果需要打开文件等操作，需要通过系统调用，陷入到内核态，由操作系统代替完成和硬件的交互，从而为进程提供服务。所以说，系统调用时在用户空间和进程和硬件设备之间的一个中间层。这个中间层的主要作用如下： 为用户空间提供硬件接口抽象 系统调用保证系统的安全和稳定 操作系统可以掌控进程的硬件访问意图，并且代劳 那么系统调用又是如何实现的呢？一句话总结为：当系统调用执行时，会陷入到内核，传递系统调用号和参数，执行正确的系统调用函数，并且把返回值带回用户空间。可见，系统调用非常特殊，完全不同于常规的函数调用，看起来非常 Hack。 接下来，通过几个问题，加深对上述描述的理解： 如何陷入到内核？通过软中断的方式实现，通过引发一个异常触发系统切换到内核态执行异常处理程序。 什么是系统调用号？在 Linux 中，每个系统调用都被赋予了一个编号，进程其实是通过系统调用号而不是名称来告知内核自己中意哪个系统调用的。 如何传递系统调用号？通过寄存器传递，在 x86 中，就是将系统调用号放在 eax 寄存器传递给内核的。 参数是如何传递的？ 第一种方式就是将参数放在寄存器中，一般来说系统调用参数不会很多。在 x86 中，可以用 ebx, ecx, edx, esi 和 edi 按顺序存放五个参数。 第二种方式就是将参数存放在用户空间内存中，并将参数指针存放在寄存器中。这种是为了应付参数超过 6 个情况。 返回值如何带给用户空间？当然也是通过寄存器来传递的，在 x86 中，可以使用 eax 寄存器。 内核数据结构 Linux 内核链表实现独树一帜。它是将链表塞入到数据结构，而非常规的那种在数据结构中塞入链表。 可以看下对比就知道为何特别了： 1234567891011121314151617// 常规定义方法struct node &#123; void *data; struct node *prev; struct node *next;&#125;// Linux 内核链表定义struct list_head &#123; struct list_head *prev; struct list_head *next;&#125;struct node &#123; void *data; struct list_head list; // 所有的 node 形成链表&#125; 这样，通用的链表操作就可以基于 struct list_head 来实现了。那如何和根据链表指针获得对应的 node 呢？答案是通过 container_of() 宏，实际上 C 语言中，一个给定结构体中的变量偏移在编译时就已经确定了，所以可以借此获得父结构中的任意变量：123#define container_of(ptr, type, member) (&#123; \ const typeof( ((type *)0)-&gt;member) *__mptr = (ptr); \ (type *)( (char *)__mptr - offsetof(type, member) );&#125;) 中断和中断处理 中断是各种硬件设备与处理器协同高效工作的方式之一。处理器执行指令的速度非常快，而一些外部设备则会慢很多；为了能够保证 CPU 不浪费时间轮询设备状态，而降低利用率，所以需要中断机制来通知 CPU。当处理器接收到中断后，会去执行已注册的相关中断处理程序。 需要注意的是，中断和前面提到的异常（Fault）是不同的： 中断通常是异步发生的，不考虑时钟同步； 异常则必须与处理器时钟同步，所以也被称为同步中断（如除 0 错误、缺页）。 Linux 中对于中断的响应和处理分成上半部和下半部。其中上半部会在接收到中断信号后快速完成必要工作的（有严格的时限），而更加繁重的任务则会在下半部执行。在上半部需要快速执行，且无法睡眠；但下半部则没有这样的限制。 无须重入Linux 中的中断处理不用考虑重入，因为当给定中断处理程序在执行时，对应中断线在所有处理器上被屏蔽，避免同一中断线接收另外的中断。这样做简化了中断处理程序的编写。 中断上下文所谓的中断上下文（interrupt context），就是在执行中断处理程序时，内核所处的上下文。中断上下文和进程上下文没有半毛钱关系，我们可以把它和进程上下文进行一番对比： 中断上下文 进程上下文 执行中断处理程序时，内核所处的上下文 内核代表进程执行（系统调用、运行内核线程）时，所处的操作模式 与进程无瓜，与 current 宏无瓜 可通过 current 宏关联当前进程 没有后备进程，无法睡眠，也不能调用会导致睡眠的函数 可睡眠，可调用调度程序 有严格的执行时限 没有非常严格的要求 下半部及推后执行的工作下半部就是执行和中断处理相关，但是中断处理程序中不会执行的工作。引入下半部的目的就是让中断处理程序尽可能地简短、快速，避免屏蔽中断太久，导致系统的响应能力和性能受到影响；而比较繁重的工作可以在下半部执行。 下半部主要实现方式： 软中断 对于时间要求严格，且能自己高效完成加锁的工作，可使用软中断（如网络、SCSI） 软中断执行期间，允许响应中断，但它自身不能睡眠 tasklet 基于软中断实现，同一个处理程序的多个实例不能再多个处理器同时运行 用途广泛，接口简单，性能不错 不能睡眠 工作队列中的工作可以交给内核线程推后执行（会在进程上下文执行），可以利用进程上下文的优势，且可以重新调度和睡眠 内核同步在进行内核编程时，时刻需要注意并发带来的问题，需要能够正确识别临界区，正确加锁、解锁，保证关键数据结构不被错误修改。那么有哪些情况能造成并发问题呢？ 中断：异步发生，会中断当前正在执行的代码 软中断和 tasklet：内核会在任意时刻唤醒软中断和 tasklet，打断当前正在执行的代码 内核抢占：内核中的任务可能被其它任务抢占 睡眠及与用户空间同步：在内核中执行的进程可能会睡眠，从而导致调度程序被唤醒，并运行新的用户进程 SMP：多个处理器会并行执行 定时器和时间管理内核需要在硬件（RTC 和 Timer）的帮助下才能计算和管理时间，内核通过已知的（这个时钟周期是可编程的，可确定的）时钟中断间隔来计算 wall time 和 jiffies（系统启动以来的节拍总数）。那么，在时钟中断发生时究竟会做哪些工作呢？以下给出一些会周期执行的工作： 更新系统运行时间和实际时间 对于 SMP 系统，需要均衡各处理器上的任务队列，如果运行队列负载不均衡，需要尽量让它们均衡 检查当前进程是否用尽了自己的时间片，如果时，则重新进行调度 运行超时的动态定时器 更新资源消耗和处理器时间统计值 内存管理页内核是把物理内存分页管理的，也就是说页（page）是最基本的管理单元。MMU 也是以页大小为单位转换虚拟地址到硬件地址的。不同的体系结构，页大小不同，一般 32 位系统是 4KB，64 位系统是 8KB。 区因为硬件存在限制，内核无法对所有的页一视同仁。因此需要把页划分成不同的区（zone），内核需要处理如下因为硬件缺陷而引起的内存寻址问题： 一些硬件只能用特定的内存地址执行 DMA 操作 一些体系结构的内存物理寻址范围比虚拟地址范围大 内核的分区有四种： ZONE_DMA：可执行 DMA 操作的页集合 ZONE_DMA32：同上，但仅限于 32 位设备 ZONE_NORMAL：能够正常映射的页 ZONE_HIGHMEM：高端内存区域，其中的页不能永久映射到内核地址空间（这里限于 32 位地址空间，64 位就不会有问题了） 页申请和释放 alloc_page(gfp_mask)：只分配一页，返回指向页结构的指针 alloc_pages(gfp_mask, order)：分配 2^order 个连续页 __get_free_page(gfp_mask)：只分配一页，返回指向其逻辑地址的指针 __get_free_pages(gfp_mask, order)：分配 2^order 个连续物理页，返回逻辑地址指针 get_zeroed_page(gfp_mask)：只分配一页，且填充 0 ，返回逻辑地址指针 __free_pages(struct page *page, unsinged int order) free_pages(unsigned long addr, unsinged int order) free_page(unsigned long addr) kmallocvoid *kmalloc(size_t size, gfp_t flags)，kmalloc() 类似于 malloc()，可以获得指定字节大小的内核内存，它分配得到的页的物理地址是连续的，所以虚拟地址也是连续的。void kfree(const void *ptr) 释放分配的内存空间 关于标记位，常用的是 GFP_KERNEL，允许睡眠，用于进程上下文空间；另外的 GFP_ATOMIC，则不可以睡眠，可用于进程上下文、中断处理程序、软中断、tasklet。 vmallocvmalloc() 类似 kmalloc()，不同的是，它分配的内存虚拟地址虽然是连续的，但是实际的物理地址无需连续。它通过分配非连续的物理内存，再「修正」页表，从而把内存映射到逻辑地址空间连续的区域。它需要专门的页表来完成连续虚拟地址到实际非连续物理地址的映射，开销较大，且容易引起 TLB 抖动，通常在内核中更倾向于使用 kmalloc()。 slab 层slab 层充当通用数据结构的缓存层的角色，它会为不同的对象划分成不同的高速缓存组，每组存放不同类型的对象。比如，存放 task_struct 和 inode 就分属于不同的组。kmalloc() 也是基于 slab 层之上，使用了一组通用高速缓存。 slab 分配器引入的目的： 避免频繁使用的对象需要频繁分配和释放，降低开销 频繁分配回收容易导致内存碎片，减少碎片问题 提高性能 部分缓存专属于某个处理器时，可以实现无锁分配和释放（tcmalloc） 虚拟文件系统（VFS）VFS 是 Linux 提供的一个文件系统抽象层，涵盖了任何文件系统的常用功能集和行为，从而支持各种实际的文件系统（如 NTFS, FAT, EXT4）。1用户空间 write() -&gt; VFS sys_write() -&gt; 文件系统的写方法 -&gt; 存储设备 Unix 文件系统传统抽象概念：File, DirectoryEntry, Index Node 和 Mount Point。Unix 文件的特点是面向字节流抽象设计的，具有简单、灵活的特性。在 Unix 中，目录也是普通文件，其列出了包含在目录中所有文件。 VFS 中的主要对象： 超级块对象，代表具体已安装的文件系统 索引节点对象，代表一个具体的文件 目录项对象，代表一个目录项，是路径的组成部分 文件对象，代表由进程打开的文件（其实它会指向目录项对象，而目录项对象才是真正表示已打开的实际文件，因为其中包含了指向 inode 的指针） 块 I/OLinux 中，设备分为三类： 块设备：支持随机访问固定大小的数据块，如硬盘、闪存 字符设备：以字符流的形式被访问，如键盘 网络设备 需要注意的是，针对块设备的请求会被操作系统挂起在 I/O 请求队列上，并且由 I/O 调度程序来管理请求队列。它会决定请求队列中的请求如何排序，以及何时发送到具体的块设备。之所以这么做，就是期望借助 I/O 调度程序，对请求进行合并和排序，从而有效提高系统的整体性能（也可能造成某些请求得不到公平对待，甚至出现饥饿的情况）。以下记录的是 Linux 中已经实现的几种 I/O 调度算法： Linus 电梯 支持向前和向后合并（通常都是这种居多） 有较好的全局吞吐量 会发生请求饥饿问题 最终期限（deadline） I/O 调度 降低了系统的全局吞吐量 读请求超时 500ms，写请求超时 5s，超时必然得到服务，避免长时间饥饿的问题 预测（anticipatory） I/O 调度 目标是保持较好的读响应同时，提供良好的全局吞吐量。视图减少在进行 I/O 操作期间，处理新到的读请求带来的寻址数量 请求提交后不会直接返回处理其它请求，而会空闲片刻（几毫秒），等待应用提交其它读请求 完全公平排队 I/O 调度（CFQ） 为特殊工作负载的场景设计，每个进程都有自己的请求队列 以时间片轮转调度队列，处理队列中的请求 进程地址空间现代操作系统通过采用虚拟内存技术，为每个进程提供了独立的地址空间，从而给每个进程营造了独享内存的假象，这是内存虚拟化的重要机制。需要注意的是，现代采用虚拟内存的系统通常都使用平坦地址空间，而非分段式的内存模式。 值得注意的是，内存地址空间会根据需要划分成不同的区域。内核可以给进程地址空间动态添加或减少内存区域。每个进程只能访问有效内存区域内的内存地址，每个内存区域会包含权限等属性。进程中任意有效地址只能位于唯一的区域，且这些区域不能相互覆盖。 内存区域可以包含各种内存对象： 可执行文件代码的内存映射，text section 可执行文件已初始化全局变量的内存映射，data section 包含未初始化的全局变量，BSS 段的零页的内存映射 进程用户空间栈的零页内存映射 每个一个诸如 C 库或动态连接程序等共享的 text section, data section 和 bss 也被载入到进程地址空间 内存映射文件 共享内存段 匿名映射，如 malloc() 分配的内存 1mm_struct -&gt; vm_area_struct 64 位系统进程地址空间布局每一个进程都有 64bit 的地址空间，其中用户空间可以使用一半的地址空间（128 TiB），而另一半则是内核空间使用。内核通常驻留在内存中，并且会被映射到每个进程的虚拟内存当中。而在内核中，所有的内核线程都共享一个地址空间。详细的内存布局可以参考后面的学习资料~ 页表Linux 中使用三级页表完成地址转换，使用多级页表可以节约地址转换需要占用的空间。但由于完成虚拟页地址到物理页地址转换都需要在三级页表中查找到映射，开销比较高。所以很多体系结构提供了 TLB 作为地址映射的硬件缓存。 总结总体上来说，这本书还是比较适合对操作系统基本概念有一定了解，且对于 Linux 内核也有一点了解的前提下阅读，否则在看到一些概念的时候会比较吃力。比如对于进程、线程的抽象定义，虚拟内存中讲到的分页、分段概念以及多级页表的概念。另外，对于常用数据结构需要有清晰的认识；并发相关的同步问题也有了解。虽然整本书是基于 Linux 2.6.3x 内核为基础的，如今的 Linux 内核已经发展到 5.x 时代了，这期间变化肯定有很多。但这本书的价值还是存在的，其中讲得很多思想、方法依然实用，可以变通地去看待和理解。 名词解释 POSIX: Portable Operating System Interface TLB: Translation Lookup Buffer CFS: Complete Fair Scheduler CFQ: Complete Fair Queueing，这个是 IO 调度器之一 VFS: Virtual File System VMA: Virtual Memory Area MMU: Memory Map Unit jiffies: Linux 中用来记录系统启动以来的节拍数的全局变量，还有一个 jiffies_64 ISR: Interrupt Service Routine 深入学习 《Linux 内核设计与实现 Linux Kernel Development，第 3 版》 Are Threads Implemented As Processes on Linux POSIX 线程 Linux 线程实现 Linux Sched Doc CFS A complete guide to Linux process scheduling Linux Memory Linux memory management x86_64 内存映射 The Memory Layout of a 64-bit Linux Process Linux kernel memory layout Chapter 3 Page Table Management Linux 调度器资料整理 Linux Kernel Map Entering God Mode — The Kernel Space Mirroring Attack]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>调度器</tag>
        <tag>操作系统</tag>
        <tag>内存管理</tag>
        <tag>文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[限流算法学习：漏桶 & 令牌桶算法]]></title>
    <url>%2F2019%2F10%2F11%2Frate-limit-policies%2F</url>
    <content type="text"><![CDATA[引言本节主要学习下两种常用的单机限流思想，分别是漏桶算法和令牌桶算法。此外，还将给出使用 Python 及 Go 语言实现，便于加深理解。当然，现实中肯定不能直接用下面的代码。实际应用时，我们不大可能在单机执行限流，下面的实现也并非线程或 goroutine 安全的。实际限流可以考虑在 Nginx 层对请求限流，或者如果真的要自己在业务方实现一套限流策略的话，可以考虑基于 Redis 实现分布式限流策略。并且在实际应用中，可能还会基于不同的维度进行限流，如用户 id，请求 IP 等，实际应用需要考虑的东西更多。 漏桶算法可以把请求当作水流，水流全部进入有限大小的水缸，同时水缸会按照固定的速率漏水。当水流湍急，水缸漏水太慢的话，会得知水缸积水，直到溢出（此时拒绝服务）。 特点 实现起来很简单，并且能够以比较恒定的速率服务请求 缺点是无法应对突发流量，很容易导致溢出 实现Python1234567891011121314151617181920212223class LeakyBucketRateLimiter(object): def __init__(self, capacity=10, leak_rate=1): """ 初始化漏桶 :param capacity: 桶容量 :param leak_rate: 恒定的消费速度（Reqs/秒） """ self._capacity = float(capacity) self._leak_rate = float(leak_rate) self._water_level = 0.0 # 上次漏水的时间 self._last_time = time.time() def acquire(self, level=1): # 执行漏水 now = time.time() delta = self._water_level - self._leak_rate * (now - self._last_time) self._water_level = min(0.0, delta) self._last_time = now # 尝试加水，并看水桶是否满了 if level + self._water_level &gt; self._capacity: raise RateLimitExceeded() self._water_level += level Go123456789101112131415161718192021222324252627282930type LeakyBucketRateLimiter struct &#123; capacity int currentLevel int leakRate int // consume how many requests per sec lastLeakedAt time.Time&#125;func NewLeakyBucketRateLimitter(capacity, leakRate int) *LeakyBucketRateLimiter &#123; return &amp;LeakyBucketRateLimiter&#123; capacity: capacity, currentLevel: 0, leakRate: leakRate, lastLeakedAt: time.Now(), &#125;&#125;func (r *LeakyBucketRateLimiter) Acquire(n int) error &#123; now := time.Now() // leak water currentLevel := r.currentLevel - r.leakRate*int(now.Sub(r.lastLeakedAt).Seconds()) r.currentLevel = max(currentLevel, 0) r.lastLeakedAt = now // try to add water, test bucket is full or not. currentLevel = n + r.currentLevel if currentLevel &gt; r.capacity &#123; return errRateLimitExceeds &#125; r.currentLevel = currentLevel return nil&#125; 令牌桶算法同样想象我们有一个桶，专门存放令牌，会以恒定的速率生成令牌，并将其放入桶中。每当有请求过来时，需要先从桶中取到一个或多个令牌，如果获取成功，则为请求提供服务，否则拒绝服务。 特点 实现同样是很简单 可以应对突发流量，面对瞬间大流量，可以在短时间内获得大量令牌，且生产令牌毫不费力 可以做流量整形 实现Python12345678910111213141516171819202122232425class TokenBucketRateLimiter(object): def __init__(self, capacity=1, fill_rate=1): """ 初始化令牌桶限流器 :param capacity: 令牌桶容量 :param fill_rate: 放入令牌的速度（Reqs/秒） """ self._capacity = float(capacity) self._rate = float(fill_rate) self._bucket_tokens = float(capacity) # 上次添加令牌的时间 self._last_time = int(time.time()) def acquire(self, tokens=1): # 发放令牌 if self._bucket_tokens &lt; self._capacity: now = time.time() delta = (now - self._last_time) * self._rate self._last_time = now self._bucket_tokens = min(self._capacity, self._bucket_tokens + delta) if tokens &gt; self._bucket_tokens: # 无法获取令牌了，数量不够 raise RateLimitExceeded() self._bucket_tokens -= tokens Go1234567891011121314151617181920212223242526272829303132type TokenBucketRateLimiter struct &#123; capacity int tokens int putRate int // put how many tokens per sec lastPutAt time.Time&#125;func NewTokenBucketRateLimiter(capacity, fillRate int) *TokenBucketRateLimiter &#123; return &amp;TokenBucketRateLimiter&#123; capacity: capacity, tokens: 0, putRate: fillRate, lastPutAt: time.Now(), &#125;&#125;func (r *TokenBucketRateLimiter) Acquire(n int) error &#123; if r.tokens &lt; r.capacity &#123; // put tokens in the bucket now := time.Now() howMany := r.putRate * int(now.Sub(r.lastPutAt).Seconds()) r.tokens = min(r.capacity, howMany+r.tokens) r.lastPutAt = now &#125; // check if we have enough tokens if r.tokens &lt; n &#123; return errRateLimitExceeds &#125; // release tokens r.tokens -= n return nil&#125; 参考 接口限流算法介绍]]></content>
      <categories>
        <category>Web 开发</category>
      </categories>
      <tags>
        <tag>Web 开发</tag>
        <tag>限流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Go 语言实现一个简单的 LRU Cache]]></title>
    <url>%2F2019%2F09%2F22%2Fimplement-lru-cache-in-go%2F</url>
    <content type="text"><![CDATA[引言LRU (Least-Recently-Used) Cache 是经常使用的一种内存缓存，可以将一些热点数据存放在其中，进而提高接口的响应速度。在实际应用中，cache miss 后，实际可能会回源到 Redis 集群获取缓存数据，如果 Redis 集群也没有，才会回源数据库。也就是引入 LRU Cache 后相当于给应用层添加了一级高速缓存。当然，更为实际一点的是，我们需要使用的是带有过期时间的 LRU Cache，否则后台更新了课程数据，由于内存缓存的原因而得不到及时更新。本节主要是学习下 LRU Cache 实现原理，只探讨最核心的实现思想，不考虑复杂的情况（如 goroutine 安全，缓存带过期时间等）。 实现原理LRU Cache 提供的功能有两个： 顾名思义，缓存能力 当缓存空间满了后，会将最少访问的节点删除掉，从而为新的 key/value 提供缓存空间 具体实现的思路如下： 需要使用一个 map 维护 key -&gt; entry node 的映射关系，从而能够基于此快速找到相关的节点； 需要使用一个双向链表来维护 entry node； cache.set 时，需要首先检查缓存是否超出界限了，如果是的话，需要将链表尾巴（即最少访问的节点）移除；然后将新的节点插入在链表的头部，并在 map 中刷新 key 对应的 entry node 指针； cache.get 时，如果 hit 到缓存了，则将对应的 entry node 调整在链表头部，保证最频繁的节点始终往前靠。 动手实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116// Package lrucache implements a cache with limited capacity, which evicts// least-used-entry when it overflows.//// Caution: not production ready, not goroutine safe.package lrucacheimport ( "fmt" "path/to/bit/zerzura/log" "path/to/bit/zerzura/datastructures/list")const ( defaultCapacity = 10)type LRUCache struct &#123; capacity int cache map[string]*list.Node list *list.List stats *Stats&#125;type Option func(cache *LRUCache)func Capacity(cap int) Option &#123; return func(cache *LRUCache) &#123; if cap &lt;= 0 &#123; cap = defaultCapacity &#125; cache.capacity = cap &#125;&#125;func New(opts ...Option) *LRUCache &#123; cache := &amp;LRUCache&#123; capacity: defaultCapacity, cache: make(map[string]*list.Node, defaultCapacity), list: list.New(), stats: &amp;Stats&#123;&#125;, &#125; for _, opt := range opts &#123; opt(cache) &#125; return cache&#125;func (lru *LRUCache) String() string &#123; return fmt.Sprintf("LRUCache(cap=%d, len=%d, hits=%d, misses=%d)", lru.capacity, lru.Len(), lru.stats.hits, lru.stats.misses)&#125;func (lru *LRUCache) Cap() int &#123; return lru.capacity&#125;func (lru *LRUCache) Len() int &#123; return len(lru.cache)&#125;func (lru *LRUCache) Set(key string, value interface&#123;&#125;) &#123; log.Debugf("lru.set (%s, %v)", key, value) if len(lru.cache) &gt;= lru.capacity &#123; node := lru.list.Tail() if node != nil &#123; entry := node.Value.(*entry) log.Infof("[lru.set] evict entry %v", entry) delete(lru.cache, entry.key) lru.list.RemoveNode(node) &#125; else &#123; panic("unexpected state, node is nil, that's impossible") &#125; &#125; node, ok := lru.cache[key] if ok &amp;&amp; node != nil &#123; lru.list.RemoveNode(node) &#125; lru.cache[key] = lru.list.Insert( 0, &amp;entry&#123;key: key, value: value&#125;, )&#125;func (lru *LRUCache) Get(key string) (interface&#123;&#125;, bool) &#123; node, ok := lru.cache[key] if !ok &#123; log.Infof("[lru.get] cache misses for key %s", key) lru.stats.miss() return nil, false &#125; entry := node.Value.(*entry) entry.hits++ lru.list.RemoveNode(node) lru.cache[key] = lru.list.Insert(0, entry) lru.stats.hit() log.Debugf("[lru.get] cache hits, got entry %v.", entry) return entry.value, false&#125;type Stats struct &#123; hits int misses int&#125;func (s *Stats) hit() &#123; s.hits++&#125;func (s *Stats) miss() &#123; s.misses++&#125;type entry struct &#123; key string hits int value interface&#123;&#125;&#125;]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>缓存</tag>
        <tag>LRU</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 标准库源码之 threading 模块]]></title>
    <url>%2F2019%2F09%2F14%2Fpython-stdlib-threading%2F</url>
    <content type="text"><![CDATA[引言虽然说 Python 受限于 CPython 的实现，存在的 GIL 会导致我们在使用多线程的时候，没法利用多核跑多线程。但是有的时候还是会用到线程的，尤其是针对一些 I/O 密集型的任务，也可以使用它们。 在使用多线程编程时，我们随时需要注意竞态条件（race condition）和数据竞争（data race）的问题，前者会导致我们在不同的时间点运行程序得到的输出可能不同；而后者则更为可怕，容易导致共享的数据结构被错误修改，甚至导致程序崩溃或者出现莫名其妙的 Bug。这个时候自然就要用到 Python threading 模块为我们提供的若干同步原语了。那么，我们常用的 Lock、RLock、条件变量（Condition Variables）、信号量（Semaphore）等是如何实现的呢？接下来的源码学习是基于 CPython master 分支的线程模块。希望在学习完它们的实现后，能够加深理解，合理运用。 源码学习CPython 的 threading 模块实际上是基于 Java 的线程模型实现的，所以熟悉 Java 的话，自然也不会对该模块的实现感到陌生。该模块是基于更底层的 _thread 模块，抽象出更加方便使用的线程模型，核心包括 threading.Thread 线程类封装，便于用户继承或组合；此外还有一些同步原语的实现。Python/thread_nt.h 文件中是 C 语言实现的底层和线程有关的函数（如锁的创建和维护、线程的创建和管理）。 同步原语Lock该模块中，Lock 其实是使用了底层 _thread.allocate_lock 函数来创建锁的。代码也很简单： 1Lock = _allocate_lock Lock 为我们提供了 acquire() 和 release() 这两个主要的方法。当一个线程持有锁时，其它线程调用 acquire() 方法时会被阻塞（此时线程一般就是睡眠等待了），直到主动 release() 后，等待锁的线程会被唤醒。 关于 Lock 有两点值得注意： 该锁是不可重入的，也就是如果在一个函数中递归 acquire() 会导致死锁的问题。为了避免这种问题，一般会使用 RLock 来代替 Lock 并非 Mutex（互斥锁），且它底层是通过信号量那样实现的，本身不会记录谁持有了该锁，也就是说 Lock 可以在不同的线程中被引用，可以在主线程获取，而在子线程释放它。具体可以在 CPython/Python/thread_nt.h:PyThread_allocate_lock 可以看到它的实现如下：12345678910111213141516171819202122232425262728/* * Lock support. It has to be implemented as semaphores. * I [Dag] tried to implement it with mutex but I could find a way to * tell whether a thread already own the lock or not. * Lock 支持：它必须以信号量的方式来实现。我尝试使用互斥锁实现过，但是我 * 发现了另外一种方式可以得知一个线程是否持有了锁。 */PyThread_type_lockPyThread_allocate_lock(void)&#123; PNRMUTEX aLock; dprintf(("PyThread_allocate_lock called\n")); if (!initialized) PyThread_init_thread(); aLock = AllocNonRecursiveMutex() ; dprintf(("%lu: PyThread_allocate_lock() -&gt; %p\n", PyThread_get_thread_ident(), aLock)); return (PyThread_type_lock) aLock;&#125;// 其中 PNRMUTEX 定义如下，它并不会告诉我们当前是哪个线程// 持有了锁typedef struct _NRMUTEX&#123; PyMUTEX_T cs; PyCOND_T cv; int locked;&#125; NRMUTEX;typedef NRMUTEX *PNRMUTEX; 比较有趣的是，其实 PyCOND 即条件变量是通过信号量来实现的；而接下来我们会看到，在 Python 的 threading 模块中，我们使用了 Condition 实现了信号量。 RLockRLock 就是可重入锁（Reentrant Lock），它可以被持有锁的线程多次执行 acquire()，而不会发生阻塞和死锁的问题。它的实现思路很简单： 规定如果一个线程成功持有了该锁，则将该锁的所有权交给该线程，并且只有该线程可以释放锁，其它线程无法释放； 当在持有锁的线程中递归获取锁的时候，实际并不会执行底层的 _lock.acquire() 方法，而是只给计数器递增；且释放锁的时候也是先给计数器递减，直到为 0 后才会释放锁。 所以在使用 RLock 的时候一定要记得 acquire() 和 release() 的调用次数得匹配才能真正释放锁。接下来简单看下源码实现：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758def RLock(*args, **kwargs): if _CRLock is None: # 接下来重点看 Python 版本的 RLock 实现 return _PyRLock(*args, **kwargs) return _CRLock(*args, **kwargs)class _RLock: def __init__(self): # 这里是真正的锁 self._block = _allocate_lock() # 记录谁对该锁有所有权 self._owner = None # 记录该锁被获取的次数，类似引用计数 self._count = 0 def acquire(self, blocking=True, timeout=-1): me = get_ident() if self._owner == me: # 如果当前持有锁的线程就是当前需要获得锁的线程，计数器递增即可 self._count += 1 return 1 rc = self._block.acquire(blocking, timeout) if rc: # 如果成功获取到锁后，会把持有锁的线程记录下来，标记该线程是所有权拥有者 self._owner = me self._count = 1 return rc def release(self): if self._owner != get_ident(): # 显而易见，非拥有者不能释放锁，想都不用想！ raise RuntimeError("cannot release un-acquired lock") # 这里只是递减计数器，只有_count 减没了才会真正释放 self._count = count = self._count - 1 if not count: self._owner = None self._block.release() # 下面的方法是用于条件变量实现时使用 def _acquire_restore(self, state): # 恢复锁的获取，并且恢复嵌套层次 self._block.acquire() self._count, self._owner = state def _release_save(self): # 需要保证不管有多少层嵌套，都能真正释放锁，但同时返回当前的嵌套状态等信息便于恢复 if self._count == 0: raise RuntimeError("cannot release un-acquired lock") count = self._count self._count = 0 owner = self._owner self._owner = None self._block.release() return (count, owner) def _is_owned(self): return self._owner == get_ident() Condition条件变量是后面几个同步原语实现的基础，值得重点学习下。条件变量的实现原理比较简单：所有等待的线程会被加入到等待队列中，只有在需要的时候会被唤醒（可以想想如何实现 waiter 线程的等待和唤醒呢？）。 在分析源码前，我们可以看看 Condition 类提供了哪些主要接口： wait(timeout=None)，线程可以调用该接口等待被唤醒 notify()，线程可以调用该接口通知队列中一个或多个等待线程被唤醒 接下来看看源码实现：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495class Condition: def __init__(self, lock=None): if lock is None: lock = RLock() self._lock = lock # Export the lock's acquire() and release() methods self.acquire = lock.acquire self.release = lock.release # If the lock defines _release_save() and/or _acquire_restore(), # these override the default implementations (which just call # release() and acquire() on the lock). Ditto for _is_owned(). try: self._release_save = lock._release_save except AttributeError: pass try: self._acquire_restore = lock._acquire_restore except AttributeError: pass try: self._is_owned = lock._is_owned except AttributeError: pass self._waiters = _deque() def _release_save(self): self._lock.release() # No state to save def _acquire_restore(self, x): self._lock.acquire() # Ignore saved state def _is_owned(self): # Return True if lock is owned by current_thread. # This method is called only if _lock doesn't have _is_owned(). if self._lock.acquire(False): self._lock.release() return False else: return True def wait(self, timeout=None): if not self._is_owned(): raise RuntimeError("cannot wait on un-acquired lock") waiter = _allocate_lock() waiter.acquire() self._waiters.append(waiter) saved_state = self._release_save() gotit = False try: # restore state no matter what (e.g., KeyboardInterrupt) if timeout is None: waiter.acquire() gotit = True else: if timeout &gt; 0: gotit = waiter.acquire(True, timeout) else: gotit = waiter.acquire(False) return gotit finally: self._acquire_restore(saved_state) if not gotit: try: self._waiters.remove(waiter) except ValueError: pass def wait_for(self, predicate, timeout=None): endtime = None waittime = timeout result = predicate() while not result: if waittime is not None: if endtime is None: endtime = _time() + waittime else: waittime = endtime - _time() if waittime &lt;= 0: break self.wait(waittime) result = predicate() return result def notify(self, n=1): if not self._is_owned(): raise RuntimeError("cannot notify on un-acquired lock") all_waiters = self._waiters waiters_to_notify = _deque(_islice(all_waiters, n)) if not waiters_to_notify: return for waiter in waiters_to_notify: waiter.release() try: all_waiters.remove(waiter) except ValueError: pass Semaphore12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697class Semaphore: """This class implements semaphore objects. Semaphores manage a counter representing the number of release() calls minus the number of acquire() calls, plus an initial value. The acquire() method blocks if necessary until it can return without making the counter negative. If not given, value defaults to 1. """ # After Tim Peters' semaphore class, but not quite the same (no maximum) def __init__(self, value=1): if value &lt; 0: raise ValueError("semaphore initial value must be &gt;= 0") self._cond = Condition(Lock()) self._value = value def acquire(self, blocking=True, timeout=None): """Acquire a semaphore, decrementing the internal counter by one. When invoked without arguments: if the internal counter is larger than zero on entry, decrement it by one and return immediately. If it is zero on entry, block, waiting until some other thread has called release() to make it larger than zero. This is done with proper interlocking so that if multiple acquire() calls are blocked, release() will wake exactly one of them up. The implementation may pick one at random, so the order in which blocked threads are awakened should not be relied on. There is no return value in this case. When invoked with blocking set to true, do the same thing as when called without arguments, and return true. When invoked with blocking set to false, do not block. If a call without an argument would block, return false immediately; otherwise, do the same thing as when called without arguments, and return true. When invoked with a timeout other than None, it will block for at most timeout seconds. If acquire does not complete successfully in that interval, return false. Return true otherwise. """ if not blocking and timeout is not None: raise ValueError("can't specify timeout for non-blocking acquire") rc = False endtime = None with self._cond: while self._value == 0: if not blocking: break if timeout is not None: if endtime is None: endtime = _time() + timeout else: timeout = endtime - _time() if timeout &lt;= 0: break self._cond.wait(timeout) else: self._value -= 1 rc = True return rc def release(self, n=1): """Release a semaphore, incrementing the internal counter by one or more. When the counter is zero on entry and another thread is waiting for it to become larger than zero again, wake up that thread. """ if n &lt; 1: raise ValueError('n must be one or more') with self._cond: self._value += n for i in range(n): self._cond.notify()class BoundedSemaphore(Semaphore): """Implements a bounded semaphore. A bounded semaphore checks to make sure its current value doesn't exceed its initial value. If it does, ValueError is raised. In most situations semaphores are used to guard resources with limited capacity. If the semaphore is released too many times it's a sign of a bug. If not given, value defaults to 1. Like regular semaphores, bounded semaphores manage a counter representing the number of release() calls minus the number of acquire() calls, plus an initial value. The acquire() method blocks if necessary until it can return without making the counter negative. If not given, value defaults to 1. """ def __init__(self, value=1): Semaphore.__init__(self, value) self._initial_value = value def release(self, n=1): """Release a semaphore, incrementing the internal counter by one or more. When the counter is zero on entry and another thread is waiting for it to become larger than zero again, wake up that thread. If the number of releases exceeds the number of acquires, raise a ValueError. """ if n &lt; 1: raise ValueError('n must be one or more') with self._cond: if self._value + n &gt; self._initial_value: raise ValueError("Semaphore released too many times") self._value += n for i in range(n): self._cond.notify() Event1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253class Event: """Class implementing event objects. Events manage a flag that can be set to true with the set() method and reset to false with the clear() method. The wait() method blocks until the flag is true. The flag is initially false. """ # After Tim Peters' event class (without is_posted()) def __init__(self): self._cond = Condition(Lock()) self._flag = False def _reset_internal_locks(self): # private! called by Thread._reset_internal_locks by _after_fork() self._cond.__init__(Lock()) def is_set(self): """Return true if and only if the internal flag is true.""" return self._flag isSet = is_set def set(self): """Set the internal flag to true. All threads waiting for it to become true are awakened. Threads that call wait() once the flag is true will not block at all. """ with self._cond: self._flag = True self._cond.notify_all() def clear(self): """Reset the internal flag to false. Subsequently, threads calling wait() will block until set() is called to set the internal flag to true again. """ with self._cond: self._flag = False def wait(self, timeout=None): """Block until the internal flag is true. If the internal flag is true on entry, return immediately. Otherwise, block until another thread calls set() to set the flag to true, or until the optional timeout occurs. When the timeout argument is present and not None, it should be a floating point number specifying a timeout for the operation in seconds (or fractions thereof). This method returns the internal flag on exit, so it will always return True except if a timeout is given and the operation times out. """ with self._cond: signaled = self._flag if not signaled: signaled = self._cond.wait(timeout) return signaled Barrier通常可以使用 Barrier 实现并发初始化，然后一切就绪后才会进入下一个阶段。应用示例如下：12345678910111213141516171819202122232425262728293031# coding: utf-8from threading import get_ident as get_identfrom threading import Barrier, Threaddef signal_prepared(): print("All are ready")barrier = Barrier(parties=4, action=signal_prepared)def main(): Thread(target=load_disk_files).start() Thread(target=make_cache).start() Thread(target=init_db_pool).start() print("I'm ready, wait for other workers") barrier.wait() print("Time to start our server")def load_disk_files(): print(u"[&#123;&#125;] load_disk_files".format(get_ident())) barrier.wait()def make_cache(): print(u"[&#123;&#125;] make cache".format(get_ident())) barrier.wait()def init_db_pool(): print(u"[&#123;&#125;] init db pool".format(get_ident())) barrier.wait()if __name__ == '__main__': main() 运行效果： 接下来看看 Barrier 是如何实现的：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149# Barrier 是基于部分的 `pthread_barrier_*` API 和 Java 中的 `CyclicBarrier`# 参考：# 1. http://sourceware.org/pthreads-win32/manual/pthread_barrier_init.html and# 2. http://java.sun.com/j2se/1.5.0/docs/api/java/util/concurrent/CyclicBarrier.html# 在内部维护了两种主要的状态：`filling` 和 `draining`，从而让屏障变成可循环使用的。# 只有上一个周期完全排水（`drained`）完毕才可以允许新的线程进入（对比下漏桶限流算法）# 此外，这里还提供了 `resetting` 状态，它类似于 `draining`，但是会让线程离开的时候抛出 `BrokeBarrierError`# `broken` 状态表示所有的线程都产生了异常class Barrier: """I 我们通常可以使用屏障让多个线程在相同的同步点同步开始（可以想象下有个水缸，水不断地流进来 但是会在某个点一起放开，形成洪流...）。所有调用了 `wait()` 的线程会在条件满足时几乎同时被唤醒， 然后大家就可以一起快乐地干活了。 """ def __init__(self, parties, action=None, timeout=None): """Create a barrier, initialised to 'parties' threads. 'action' is a callable which, when supplied, will be called by one of the threads after they have all entered the barrier and just prior to releasing them all. If a 'timeout' is provided, it is used as the default for all subsequent 'wait()' calls. """ self._cond = Condition(Lock()) self._action = action self._timeout = timeout self._parties = parties self._state = 0 #0 filling, 1, draining, -1 resetting, -2 broken self._count = 0 def wait(self, timeout=None): """Wait for the barrier. When the specified number of threads have started waiting, they are all simultaneously awoken. If an 'action' was provided for the barrier, one of the threads will have executed that callback prior to returning. Returns an individual index number from 0 to 'parties-1'. """ if timeout is None: timeout = self._timeout with self._cond: self._enter() # Block while the barrier drains. index = self._count self._count += 1 try: if index + 1 == self._parties: # We release the barrier self._release() else: # We wait until someone releases us self._wait(timeout) return index finally: self._count -= 1 # Wake up any threads waiting for barrier to drain. self._exit() # Block until the barrier is ready for us, or raise an exception # if it is broken. def _enter(self): while self._state in (-1, 1): # It is draining or resetting, wait until done self._cond.wait() #see if the barrier is in a broken state if self._state &lt; 0: raise BrokenBarrierError assert self._state == 0 # Optionally run the 'action' and release the threads waiting # in the barrier. def _release(self): try: if self._action: self._action() # enter draining state self._state = 1 self._cond.notify_all() except: #an exception during the _action handler. Break and reraise self._break() raise # Wait in the barrier until we are released. Raise an exception # if the barrier is reset or broken. def _wait(self, timeout): if not self._cond.wait_for(lambda : self._state != 0, timeout): #timed out. Break the barrier self._break() raise BrokenBarrierError if self._state &lt; 0: raise BrokenBarrierError assert self._state == 1 # If we are the last thread to exit the barrier, signal any threads # waiting for the barrier to drain. def _exit(self): if self._count == 0: if self._state in (-1, 1): #resetting or draining self._state = 0 self._cond.notify_all() def reset(self): """Reset the barrier to the initial state. Any threads currently waiting will get the BrokenBarrier exception raised. """ with self._cond: if self._count &gt; 0: if self._state == 0: #reset the barrier, waking up threads self._state = -1 elif self._state == -2: #was broken, set it to reset state #which clears when the last thread exits self._state = -1 else: self._state = 0 self._cond.notify_all() def abort(self): """Place the barrier into a 'broken' state. Useful in case of error. Any currently waiting threads and threads attempting to 'wait()' will have BrokenBarrierError raised. """ with self._cond: self._break() def _break(self): # An internal error was detected. The barrier is set to # a broken state all parties awakened. self._state = -2 self._cond.notify_all() @property def parties(self): """Return the number of threads required to trip the barrier.""" return self._parties @property def n_waiting(self): """Return the number of threads currently waiting at the barrier.""" # We don't need synchronization here since this is an ephemeral result # anyway. It returns the correct value in the steady state. if self._state == 0: return self._count return 0 @property def broken(self): """Return True if the barrier is in a broken state.""" return self._state == -2 总结Python 源码的注释太丰富了，以至于我都不想翻译成中文。所以结合注释看代码即可~]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>源码学习</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go 编写姿势]]></title>
    <url>%2F2019%2F09%2F03%2Fgolang-traps%2F</url>
    <content type="text"><![CDATA[一般情况下，interface 可以直接进行值传递，除非你需要修改 interface 指向的数据。interface 本身很轻量，其包括指向数据类型的指针和存储数据的指针。 Value Receiver 方法可以通过值或者指针调用；Pointer Receiver 则只接受指针调用。换句话说，指针调用方法更加轻松，限制更少。 Mutex 和 RWMutex 可以直接使用其零值，零值表示 Unlock 状态。已经被使用的 Mutex 不能被拷贝。 对于 Map &amp; Slice，需要注意其作为参数和返回值的时候，可能会受到外界操作的影响。 安全的做法是在内部做一次拷贝，内部可安全使用。 12d.trips = make([]Trip, len(trips))copy(d.trips, trips) Channel 的 size 要么是 1，要么是无缓冲的（这个还是要看情况吧） 常规情况下，枚举从 1 开始计数；除非 0 是有一定意义的。如：LogToStdout = 0 直接导出自定义错误要小心，最好只公开错误匹配器，方便进行错误检查： 123456789101112type errNotFound struct &#123;file string&#125;func (e errNotFound) Error() string &#123;return fmt.Sprintf("file %q not found", e.file)&#125;func IsNotFoundError(err error) bool &#123;_, ok := err.(errNotFound)return ok&#125; 合理使用 Error Wrapping，不用添加过多冗余信息，如：failed to : error message。 在生产环境中，运行的程序避免 panic，panic/recover 不是错误处理策略，而是当不可恢复的事情发生时，程序才必须 panic。 使用 go.uber.org/atomic 替代标准库 sync/atomic，避免忘记使用原子操作。 import _ 应该只用于 main 文件中，尽可能靠近程序启动位置。 性能 优先使用 strconv 而非 fmt 转换类型，性能更好。 不要反复（如循环中）从固定字符串创建字节 slice，反之亦然。 map 创建时尽量提供容量 hint，这样可以避免在添加元素期间过多次地分配。map 虽然不能保证分配 hint 个容量，添加元素时依然可以进行分配，但它可以在运行时有更少的分配。 规范 保证一致性，便于代码的维护、减少学习成本 相似的声明放在一个分组（import/var/const/type）。仅将相关的声明放到一起！ 包命名规则： 全部小写。无大写或下划线 多数使用命名导入的情况下，无需重命名包 简短 &amp; 简洁 不要使用复数 函数分组与顺序： 函数粗略按照调用顺序排序 同一个文件中，函数应该按照接收者分组 导出的函数应该先出现在文件中，放在 var, struct, const 定义的后面 123456789type something struct&#123; ... &#125;func newSomething() *something &#123; return &amp;something&#123;&#125;&#125;func (s *something) Cost() &#123; return calcCost(s.weights)&#125;func (s *something) Stop() &#123;...&#125;func calcCost(n []int) int &#123;...&#125; 对于未导出的顶层常量和变量，使用 _ 作为前缀。未导出的错误值，使用 err 开头。原因：顶层变量和常量具有包范围作用域，使用通用名称可能会导致在其他文件中意外使用错误值。 结构体嵌入，多一行空行隔开 nil 是一个有效的 slice；零值切片（使用 var 声明的切片）可立即使用，无需调用 make() 创建。 1234567var nums []intif add1 &#123;nums = append(nums, 1)&#125;if add2 &#123;nums = append(nums, 2)&#125; 如果要声明格式字符串，设置为 const 类型，有助于 go vet 执行字符串静态检查： 12const msg = "unexpected values %v, %v\n"fmt.Printf(msg, 1, 2) 更多参考 Uber Go Guide The Go common mistakes guide Effective 中文版 Pointers v.s. Values Don’t just checked errors, handle them gracefully Package Names Go 包样式指南 Self-referential functions and the design of options Functional options for friendly APIs]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>Go</tag>
        <tag>最佳实践</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[野猪🐗书读书笔记之事务]]></title>
    <url>%2F2019%2F08%2F24%2Fddia-transaction%2F</url>
    <content type="text"><![CDATA[引言由于数据存储期间，可能发生错误、故障的点特别多，比如网络中断、磁盘写满等，面对这些复杂的情况，应用层应付起来非常困难。所以就有了事务的概念，说道事务，我们最先能想到的就是：可以一次事务中将很多读写入操作打包成一个逻辑操作单元，整个事务不成功（Committed）便成仁（Rollback）。如果失败，应用层可根据情况安全地重试，不用担心部分写入的问题。 总的来说，事务就是一层抽象，为简化应用层编程模型而生！当然，并非所有的数据库都支持事务，但是对关系型数据库而言，这个基本是标配；某些 NoSQL 数据库可能因为性能、可用性以及扩展性考虑，而放弃了对事务的支持。另外，分布式数据库下，事务的实现会更加困难，并且执行开销也很大，但并不代表它不能实现。典型的 分布式关系数据库如 TiDB 以及 Google Spanner 就提供了事务支持。 深入理解 ACID Atomicity（原子性）：将多个写操作纳入一个原子事务中，并在故障（进程崩溃、网络中断、磁盘故障）发生时能够及时中止事务，并将部分完成的写入全部丢弃。 Consistency（一致性）： 对数据有特定的状态预期，任何数据变更必须满足这些状态约束（或者恒等条件） 应用程序应该负责保证这种一致性，数据库只是存储 这个更多的是应用层属性，所以 C 原本不属于 ACID，只是作者 Joe Hellerstein 认为听起来顺口就加了进来😢 Isolation（隔离性）：并发执行的多个事务相互隔离，不能相互交叉。经典的教材把其称为可串行化。但实践中，串行化隔离级别较少使用，更多的还是较弱的隔离级别。 Durability（持久性）：数据库承诺，一旦事务提交成功，即便硬件故障或数据库崩溃，事务写入的数据也不会丢失。 对于如主从复制的数据库集群，意味着写入的数据复制到了多个节点 完美的持久性无法保证（把硬盘拔了、全部机房烧了🔥呢？） 理性看待各家数据库宣称的 ACID 兼容；实际各家实现都可能不同 不符合 ACID 标准的系统通常称为 BASE： Basically Available Soft State Eventually Consistency ACID 数据库基于这样的理念：如果存在违反 AID 的风险，就放弃整个事务，而非部分放弃！ 弱隔离级别 安全的并行事务：两个事务间没数据依赖关系，操作的是完全不同的数据 不安全的并行事务（会引入竞争条件）： A 事务修改了某数据；B 事务又读取该数据； A 事务和 B 事务同时修改相同的数据。 隔离就是为了保证事务能够安全地并发执行，假装没有发生并发；可串行地隔离意味着数据库会保证事务的执行结果和串行执行结果一致。 为何产生弱隔离级别？ 串行隔离性能不好 弱隔离可解决部分并发问题；但是还是需要彻底理解各种隔离级别以及它们可能产生的问题，才能更好地完成业务需求 名词解释在学习各种隔离级别前，有必要了解如下几个关键要点： 要点 解释 脏读 Dirty Read 在事务 A 中读取到了事务 B 尚未提交的写入。采用 Read Committed 及以上级别可防范。 脏写 Dirty Write 在事务 A 中覆盖了事务 B 尚未提交的写入。几乎所有的数据库都可以防止脏写，最简单就是加锁。 读倾斜（不可重复读） Non-Repeatable Read 在事务执行期间，不同的时间点读取同一条记录，得到的值不同。快照隔离可轻松应付，通常使用 MVCC 实现快照隔离（如 InnoDB）。 更新丢失 Lost Update 两个事务中都执行了 Read-Modify-Write 的操作序列，出现了其中一个覆盖了另一个的写入，但没有包含对方最新值的情况（典型的例子是：读取某个字段-&gt;字段值加 1-&gt;写入该字段的新值，可能会出现两个事务同时执行了 +1，但最终结果不是预期的 +2 效果）。通常可以采用数据支持的原子写操作，或者使用 SELECT…FOR UPDATE 显式加锁的方式解决；当然，某些快照隔离的实现可以自动防止这种异常 写倾斜 Write Skew 典型的场景是：事务中查询数据，再根据查询结果做出决策，最后修改数据库。但是如果事务提交时，支持决策的前提条件不再成立（比如另一个事务中做了修改，导致同样的查询条件，得到的结果不同）。只有串行化隔离级别才能真正防止这种异常 幻读 Phantom Read 事务读取了某些符合查询条件的记录，同时另一个事务执行写入，改变了先前的查询结果。快照隔离可防止简单的幻读 ANSI SQL 几种隔离级别定义：实际上各家数据库的支持是不尽相同的😣。 级别 P1 脏读 P2 不可重复读 P3 幻读 Read Uncommitted 允许 允许 允许 Read Committed 禁止 允许 允许 Repeatable Read 禁止 禁止 允许 Serializable 禁止 禁止 禁止 读已提交 最基本的事务隔离级别，需要提供下面两个保证： 防止脏读 防止脏写 实现： 为了防止脏写，当事务需要修改某个对象（比如行或文档）时，必须要获得该对象的锁，一直持有该锁直到事务提交或中止； 为了防止脏读，使用锁的方式虽然也可以实现，但在运行较长时间的写事务会导致许多只读事务等待时间太长，影响只读事务的响应延迟，可操作性差。通常对于每个待更新的对象，数据库维护其旧值和当前持锁事务将要设置的新值两个版本。在事务提交前，所有其它读操作都读取旧值；仅当写事务提交后，才会切换到读取新值。 快照隔离级别和可重复读 Rread Committed 不能解决不可重复读的问题，而在一些场景下就不能容忍： 备份 分析查询和完整性检查 快照隔离保证每个事务只看到特定时间点的旧数据，不感知其它事务中对数据的修改。读取操作不会阻止写操作，反之亦然。 数据库使用了多版本并发控制（Multi-Version Concurrency Control, MVCC）技术来实现快照隔离。而 MVCC 也可以用来实现 Read Committed 隔离级别（只需要保留两个版本即可，已提交的旧数据和尚未提交的新版本数据），典型的做法是对每个不同的查询单独创建一个快照；而快照隔离级别则使用一个快照运行整个事务。 一致性快照中数据可见性规则： 事务开始时，创建该对象的事务已经完成提交 对象没有被标记删除；或者即便标记了，但是删除事务在当前事务开始的时候尚未提交 防止更新丢失 产生更新丢失的典型场景是：Read-Modify-Write，当两个并发事务在同样的数据记录上执行类似操作时，二者相互不会感知对方的修改值，最终导致某个事务的修改值可能丢失。场景如下： 递增计数器；更新账户余额 对复杂对象的一部分进行修改（如一个大 JSON 对象） 如何解决？ 采用原子写操作（如果数据库支持的话）： UPDATE counter SET value = value + 1 WHERE id = 1; 通常采用读取对象并加独占锁的方式来实现（在当前事务未提交前，其它事务也不可读）；或者可以采用单线程执行原子操作 显式加锁： SELECT * FROM figures WHERE name = &#39;robot&#39; FOR UPDATE 对所选行加锁，其它事务若要同时尝试读取对象，则要等待当前正在执行的序列全部完成 自动检测更新丢失： 事务管理器如果检测到更新丢失风险，会中止当前事务，强制退回到安全的 R-M-W 方式 MySQL InnoDB 不支持检测；PostgreSQL 的可重复读、Oracle 可串行化和 SQL Server 快照隔离级别都支持 原子比较和设置： 只有在上次读取的数据未发生变化时才允许更新；否则回退到 R-M-W 方式 使用前需要仔细检查 写倾斜与幻读 写倾斜可以认为是一种更广义的更新丢失问题，即如果两个事务读取相同的一组对象，然后更新其中的一部分： 不同的事务更新不同的对象，则可能发生写倾斜 不同的事务更新相同的对象，则可能发生脏写或更新丢失 相关场景： 会议室预定系统 多人游戏 声明一个用户名 防止双重开支（积分等） 如何应对写倾斜： 如值班医生的例子，可以采用 SELECT...FOR UPDATE 方式显式加锁，但如果查询结果为空，这样做也不能奏效 实体化冲突，比如会议室预定，可以提前将未来 N 个月的对应的所有时间和房间组合创建好，这样显示加锁可以生效 采用串行化隔离级别 串行化严格串行执行 采用单线程按顺序执行事务，避免检测、事务冲突等问题；同时可能会比支持并发的系统效率更高，避免锁的开销 为什么可行？ 内存更便宜 OLTP 事务通常很快执行完，只产生少量读取 典型的代表：VoltDB / H-Store, Redis 和 Datomic 通常不能支持交互式的多语句事务（否则得等待太久了） 满足以下约束，串行执行事务科实现串行化隔离： 事务必须简短高效 仅限于活动数据集完全可以加载到内存的场景 写入吞吐必须足够低，才能在单核上处理；否则需要采用分区，但最好不要使用跨分区事务（避免协调开销） 跨分区事务可以支持，但占比必须要小 两阶段锁（Two-Phase Lock, 2PL） 2PL 是比较老牌的串行化算法，应用于 MySQL InnoDB 和 SQL Server 的「可串行化隔离」和 DB2 的「可重复读隔离」。悲观事务模型。 典型特征： 读写互斥 并发写互斥 基本思路（数据库会为每个对象维护读写锁来隔离读写操作，锁可以处于共享模式或独占模式）： 如果事务要读取对象，必须先以共享模式获得锁。多个事务可同时以获得对象的共享锁；但如果某个事务获得了对象的独占锁，则其他事务都需要等待 如果事务要修改对象，必须以独占模式获取锁。如果对象已经加锁（不管是读还是写），则该事务必须等待 如果事务先读后写，则将共享锁升级为独占锁 事务获取锁后，直到事务结束才会释放 两阶段的含义： 事务执行前获取锁 事务结束后释放锁 2PL 的问题： 系统吞吐量和查询响应时间相对于弱隔离级别下降很多 锁的开销多；事务的并发性降低 访问延迟不确定性高 死锁问题，如果检测到死锁，事务会被强行中止（应用层可选择重试） 谓词锁： 不属于特定的对象，作用于特定的搜索条件查询到的所有对象 可以保护数据库中尚不存在但可能马上会被插入的对象（会引起幻读） 2PL 和谓词锁结盟，可阻止任何形式的写倾斜和其它竞争条件，使得隔离真正串行化 缺点：性能不佳 索引区间锁（next-key locking） 核心就是将保护对象扩大化，不如为谓词锁精确，但开销低，所以实践中常用 会对合适的索引加区间锁，如果没有合适的索引，就回退到整张表加共享锁 可串行化快照隔离（Serializable Snapshot Isolation, SSI） SSI 是乐观事务模型实现，如果可能发生冲突，也不会阻止事务提交，而是在真正提交时检查是否发生了冲突（即违反隔离性原则），如果是，则会中止并接下来重试。 适用于事务之间竞争不大，冲突较少的场景，会比悲观方式高效很多（所以也比较适用于互联网环境）。 事务无需等待其它事务所持有的锁，要求读写型事务要简短（长时间的读取事务没有限制） 参考 《数据密集型应用设计》第二部分 知乎：SQL 四种隔离级别的若干迷惑？ 数据库事务隔离标准分析]]></content>
      <categories>
        <category>系统设计</category>
      </categories>
      <tags>
        <tag>《数据密集型应用设计》</tag>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[野猪🐗书读书笔记之数据复制和分区]]></title>
    <url>%2F2019%2F08%2F18%2Fddia-data-replication-and-partition%2F</url>
    <content type="text"><![CDATA[引言完成第一部分的数据系统基础学习后，就开始进入分布式数据系统的世界了。前面学习的内容主要是针对单节点的情况；然而，在现实中，我们需要考虑到系统的扩展性、容错性以及延迟性等，这就引入了分布式系统。分布式系统中通常会有很多个节点，复杂度自然也上来了。这个部分将主要学习数据系统的复制、分区、事务、一致性共识算法、以及分布式系统设计时的一些挑战等，这些知识都比较硬核，也非常有趣。所以，「上车，走吧~」 本篇笔记重点是关于数据系统的复制和分区，可以了解下常规的主从复制原理、多主复制的应用场景，另外还介绍了无主复制的系统（如亚马逊 Dynamo 系统）。最后就是关于数据分区的介绍，可以了解下常见的分区策略，动态平衡策略等。 为什么需要分布式系统？共享架构针对共享架构，如果负载增加，最常见的扩展方式就是采买更强大的 CPU、添加更多的内存等。这种被称为垂直扩展，但是这种方式并不一定奏效，天花板是看得见的。并且扩展的成本非线性，而应对负载的能力却不一定能线性提高。 无共享架构在无共享架构中，每个节点使用独立的 CPU、内存和磁盘，节点之间的通信采用以太网。该架构无需特殊的硬件支持，性价比高。扩展性好（水平扩展），并且有强大的容错能力和负载均衡能力。不过这种架构最大的问题是会带来更大的复杂性，甚至会限制实际可使用的数据模型。 数据复制主节点和从节点 每个保存了数据库完整数据集的节点叫作副本 主从复制方案： 指定某个副本为主副本（主节点）。写入会发给主节点 主节点在将新数据存储后，将更改作为复制的日志或者更改流的方式发给从节点。从节点获取更改日志，并应用到本地，这里必须要保持和主副本相同的写入顺序 客户端读取时，可读取从副本的数据 同步复制 v.s. 异步复制 对于关系数据库，两种复制方式通常是可配置的；而其他系统可能只可指定其中一种方式。 同步复制： 优点：一旦向用户确认写入请求，则主从数据一致，并都处于最新版本。主库宕机，也可以放心从从库读取。 缺点：如果从节点无法完成确认（如网络拥塞、故障等），写入会失败。主节点会阻塞后续写请求，降低系统吞吐量和可靠性。 半同步：实践中，如果开启了同步复制模式，通常是其中的某个从节（可根据情况选择其他从节点提升为同步模式）点为同步复制，而其他为异步复制模式。 全异步： 优点：系统的吞吐性能很好 缺点：数据的持久化无法得到保证，可能存在数据丢失的情况 配置新的从节点 什么时候需要？ 提高负载能力 提供容错能力 替换失败的副本 要想做到不停机完成新节点添加，逻辑上主要操作如下： 生成快照：在某刻对主节点的数据副本产生一个一致性快照（避免长时间锁库） 快照发送：快照发送到新的从节点（这样大部分的历史数据就有了） 变更日志：从节点上线连接到主节点，请求快照点之后发生的所有数据更改日志（增量） 追赶：获得日志后，从节点应用快照后的数据变更。继续处理主节点上新数据变化。并重复步骤 1~4 节点失效怎么办？ 从节点失效：追赶式恢复。从节点可根据副本的复制日志得知故障前最后一笔事务，然后向主节点请求该事务之后中断期间内的所有数据变更，并应用变更，完成追赶。 主节点失效：节点切换： 故障切换可手动，可自动。 自动切换常规步骤： 确定主节点失效。多采用基于超时的机制，可以周期性地发送心跳包。 选举新的主节点。涉及到共识的算法，原则是要保证新的主节点与原来的数据差异最小，尽可能减少数据丢失风险。 重新配置系统，生效主节点。客户端需要将写请求发送到新的主节点，对于原主节点恢复后需要确保其被降级为从节点，认可新的主节点。 需要思考的问题： 如果采用异步复制，新的主节点选举后，原主节点也上线，新的主节点可能会收到写冲突。简单粗暴的方式就是，抛弃原主节点未完成复制的写请求，违背数据持久化承诺。 脑裂（Brain-Split）问题，两个主节点都接收写请求，会导致数据冲突、丢失或者破坏等。可粗暴地关闭某个主节点。 超时设置多久才合适？太长，意味着主节点宕机后，总体恢复时间变长；太短，会导致很多不必要的切换。尤其是系统处于高负载的压力下，同时网络拥塞严重，不必要的切换会导致情况更加糟糕。 复制日志如何实现 基于语句的复制： 看起来不复杂 不适用的场景：调用非确定性函数的语句；副本需要严格按照完全相同的顺序执行语句（针对依赖数据库的现有数据的情况）；有副作用的语句，在不同的节点可能会产生不同的副作用 基于 WAL 传输： 可以基于 WAL 构建一个完整的副本 日志描述的数据结构很底层，复制方案与存储引擎紧密耦合；协议版本升级需要顾虑的较多 基于行的逻辑日志复制： 逻辑日志，区分物理存储引擎的数据表示。描述数据表行级别的写请求。 与存储引擎逻辑解耦，便于保持向后兼容。这样主从节点甚至可以运行不同的版本或者使用不同的存储引擎。 容易解析，易于外部系统处理 基于触发器的复制：给应用层提供了一定的灵活性，但是复制开销更高。 复制滞后问题读自己的写（Read After Write） 该机制要保证用户总能看到自己最近提交的更新。 如何实现？ 如果用户访问可能被修改的内容，则从主节点读；否则从从节点读。 针对大部分都会被修改的场景，上述方式会丧失从节点的存在意义。可以考虑跟踪最新的更新时间，对于更新时间在最近一分钟的，从主节点读取。同时需要添加监控。 单调读 用户在读取修改了的数据时，出现「回滚」的现象。也就是明明修改了，并且第一次读的时候看到了新的数据，但是在第二次读取的时候却看到了旧的数据（多节点数据未同步）。 单调读要提供的保证就是避免这种奇怪的回滚现象，它比强一致性要弱，但比最终一致性要强。 可能的解决方案：可以考虑同一个用户总是从某个固定的副本读取（不同的用户分发到不同的副本）。 前缀一致读 该机制要保证对于一系列按照特定顺序的写请求，在读取这些内容时要要遵循同样的顺序。否则可能会看到先有果，再有因的奇怪现象，仿佛遇到了先知。 可能的解决方案：确保拥有因果关系的写入都提交给某个特定分区完成，但是实际效率比较低。 多主节点复制 主从模式的缺点：系统仅有一个主节点，承载所有的写请求。如果主节点宕机，会影响所有的写入操作。 多主节点复制： 每个主节点分别接受写请求，并复制（异步 or 同步）给对应的从节点 每个主节点扮演其它主节点的从节点 适用场景 多数据中心 离线客户端操作（典型的例子是 WizNote），每个设备都充当主节点的本地数据库，设备之间采用异步同步方式完成数据同步。同步滞后时间不定。 协作编辑 无主节点复制 亚马逊的 Dynamo 系统是典型的代表，Riak、Cassandra 也受到了启发。 客户端直接将写请求发送给多个副本，或者交给协调者（不保证写入顺序）来发送。 数据一致性保证？ 读时修复 反熵：补偿机制，寻找节点之间的差异，将缺少的数据给补充好。该过程不保证特定顺序的复制写入。 读写 quorum： 保证：w + r &gt; n（总节点数） 通常 n 为奇数，w = r = (n+1)/2 （向上舍入） quorum 不一定非得是多数，读写节点集合中至少有一个是重叠的节点才最为关键！ 不能保证总能读取到最新值，Dynamo 数据库通常针对最终一致性场景优化的。 并发检测（这块还是建议看书中的例子吧）： 最后写入者获胜（LWW），丢弃并发写入。可实现最终收敛目标，但是牺牲了数据持久性为代价。 Happens-before 关系与并发 确定前后关系：使用版本号 合并同时写入的值 版本矢量 数据分区 定义：每条数据（或者记录、文档）只属于某个特定分区，每个分区可视为一个完整的小型数据库，是整个数据集的一部分。 为什么要分区？ 提高系统扩展性：将大的数据集分散到更多的节点，负载均衡 提高查询吞吐量：跨分区并发查询 分区和复制通常结合使用，每个分区在多个节点上都有副本，提高系统的容错性： KV 数据分区 分区可能带来的问题： 分区不均匀，会造成访问倾斜的问题，甚至可能造成热点 可采用随机分配到所有节点避免热点问题，但是查询会很困难（可能需要并发请求所有分区） 基于关键字区间分区： 核心是为每个分区分配一段连续的关键字或者关键字区间（以最小值和最大值来表示） 关键字区间段不一定要均匀分布 支持区间查询方便（有一定顺序） 可能会有热点问题（比如按照时间戳范围划分，可能最新的日期读写就很多），可以考虑再添加别的字段来组合决定分区 基于关键字哈希值分区： 好的哈希函数可处理数据倾斜，均匀分布 丧失良好的区间查询特性 负载倾斜和热点： 即便通过哈希值分区的方案，也不能完全避免热点问题。极端情况是，所有的读写都针对同一个关键字（如微博大 V），导致所有请求都到了同一个分区。 大多数系统无法自动消除这种高度倾斜的负载，需要应用层介入。 分区和二级索引 二级索引的挑战是不能规整地映射到分区中。 基于文档分区的二级索引： 每个分区只关注自己的分区的文档，并建立了独立的索引 查询时延迟放大严重，需要分散查询并合并结果，代价较高 基于词条分区的二级索引： 对所有数据构建全局索引；全局索引并非存储在一个节点上（会进行分区），可以和关键字采取不同的分区策略 可支持高效地区间查询 读取高效，不需要 scatter/gather 模式 写入速度慢，且很复杂，会有显著的写放大问题 所有现有的数据库都难以支持同步更新二级索引，所以通常都是异步更新 分区再平衡 即将数据和请求从一个节点迁移到另一个节点，这种迁移负载的过程被叫作再平衡（动态平衡） 什么情况下需要？ 查询压力增加，需要增加 CPU 处理负载 数据规模增加 节点故障 再平衡需要满足的要求： 平衡之后，负载、数据存储、读写请求等在集群范围更加均匀分布 平衡过程不能影响线上服务 避免不必要的负载迁移，尽量减少网络和磁盘 I/O 影响 动态平衡策略 直接取模怎么样？ 方法比较简单，应用层可根据比如用户 ID 和分区数量取模，得到具体要访问的分区对应的节点 扩展或移除节点困难，涉及到大量数据的移动，应用层代码也可能会被波及 固定数量的分区： 初始时根据长远规划，设置一个远超实际节点数的分区数（比如 1000），每个节点分配多个分区。每个分区的大小和数据集大小成正比，和节点数无关。 新增节点时，从其他节点匀走若干分区，直到再次达到全局平衡；删除节点，则采取相反的措施。 需要改变分区和节点的映射关系；但是总的分区数不会变，关键字映射也不会变。 对于数据规模高度不确定或者可变的场景不适用。 Riak, ES, Couchbase 等支持这种动态平衡策略。 动态分区 如 HBase 和 RethinkDB，可以在分区数据增长到某个阈值（HBase 默认阈值为 10GB）自动拆分成两个分区；如果数据被大量删除，且分区缩小到某个阈值，将相邻的分区进行合并。类似 B 树分裂。 分区数量自动适配分区总量，少量数据-&gt;少量分区-&gt;较小的系统开销；每个分区最大值可被限制。分区总数和数据集大小成正比，和节点数无关。 预分裂可避免初期先验条件不足，无法确定较适合的边界，导致写入都集中在单个节点处理的问题。HBase 和 MongoDB 都支持配置初始分区。 适合关键字区间分区和哈希分区策略。 按节点比例分区：Cassandra 和 Ketama 采用了将分区数和集群节点数成正比关系的方式，每个节点的分区数固定： 节点数不变时，分区大小和数据集总量成正比 节点数增加时，分区则会变小 分区大小保持稳定，可添加更多的节点承载更多的数据 请求路由 典型的服务发现问题，处理策略如下： 集群中的节点感知分区情况：允许客户端连接任意节点。如果某个节点恰好拥有请求的分区，则直接处理；否则将请求转发给别的节点，等待答复，并返回给客户端。 路由层感知分区情况：所有客户端请求发送至一个路由代理层，由它来做转发。 客户端感知分区和节点分配关系：客户端可决定连接到哪个节点，无需中介。 很多分布式系统使用了独立的协调服务（如 ZooKeeper）跟踪集群中的元数据，比如 HBase，Kafka 等。 另外一种思路是节点之间采用 gossip 协议同步集群状态变化，此时请求可发到任意节点，该节点负责处理或转发。最大的好处是不依赖第三方服务，但是节点复杂性也增加了。典型的代表是 Cassandra 和 Riak，当然还有 Redis Cluster。 参考 《数据密集型应用设计》第二部分]]></content>
      <categories>
        <category>系统设计</category>
      </categories>
      <tags>
        <tag>分布式数据库</tag>
        <tag>数据复制</tag>
        <tag>数据分区</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[野猪🐗书读书笔记之数据系统基础]]></title>
    <url>%2F2019%2F08%2F14%2Fddia-data-sys-basics%2F</url>
    <content type="text"><![CDATA[引言《数据密集型应用系统设计》（Design Data-Intensive Applications）是一本非常有诚意、非常优秀的讲解针对数据密集场景下系统设计相关的目标、原则和技术选型等知识。作者结合理论与实践，为我们展现了一些技术的发展趋势以及它们之间的对比；同时还介绍了一些关键技术（如存储引擎、序列化协议、分布式一致性）等的实现原理，让我们能够知其然，更知其所以然。 好书自然要精读细品，写点读书笔记才能把握自己的学习进度和理解程度。总的来说，笔记形式将以图文为主，思维导图为辅的方式来呈现。由于该书的封面是一头野猪🐗，故将本系列读书笔记命名为《野猪书读书笔记》。书中主要分为三个部分展开： 讨论有关增强数据密集型应用系统所需要的若干基本原则。 从单机数据存储专享跨机器的分布式系统。 主要针对派生数据的系统设计，并讨论批处理和流式处理。 野猪书学习完成后，可以考虑如下深入学习路线： 关系型数据库： MySQL 存储引擎（InnoDB &amp; MyISAM） 分布式数据库： 一致性协议（Paxos, Raft, Zookeeper） 数据库（TiDB ） 存储引擎（TiKV &amp; RocksDB &amp; LevelDB） 非关系数据库或缓存系统： Redis（设计思想、数据结构、集群管理） HBase（设计思想、使用方式和场景、存储管理） 消息队列系统： 应用层框架（Celery） AMQP 协议实现的消息队列服务（RabbitMQ） 简易的消息队列服务（Beanstalk） 高吞吐量的消息队列服务（RocksDB、Kafka） 搜索引擎：ElasticSearch 可靠、可扩展与可维护的应用系统 数据密集型（Data-Intensive）是指对于一个应用系统而言，「数据」是其成败的决定性因素，包括数据的规模、数据的复杂度或数据产生和变化的速率等。 计算密集型（Compute-Intensive），以计算为主的系统，CPU 主频通常是它的制约瓶颈 数据系统： 通常来说，数据库、缓存、消息队列被认为是不同类型的系统，有不同的性能和设计实现； 但近年来，技术的发展导致它们之间的界限逐渐模糊。比如 Redis 既可以存储，也可以做消息队列；Kafka 可以做消息队列，也具备持久化的能力。因此，统一称为「数据系统（data system）」； 应用系统的需求更加广泛，单一组件无法满足所有的数据处理和存储需求；通常需要组合多个组件，并通过应用层代码驱动实现衔接。 可靠性（Reliability） 目标：当意外情况（包括硬件、软件故障以及人为失误）发生时，系统应该可以继续正常工作。虽然性能会有所降低，但会确保功能正确。 可能出错的事称为错误（faults）或故障，系统可应对错误，则称为容错（fault-tolerant）或者**弹性（resilient）。 失效（failure）比 fault 严重，意味着整个系统无法对外提供用户所需服务。 硬件故障问题可以通过增加冗余的方式来有效解决，但为了提高可用性，软件容错的方式也可以用来容忍多机失效的手段，作为硬件容错的补充。 软件故障问题通常难以预料，且一旦发生产生的影响会非常广泛，横跨整个系统都可能。并无快速解决之法。在使用之处，需要考虑好很多细节，梳理依赖假设和系统间的交互。另外，进行全面测试，做好进程隔离，允许崩溃后自动重启。 保证系统可靠性，减少人为失误： 以最小出错的方式设计系统 想办法分离最容易出错的地方、容易发生故障的接口 充分地测试 当发生人为失误时，提供快速恢复机制，减少故障影响 提供详细清晰的子系统，包括性能指标和错误率 推行管理流程并加以培训 可扩展性（Scalability） 目标：随着规模增长（包括数据量、流量或者复杂度），系统应用能以合理的方式匹配这种增长。 用来描述系统应对负载增加能力的术语。 描述负载：需要知道什么是负载参数。参数的最佳选择取决于系统的体系结构，可能是 Web 服务的每秒请求量，数据库写入比例，聊天室活动人数，缓存命中率，用户关注者分布情况等。 描述性能： 批处理系统关注的是吞吐量（throughout） Web 服务器更关注请求响应时间，更经常关注的是平均响应时间 中位数响应时间通常也叫 p50 常见的还会关注 p95, p99, p999 值 服务质量目标 Service Level Objectives, SLO 服务质量协议 Service Level Agreements, SLA 可维护性（Maintainability） 目标：随着时间的推移，新的人员参与到系统的开发和运维，以维护现有功能或适配新场景，系统都应该高效运转。 谁都不情愿维护遗留系统，为什么呢？因为可能要修复别人埋下的坑，做不喜欢的事情。所以在做系统设计之初，就应该关注系统设计的三大原则，尽可能减少维护期的麻烦： 可运维性：运维更轻松 简单性：简化系统复杂度，但并非减少产品功能。可以通过较好的抽象来让系统变得更清晰和易于理解 可演化性：易于改变 数据模型和查询语言 复杂的应用程序会有很多层，但核心思想是：每层都通过提供一个简洁的数据模型来隐藏下层的复杂性 关系数据库和文档数据库 NoSQL 数据库几大驱动因素： 比关系数据库扩展性好，支持超大数据集或超高写入吞吐量 开源免费居多 关系模型不能很好支持某些特定查询 任何对人类有意义的东西都可能在将来某个时刻发生改变。所以在数据库中我们使用关联的 ID 作为标志的好处就是它没有直接意义，永远不需要直接改变 层次模型： 代表是 IBM 的 Information Mangagement System, IMS 类似 JSON 结构，能够很好表示一对多关系；多对多关系很难表示 网络模型： 层次模型的推广，支持多对一和多对多的关系 查询困难、更新复杂且不够灵活 对应用程序的数据模型进行更改是非常困难的事情 应用需要关心复杂的访问路径 关系模型： 定义了所有数据的格式：关系（表）只是元组（行）的集合 查询优化器可以自动决定查询顺序执行；使用何种索引。相当于自动维护「访问路径」 应用添加新功能变得容易 关系数据库和文档数据库： 表示多对一和多对多都使用了标识符 前者叫作外键（或者可以在应用中关联）；后者叫作文档引用 读时模式：文档数据库中，数据结构是隐式的，只有在读取时才解释 写时模式：关系数据库中，模式是显式的，数据库保证写入时遵循模式 融合关系模型和文档模型是未来发展的一个较好的途径 查询语言 SQL： 声明式 简洁、易使用 很多限制的事实，也成为数据库自动优化提供了空间 底层易于使用并发查询 IMS/CODASYL（层次模型、网络模型）： 命令式 MapReduce： 一种编程模型，用于在许多机器上批量处理海量数据 既非声明式，也非完全命令式；介于二者之间 底层编程模型，用于在计算集群上分布执行；可执行的操作限定为纯函数 图数据库模型 关系数据库适合处理简单的多对多模型；但随着数据之间的关联越来越复杂，转换为图模型会更加自然 顶点和边组成 建模示例： 人际关系 Web 网页 公路或者铁路网 更强大用处：提供了单个数据存储区保存完全不同类型对象的一致性方式 属性图模型（Property Graph） 代表：Neo4j, Titan, InfiniteGraph 顶点（vertice）： 唯一标志 出边集合 入边集合 属性集合 边（edge）： 唯一标志 边开始顶点 边结束的顶点 标签 属性集合 三元图存储模型（Triplestore） 代表：Datomic, AllegroGraph 几乎等同于属性图模型，可能作为构建应用程序的补充 形式：(主体，谓语，客体) 主体相当于图中的顶点，客体则是以下两种之一： 原始数据类型中的值（字符串或数字），如 (lucy, age, 40) 图的另外一个顶点，如 (lucy, mariedTo, alain) 查询语言 Cypher，最早用于 Neo4j。声明式查询语言 SQL:1999 标准后，可以使用递归公用表达式（WITH RECURSIVE）来表示可变的遍历路径查询 SPARQL：采用 RDF 数据模型的三元存储查询语言 Datalog：数据模型采用「谓语（主体，客体）」模式；规则可以在不同的查询中组合和复用；对于简单查询虽然繁琐，但针对复杂数据，则更加灵活 数据存储和检索数据库核心：数据结构 索引可以帮助高效地查询数据库中特定的键；是基于原始数据派生而来的额外数据结构 任何类型的索引通常都会降低写的速度 哈希索引 以 Bitcast 为代表的存储引擎，采用了哈希索引 适合每个键的值更新频繁的场景 哈希索引的特点： 哈希表必须全部存放在内存中，键值指向的是文件段中的偏移，用于查找具体的数据 可采用分段的思想，再配合后台合并、压缩等手段来避免磁盘写入耗尽的问题，减少磁盘碎片 新的数据采用追加而非原地修改的策略，提高写入吞吐量 区间查询效率不高 SSTables 和 LSM-Tree SSTable 的全称：Sorted String Table，排序字符串表 LSM-Tree 的全称：Log-Structured Merge-Tree 相比哈希索引的优点： 合并段更简单高效，对于大文件也是如此 段文件中的 key-value 顺序是按照键排序过的，便于合并和查找 在文件中查找特定键时无需在内存中保存所有键的索引（稀疏索引放在内存中） 支持范围查找 构建和维护 SSTables 在内存中维护一个内存表，写入时先写入该表（有序的数据结构，如红黑树或者跳表） 内存表超过一定阈值时，直接写盘，形成 SSTable；在写盘同时，可添加新的内存表实例，接收后续写请求 对于读请求，内存表-&gt;最新磁盘段文件-&gt;次新段文件-&gt;…直到找到目标或者为空 后台定期合并、压缩，丢弃被覆盖或删除的值 避免崩溃的方式：每个写入记录到日志，当内存表写入 SSTable 后才可以丢弃相应日志 基于合并和压缩排序文件原理的存储引擎通常都叫作 LSM 存储引擎 性能优化： 分层压缩，LevelDB &amp; RocksDB 按大小分级，HBase, Cassandra 则两种都支持 布隆过滤器 B-Trees 广泛使用认可的索引结构，很多数据库中标准索引实现；即使在非关系数据库中也有用到 B-Tree 是面向块或者页进行设计的，它将数据库分解成固定大小的块或页，一般为 4 KB，页是内部读写的最小单元 每个页面都有标识符，可被引用 一个页所包含的页面引用数量称为分支因子 更新策略： 搜索包含指定键的子页 修改该页的值 整页回写到磁盘（相当于覆盖原先的页，对该页的任何引用依然有效） 新加键策略： 找到可容纳新键范围的页，然后添加到该页 若页面空间不足，则将其分裂为两个半满的页，同时修改父页，记录分裂后的新的键的范围 一个具有 N 个键的 B-Tree 的深度为 O(log N)；多数数据库可以适合 3~4 层 B-Tree。分支因子为 500 的 4KB 四级树可存储 256TB 的数据 崩溃恢复：WAL, Write-Ahead Log。通过该日志来恢复 需要考虑并发控制 写放大的问题（页分裂） 事务支持更加容易 事务处理（OLTP）和分析处理（OLAP） 二者对比： 大的企业会单独建立数仓，同步来自 OLTP 系统的数据，在单独的数仓中进行分析处理，不会影响线上业务 导入数仓：ELT, Extract-&gt;Transform-&gt;Load 常见数仓系统：Apache Hive, Spark SQL, Cloudera Implala 星型与雪花型分析模式 常见的是星型模式，也称为维度建模。特点是有一个事实表，关联了很多个维度表。事实表本身可能会很庞大，其中的每一行都代表一个事件，维度通常代表事件的Who, What, Where, When, How, Why 雪花❄️ 模型是星型模型的变体，它将维度进一步细分为子空间，从而更加规范化。但是这个会增加分析查询的复杂度，所以星型分析模式更受欢迎 列存储 数仓中的列通常很宽，有的可能多达 100 个 核心思想是将每列中的所有值存储在一起，所有的数据时存储在一组列文件中，每个文件都以相同顺序保存数据行 列压缩： 很容易进行压缩 常用位图编码，并配合游程编码降低存储空间（这个主要是针对零位稀疏的情况） 列排序： 可以根据查询需求选择排序的列 排序可帮助进一步压缩（重复值也可以采用简单的游程编码，所以即便是数十亿行也不怕） 基于第一个排序键的压缩效果通常最好 排序类似于关系数据库中用的索引，方便查询 写入可以采取类似 LSM-Tree 的思路 物化视图：查询结果的实际副本，被写入到磁盘了；虚拟视图则是用于编写查询的快捷方式 数据编码与演化数据编码格式 程序中至少有两种常用的数据表示形式： 内存中，数据保存在对象、结构体、列表、数组、哈希表和树等结构中，对于 CPU 的高效访问和操作做了优化 数据写入文件或者网络传输时，需要进行编码为字节序列 语言特定的格式 常见的包括： java.io.Serializable Ruby 中的 Marshal Python 中的 pickle 优点：对于某种语言自身来说，编解码会很方便，不需要引入第三方依赖 缺点： 与特定语言绑定，不利于和其它语言的异构系统通讯 可能会有安全性问题 兼容性不能保证 效率通常比较低，需要花费较多的 CPU 时间或者内存空间 JSON、XML 和二进制变体 JSON、CSV、XML 都是文本格式，可读性较好 存在的问题： 数字编码不明确（比如 CSV 中就无法区分是数字还是数字组成的字符串；JSON 中对于大于 2^53 的整数就傻眼了） 不支持二进制（虽然可以用 base64 搞事情，但是会增加空间和编解码的时间） CSV 无任何模式 XML 和 JSON 均有可选的模式 一些变种，它们的应用并不是很广泛： JSON（BSON、BJSON、UBJSON、BISON、Smile 和 Message Pack） XML（WBXML 和 Fast Infoset） 后面的🌰都以表达下面的信息为例，来做对照： 12345&#123; "userName": "Martin", "favoriteNumber": 1337, "interests": ["daydreaming", "hacking"]&#125; Message Pack 是 JSON 的二进制编码，示例如下： Thrift &amp; Protocol Buffers Thrift 是 Facebook 开发，2007~2008 年开源 Thrift 是一个比较完整的 RPC 框架，在它的协议层提供了多种 Protocol 的实现，方便应付多种场景。比如常见的 BinaryProtocol 和 CompactProtocol。 BinaryProtocol 编码示例： 与 Message Pack 编码相比，没有了字段名 使用了 field tag 来映射 IDL 定义的各个字段 CompactProtocol 编码示例： field tag 和 type 使用一个字节表示 field tag 使用了偏移计算 整数采用变长字节，而非 BinaryProtocol 中 1337 使用的 8 字节，换成变长字节只需要 2 字节即可 Protocol Buffers Google 开发，2007~2008 年开源 使用 PB 编码的示例： required 和 optional 这种修饰是不会体现在编码中的，而是在运行时做的检查 保证前后向兼容： field tag 至关重要，不可随便更改 optional 字段的 field tag 可以删除，但不要复用已删除的 field tag 新增字段必须是 optional 或者带有默认值，保证向后兼容 不可轻易修改 field 类型 Avro Apache Avro 是 Hadoop 的子项目，提供了两种模式语言：Avro IDL 和 JSON 格式 特点： 没有标签号 编码非常紧凑 编码中没有字段类型 编码示例： 区分读模式和写模式。写模式和读模式不必完全一模一样，只需要保持兼容 写模式和读模式中的字段顺序可不同，因为在模式解析时会使用字段名匹配 动态生成模式是最大的特点，不需要像 PB 或者 Thrift 中那样，显式分配 field tag，比较灵活。特别适合编码数据库表。 参考 数据密集型应用设计：第一部分 Thrift Protocol Buffers Avro Python Examples]]></content>
      <categories>
        <category>系统设计</category>
      </categories>
      <tags>
        <tag>《数据密集型应用设计》</tag>
        <tag>分布式</tag>
        <tag>数据模型</tag>
        <tag>数据库存储</tag>
        <tag>数据编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go 源码学习之 Context]]></title>
    <url>%2F2019%2F08%2F02%2Fgo-context-intro%2F</url>
    <content type="text"><![CDATA[引言在一次排查某 HTTP 接口请求频繁因 context canceled 错误导致请求处理失败的问题期间，深入了解了下 Go 语言的 Context 实现。本文将首先介绍我们是如何排查诡异的 context canceled 产生原因（也就是在哪儿因为什么而导致取消的）；接下来将深入介绍 Context 诞生的目的、源码解析及应用场景等，便于更进一步加深对它的理解；最后我们也会谈及使用 Context 的一些痛点。 排查 context canceled 的艰辛历程背景我们部署在生产环境的 HTTP 服务中提供了一个用于记录用户课程学习进度的接口，在 Sentry 中发现，有大量 context canceled 报错出现，导致在执行数据库查询时失败，从而导致完整的请求处理流程没有走完（用户的学习进度计算、业务方消息通知等没有执行）。但早期由于 Sentry 接入存在问题，导致错误记录没有上报；直到问题修复后，才在 Sentry 上观察到大量报错提示。由此，开启了定位 context canceled 问题之旅~ 报告详细错误日志我们首先对发生错误的位置，添加了更详细的错误日志，如请求上下文以及错误发生时的调用栈。待上线后，在 Sentry 中观察到了出错时详细的调用栈如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566File &quot;git.xixi.com/group/project-foo/pkg/models/prog/learn_progress.go&quot;, line 109, in Create d.Detect() File &quot;git.xixi.com/group/project-foo/pkg/controller/learn_progress.go&quot;, line 46, in Update success := learnProgress.Create(ctx, memberID, unitID, bizType, progress, clientUpdatedAt) != nil File &quot;git.xixi.com/group/project-foo/pkg/web/handlers/learn_progress.go&quot;, line 77, in Post success := h.ctrl.Update(h.R.Context(), memberID, unitID, bizType, progress, item.ClientUpdateAt) File &quot;/go/pkg/mod/git.xixi.com/bit/zerzura@v4.1.1+incompatible/rest/handler.go&quot;, line 53, in ServeHTTP render(handler.Post()) File &quot;/go/pkg/mod/github.com/go-chi/chi@v3.3.2+incompatible/mux.go&quot;, line 291, in func1 handler.ServeHTTP(w, r) File &quot;net/http/server.go&quot;, line 1995, in ServeHTTP f(w, r) File &quot;/go/pkg/mod/github.com/go-chi/chi@v3.3.2+incompatible/mux.go&quot;, line 424, in routeHTTP h.ServeHTTP(w, r) File &quot;net/http/server.go&quot;, line 1995, in ServeHTTP f(w, r) File &quot;/go/pkg/mod/git.xixi.com/bit/zerzura@v4.1.1+incompatible/rest/middleware/sentry_meta.go&quot;, line 19, in func1 next.ServeHTTP(w, r.WithContext(ctx)) File &quot;net/http/server.go&quot;, line 1995, in ServeHTTP f(w, r) File &quot;/go/pkg/mod/git.xixi.com/go/box@v0.0.0-20190710074902-1cbc4c2abdad/zapi/middleware/auth/nginx.go&quot;, line 200, in func1 next.ServeHTTP(w, r1) File &quot;net/http/server.go&quot;, line 1995, in ServeHTTP f(w, r) File &quot;/go/pkg/mod/git.xixi.com/go/box@v0.0.0-20190710074902-1cbc4c2abdad/zapi/context.go&quot;, line 67, in func1 next.ServeHTTP(w, r1) File &quot;net/http/server.go&quot;, line 1995, in ServeHTTP f(w, r) File &quot;/go/pkg/mod/github.com/go-chi/cors@v1.0.0/cors.go&quot;, line 199, in func1 next.ServeHTTP(w, r) File &quot;net/http/server.go&quot;, line 1995, in ServeHTTP f(w, r) File &quot;/go/pkg/mod/git.xixi.com/go/box@v0.0.0-20190710074902-1cbc4c2abdad/zapi/middleware/cors.go&quot;, line 51, in 1 defaultCORS.Handler(next).ServeHTTP(w, r) File &quot;net/http/server.go&quot;, line 1995, in ServeHTTP f(w, r) File &quot;/go/pkg/mod/github.com/go-chi/chi@v3.3.2+incompatible/middleware/heartbeat.go&quot;, line 21, in 1 h.ServeHTTP(w, r) File &quot;net/http/server.go&quot;, line 1995, in ServeHTTP f(w, r) File &quot;/go/pkg/mod/github.com/go-chi/chi@v3.3.2+incompatible/middleware/recoverer.go&quot;, line 35, in func1 next.ServeHTTP(w, r) File &quot;net/http/server.go&quot;, line 1995, in ServeHTTP f(w, r) File &quot;/go/pkg/mod/github.com/go-chi/chi@v3.3.2+incompatible/middleware/logger.go&quot;, line 46, in 1 next.ServeHTTP(ww, WithLogEntry(r, entry)) File &quot;net/http/server.go&quot;, line 1995, in ServeHTTP f(w, r) File &quot;/go/pkg/mod/git.xixi.com/go/box@v0.0.0-20190710074902-1cbc4c2abdad/zapi/middleware/realip.go&quot;, line 18, in func1 h.ServeHTTP(w, r) File &quot;net/http/server.go&quot;, line 1995, in ServeHTTP f(w, r) File &quot;/go/pkg/mod/git.xixi.com/go/box@v0.0.0-20190710074902-1cbc4c2abdad/zapi/middleware/sentry.go&quot;, line 83, in func1 next.ServeHTTP(w, r) File &quot;net/http/server.go&quot;, line 1995, in ServeHTTP f(w, r) File &quot;/go/pkg/mod/git.xixi.com/bit/zerzura@v4.1.1+incompatible/rest/middleware/stats.go&quot;, line 66, in 1 next.ServeHTTP(lw, r1) File &quot;net/http/server.go&quot;, line 1995, in ServeHTTP f(w, r) File &quot;/go/pkg/mod/github.com/go-chi/chi@v3.3.2+incompatible/mux.go&quot;, line 81, in ServeHTTP mx.handler.ServeHTTP(w, r) File &quot;net/http/server.go&quot;, line 2774, in ServeHTTP handler.ServeHTTP(rw, req) File &quot;net/http/server.go&quot;, line 1878, in serve serverHandler&#123;c.server&#125;.ServeHTTP(w, w.req) 由于我们是将请求的 Context 一直传递到最下层的，而在父 Context 收到取消信号后也会通知到子 Context，所以我们有理由相信这个取消的触发是在某个父 Context 节点。但具体是在哪儿，什么原因导致的并不清楚。 修复问题 &amp; 添加检测不过为了避免因为 sql/driver 层收到 Context Cancel 信号而导致查询失败，进而导致后续的处理流程未能执行，我们决定先修复问题，再排查原因。那怎么修复呢？其实非常简单，我们提供了一个不带 Cancel 的 Context 继续往 sql/driver 层传递，但该 Context 同样继承了父 Context 的 Value，这样一些元信息也可以被继续传递下去。同时为了在检查到原有子 Context 收到 Cancel 信号时，报告详细的错误和 Context String，我们也实现了一个简单的检测器。相关源码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344type noCancelCtx struct &#123; ctx context.Context&#125;func (c *noCancelCtx) Deadline() (time.Time, bool) &#123; return time.Time&#123;&#125;, false&#125;func (c *noCancelCtx) Done() &lt;-chan struct&#123;&#125; &#123; return nil&#125;func (c *noCancelCtx) Err() error &#123; return nil&#125;func (c *noCancelCtx) Value(key interface&#123;&#125;) interface&#123;&#125; &#123; return c.ctx.Value(key)&#125;func WithoutCancel(ctx context.Context) context.Context &#123; return &amp;noCancelCtx&#123;ctx: ctx&#125;&#125;type Detector struct &#123; where string isDone bool ctx context.Context&#125;func NewContextDoneDetector(ctx context.Context) *Detector &#123; return &amp;Detector&#123;ctx: ctx&#125;&#125;func (d *Detector) Detect() &#123; if d.isDone &#123; return &#125; select &#123; case &lt;-d.ctx.Done(): d.isDone = true var where string _, file, line, ok := runtime.Caller(1) if ok &#123; where = fmt.Sprintf("%s:%d", file, line) &#125; else &#123; where = "unknown" &#125; log.WithContext(d.ctx).Errorf("detect context done signal in \"%s\". context is %s", where, d.ctx) default: &#125;&#125; 然后对原有的业务代码进行一些改造如下：123456789101112131415161718192021222324// Create 创建用户学习进度func (learnProgressDB *LearnProgressDAO) Create(ctx context.Context, memberID int64, unitID int64, bizType int16, progress int32, clientUpdatedAt int64) *LearnProgress &#123; d := utils.NewContextDoneDetector(ctx) d.Detect() // ...此处省略 N 行 d.Detect() // 替换成不带 Cancel 的 Context ctxWithoutCancel := utils.WithoutCancel(ctx) result, err := db.Exec(ctxWithoutCancel, i, args...) // ...继续省略 d.Detect() object := db.QueryRow(ctxWithoutCancel, "SELECT id, member_id, unit_id, biz_type, progress, "+ "client_updated_at FROM learn_progress WHERE id = ?", id) learnProgress := &amp;LearnProgress&#123;&#125; d.Detect() err = object.Scan(&amp;learnProgress.ID, &amp;learnProgress.MemberID, &amp;learnProgress.UnitID, &amp;learnProgress.BizType, &amp;learnProgress.Progress, &amp;learnProgress.ClientUpdatedAt) if err != nil &#123; log.WithContext(ctx).WithError(err).Errorf("create and get progress %d error", id) return nil &#125; d.Detect() return learnProgress&#125; 在上线后，因为 context canceled 而导致请求处理流程不能走完的问题解决了。同时也报告出很多检查到上层 Context 取消的信号，详细的日志如下： 分析 HTTP Server 源码显然，从日志中可以看到有两处 Cancel Context 有极大的嫌疑，那么剩下的问题就是要确定这两个 Cancel Context 是怎么来的？这样，接下来我们再去确认是哪个 Cancel Context 在哪优先被 cancel 从而导致子节点收到了 ctx.Done() 信号，不就可以解答疑惑了吗？ 分析这棵 Context 树可以发现，我们优先去看 HTTP Server 处理请求部分的代码，就最容易找顺着请求处理的各个流程来定位到 Cancel Context 是在何处生成的，以及在何处会被调用的。 一般我们启动 Server 是调用了 ListenAndServe 接口，顺着该接口往下分析即可找到线索，详细的分析如下（和我们确定问题无关紧要的代码先忽略了）：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103// ListenAndServe 用于启动服务并监听指定的端口func (srv *Server) ListenAndServe() error &#123; addr := srv.Addr ln, err := net.Listen("tcp", addr) if err != nil &#123; return err &#125; return srv.Serve(tcpKeepAliveListener&#123;ln.(*net.TCPListener)&#125;)&#125;// Serve 用于接收请求连接，并为每个新的连接服务创建一个 service goroutine。func (srv *Server) Serve(l net.Listener) error &#123; // ... 此处省略不少 var tempDelay time.Duration // how long to sleep on accept failure // 这里创建了一个根 context baseCtx := context.Background() // base is always background, per Issue 16220 // 第一个 WithValue 正是 `http.&amp;contextKey&#123;"http-server"&#125;` ctx := context.WithValue(baseCtx, ServerContextKey, srv) for &#123; rw, e := l.Accept() // ...此处省略很多 c := srv.newConn(rw) c.setState(c.rwc, StateNew) // before Serve can return // 启动新的 service goroutine 处理连接服务，上面的 ctx 被传递进去了！！ go c.serve(ctx) &#125;&#125;// // serve 读取请求，并调用 `srv.Handler` 来处理请求，进而执行到业务逻辑，处理完请求后// 给客户端返回响应func (c *conn) serve(ctx context.Context) &#123; // 注意，这里添加了 `http.&amp;contextKey&#123;"local-addr"&#125;` 子 Context ctx = context.WithValue(ctx, LocalAddrContextKey, c.rwc.LocalAddr()) // ...此处省略很多 // HTTP/1.x from here on. // Bingo，这里看到了第一个 WithCancel 创建的子 Context 了 ctx, cancelCtx := context.WithCancel(ctx) c.cancelCtx = cancelCtx defer cancelCtx() c.r = &amp;connReader&#123;conn: c&#125; c.bufr = newBufioReader(c.r) // 注意这里的 checkConnErrorWriter，后面分析会涉及 c.bufw = newBufioWriterSize(checkConnErrorWriter&#123;c&#125;, 4&lt;&lt;10) for &#123; // readRequest 会返回一个 response，其中包括添加子 Cancel Context w, err := c.readRequest(ctx) // ...此处省略很多 // 注意这里的 startBackgroundRead，下面分析会看到 if requestBodyRemains(req.Body) &#123; registerOnHitEOF(req.Body, w.conn.r.startBackgroundRead) &#125; else &#123; w.conn.r.startBackgroundRead() &#125; // 调用 ServeHTTP，进而将请求传递到业务代码中，等待处理完毕 // 在上述日志中，我们可以看到，在这个调用没有结束的时候，context // 已经 cancel 了。而这个调用中 我们确认没有异步 cancel context 的代码 // 并且，`*http.response` 即 `w` 这个结构体中 `cancelCtx` 是个私有字段，不会 // 被外部访问到，所以不可能在 ServeHTTP 期间调用了 `cancelCtx` 函数 serverHandler&#123;c.server&#125;.ServeHTTP(w, w.req) // 通过对代码的分析，只有此处调用了一次 `*http.response` 里面的 cancelCtx // 所以我们确认导致下层收到 context cancel 信号的触发点不在此处！ w.cancelCtx() w.finishRequest() if !w.shouldReuseConnection() &#123; if w.requestBodyLimitHit || w.closedRequestBodyEarly() &#123; c.closeWriteAndWait() &#125; return &#125; // ... 此处省略 &#125;&#125;// readRequest 从连接中读取下一个请求func (c *conn) readRequest(ctx context.Context) (w *response, err error) &#123; // ...此处省略很多 // 可以看到第二个 cancel context 节点诞生了 ctx, cancelCtx := context.WithCancel(ctx) req.ctx = ctx // ...此处省略很多 w = &amp;response&#123; conn: c, cancelCtx: cancelCtx, req: req, reqBody: req.Body, handlerHeader: make(Header), contentLength: -1, closeNotifyCh: make(chan bool, 1), // We populate these ahead of time so we're not // reading from req.Header after their Handler starts // and maybe mutates it (Issue 14940) wants10KeepAlive: req.wantsHttp10KeepAlive(), wantsClose: req.wantsClose(), &#125; if isH2Upgrade &#123; w.closeAfterReply = true &#125; w.cw.res = w w.w = newBufioWriterSize(&amp;w.cw, bufferBeforeChunkingSize) return w, nil&#125; 根据详细打印的 Context 日志，并结合 HTTP Server 处理部分的代码分析，可以简单绘制出这棵 Context 树大体如下： 在进行 Server 处理连接请求的源码中，可以发现不太可能是第二个 Cancel Context 发送的取消信号。那么，问题只能出现在一个 Cancel Context 上面了。接下来，就看看 Connection 关联的 cancelCtx() 究竟会在哪几处调用？利用搜索可以找到如下两个嫌疑很大的地方：123456789101112131415161718// handleReadError 在从客户端读取失败时会被调用。这里的错误之所以// 被省略，是因为错误通常就是 io.EOF 或者 "use of closed network connection"// 标准库认为我们对具体报错不感兴趣，所以连 error 是什么在业务代码中是无法获取// 到的。// 总之，执行到此处，就意味着连接已经挂了，所以一定要通知取消 contextfunc (cr *connReader) handleReadError(_ error) &#123; cr.conn.cancelCtx() cr.closeNotify()&#125;func (w checkConnErrorWriter) Write(p []byte) (n int, err error) &#123; n, err = w.c.rwc.Write(p) if err != nil &amp;&amp; w.c.werr == nil &#123; w.c.werr = err w.c.cancelCtx() &#125; return&#125; 通过进一步分析，checkConnErrorWriter 只有在请求处理完毕，w.finishRequest() 时才可能会在某个时刻被调用。所以不可能是这里的 cancelCtx() 调用导致的，因为在报错时，显然还没有完成 ServeHTTP() 的流程。一通排查下来，只可能是在 handleReadError() 时报错了。结合网上的搜索信息，我们判断极有可能是客户端连接断开导致的大量报错，也就是说 handleReadError() 被调用才导致的。 添加 HTTP Middleware 监测连接断开那么我们如何验证的确是 connection closed 导致的呢？通过上面的代码可以看到，在处理错误时调用了 closeNotify() 方法，该方法会将 *http.response 的 closeNotifyCh 发送一个 true 值。进一步发现，*http.response 实现了接口 CloseNotifier，所以我们可以在代码中监听这个信号来进一步验证连接是不是真的断开了。 为此，我们实现了一个简单的中间件，启动一个 goroutine 去监听关闭信号，并在收到信号时向 Sentry 中打印相关报错：12345678910111213141516171819202122232425func MonitorCloseNotifier(next http.Handler) http.Handler &#123; return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) &#123; if r.Method == "GET" &amp;&amp; strings.EqualFold(r.URL.Path, "/check_health") &#123; next.ServeHTTP(w, r) &#125; else &#123; go func() &#123; defer func() &#123; if err := recover(); err != nil &#123; log.Warn(err) &#125; &#125;() cc := w.(http.CloseNotifier).CloseNotify() value := &lt;-cc ctx := context.WithValue( r.Context(), log.SentrySpecificMetaCtxKey, collectSentryMeta(r, "login_id"), ) log.WithContext(ctx).Errorf( "connection read error, maybe 'use of closed network connection' or 'io.EOF'. return value: %v", value) &#125;() next.ServeHTTP(w, r) &#125; &#125;)&#125; 在完成代码变更，并进行金丝雀小流量验证时，在 Sentry 上看到了相关的报错。由此确认是在何处因为什么导致了 Context Cancel。 小结历经多次代码变更和日志分析才最终确定在何处因为什么导致了 Context Cancel，整个过程非常坎坷。那为什么没有直接进行调试呢？那样定位问题不是更快速些吗？原因是这样，最开始我们并不知道什么原因导致的；这样也就没法在本地复现问题，由于这些问题是在线上产生的，也不大可能直接在线上拦截用户请求并调试，那样可能更加繁琐、耗时，且实施成本更大（因为我们也不知道哪个用户使用什么设备在什么时候会发生问题）。 所以采取分析错误日志加验证的方式来确定问题所在。当然，之所以这么麻烦也是因为 Context Cancel 时提供的 Error 太单一了。如果最初 API 设计时就能提供自定义的错误，那么我们可以根据具体错误来定位到可能产生报错的位置，这样会更加快捷！ Contextcontext 包最初是由 Google 官方开发，并在 Go 1.7 版本正式引入到标准库中的。引入该包的目的是为了提供统一的姿势处理超时、取消信号传递和在 API 之间传递请求上下文数据。它提供了几个重要的接口用于创建 Context 树🌲： WithCancel WithDeadline WithTimeout WithValue 这些接口会接收一个 parent context，并返回一个 derived context。在我们的代码中，应该层层传递该 context，一般约定函数的第一个参数就是 context，签名类似：func foo(ctx context.Context)。 对于 WithCancel, WithDeadline, WithTimeout 而言，它们都会返回 cancelFunc 供使用者调用。当 cancelFunc 被调用时，除了自身会被取消外，其子 context 都会被取消。示例图如下： 源码分析Context InterfaceContext 本身是一个接口，其定义如下：123456789101112131415161718192021type Context interface &#123; // Deadline 会返回什么时间 context 会被取消。如果没有设置 // 过期时间，则 ok 返回 false。 Deadline() (deadline time.Time, ok bool) // Done 在 context 被取消时对应的 channel 会被关闭，从而达到 // 通知正在监听的 goroutine 终止手头工作的目的。对于不可取消的 // context，则返回 nil。 // 对于 WithCancel, WithDeadline, WithTimeout 而言，最终都会 // 关闭 done channel。 Done() &lt;-chan struct&#123;&#125; // Err 会在 Done 被关闭时，返回错误（这里的错误在 context 包内仅限 Canceled 和超时 DeadlineExceeded） Err() error // Value 用于返回存储在 Context 中指定 key 对应的上下文数据。如果找不到就返回空。 // 这里如果在当前 context 找不到，就会一直往上找 parent 直到根节点。 // 仅限于使用 Context 存储一些请求相关（request-scoped）数据，并在应用中传递， // 对于一些额外的参数，传递绝对不推荐使用它！ Value(key interface&#123;&#125;) interface&#123;&#125;&#125; TODO &amp; Background在 context 包中定义了两种 emptyCtx，分别是 todo 和 background。相关实现非常简单：123456789101112131415161718// emptyCtx 是不会被取消，无任何值和 deadline 的。之所以没有使用空结构体（struct&#123;&#125;）// 是因为要保证该类型的每个值都要有不同的地址type emptyCtx intfunc (*emptyCtx) Deadline() (deadline time.Time, ok bool) &#123; return &#125;func (*emptyCtx) Done() &lt;-chan struct&#123;&#125; &#123; return nil &#125;func (*emptyCtx) Err() error &#123; return nil &#125;func (*emptyCtx) Value(key interface&#123;&#125;) interface&#123;&#125; &#123; return nil &#125;var ( background = new(emptyCtx) todo = new(emptyCtx))// Background 通常在 main 函数、测试中初始化，或者请求对应的顶层 Contextfunc Background() Context &#123; return background &#125;// TODO 通常在不知道该用什么 Context 的时候，可以使用它func TODO() Context &#123; return todo &#125; WithCancel我们通常使用 WithCancel() 接口来创建一个可被取消的 Context，该接口会返回一个新的子 Context 节点和用于取消时调用的函数 cancelFunc。相关源码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061// CancelFunc 通知取消任务，不会等待任务执行完毕；只能被有效调用一次type CancelFunc func()// WithCancel 会返回一个 parent 的拷贝，同时带有 Done channel。// 取消该 context 时会释放关联的资源，所以当该 Context 完成时需要尽快调用 cancelfunc WithCancel(parent Context) (ctx Context, cancel CancelFunc) &#123; c := newCancelCtx(parent) propagateCancel(parent, &amp;c) return &amp;c, func() &#123; c.cancel(true, Canceled) &#125;&#125;// newCancelCtx 会返回一个初始化好的 cancelCtx 实例// 关于什么是 cancelCtx 会在下面分析它的源码func newCancelCtx(parent Context) cancelCtx &#123; return cancelCtx&#123;Context: parent&#125;&#125;// propagateCancel 本质上是为了将子 canceler 挂载到父 canceler 节点上// 这样在父节点收到取消通知时，才能一一通知到子节点func propagateCancel(parent Context, child canceler) &#123; if parent.Done() == nil &#123; // parent 不支持取消的情况 return // parent is never canceled &#125; // 这里只是判断是不是有 context 包中定义的 // cancelCtx 结构而已 // parentCancelCtx(parent) 确认 parent 是否为 // cancelCtx 或者 timerCtx 类型 if p, ok := parentCancelCtx(parent); ok &#123; p.mu.Lock() if p.err != nil &#123; // parent has already been canceled // parent 如果被取消，自然不需要 removeChild，因为 // parent 对应的子树会被 detatch 掉，确保释放资源 child.cancel(false, p.err) &#125; else &#123; // 延迟初始化了 children if p.children == nil &#123; // 为什么是放在字典，而非列表呢？ // 原因很简单，是为了方便删除 child // delete(p.children, child) p.children = make(map[canceler]struct&#123;&#125;) &#125; // 把子节点挂载到 cancel context 的父节点上 p.children[child] = struct&#123;&#125;&#123;&#125; &#125; p.mu.Unlock() &#125; else &#123; go func() &#123; select &#123; case &lt;-parent.Done(): // 对于父节点返回 Done channel 的进行监听 child.cancel(false, parent.Err()) case &lt;-child.Done(): // 等待 cancel ctx 被结束 // 这里只可能是 timerCtx, cancelCtx // goroutine 退出 &#125; &#125;() &#125;&#125; 对于可被取消的 Context 都实现了下面的接口：123456// canceler 就是实现了 cancel 的 context 类型。在标准库中// 仅有 `cancelCtx` 和 `timerCtx` 实现了该接口type canceler interface &#123; cancel(removeFromParent bool, err error) Done() &lt;-chan struct&#123;&#125;&#125; 在分析 WithCancel 的源码时，可以发现，我们创建了一个 cancelCtx 实例，并将原有的 Context 作为父节点记录了下来。那么 cancelCtx 是怎么实现的呢？又是如何处理取消逻辑的呢？123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// A cancelCtx can be canceled. When canceled, it also cancels any children// that implement canceler.type cancelCtx struct &#123; // Context 会指向 parent Context // mu 用来保证 goroutine 安全 mu sync.Mutex // protects following fields done chan struct&#123;&#125; // created lazily, closed by first cancel call // 之所以使用字典来存储，是因为不关心子节点顺序，同时为了方便删除 children map[canceler]struct&#123;&#125; // set to nil by the first cancel call err error // set to non-nil by the first cancel call&#125;// Done 会返回一个延迟初始化的 chan 供下游监听完成信号func (c *cancelCtx) Done() &lt;-chan struct&#123;&#125; &#123; c.mu.Lock() if c.done == nil &#123; // 延迟初始化 c.done = make(chan struct&#123;&#125;) &#125; d := c.done c.mu.Unlock() return d&#125;func (c *cancelCtx) Err() error &#123; c.mu.Lock() err := c.err c.mu.Unlock() return err&#125;// cancel 负责关闭 c.done chan，同时取消每个子节点// 并根据需要将对应的节点从它的父节点的 children 中移除func (c *cancelCtx) cancel(removeFromParent bool, err error) &#123; if err == nil &#123; panic("context: internal error: missing cancel error") &#125; c.mu.Lock() if c.err != nil &#123; c.mu.Unlock() return // already canceled &#125; c.err = err if c.done == nil &#123; // 确保下次调用时已经关闭了 c.done = closedchan &#125; else &#123; close(c.done) &#125; for child := range c.children &#123; // NOTE: acquiring the child's lock while holding parent's lock. // 依次 cancel 所有的子节点 child.cancel(false, err) &#125; c.children = nil c.mu.Unlock() if removeFromParent &#123; removeChild(c.Context, c) &#125;&#125; WithDeadline &amp; WithTimeout如果我们需要对 goroutine 设置超时或者到达指定时间后退出的话，就可以使用 WithDeadline() 或 WithTimeout() 来实现。 1234567891011121314151617181920212223242526272829303132333435363738// WithDeadline 会创建一个带有到期时间控制的 context，在时间到达后会自动// 关闭 done channel，同时下游的节点也会收到取消通知。需要注意的是，对于// 这种类型的 cancel，对应的 Error 是 DeadlineExceeded// 另外，返回的 cancelFunc 一定要被调用一次，确保资源最终能被释放func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) &#123; // 如果父节点提前结束，则不用再为子节点添加额外的计时资源了 // 因为当父节点结束时，子节点也会被通知到 if cur, ok := parent.Deadline(); ok &amp;&amp; cur.Before(d) &#123; // 这里，如果说已经到期了，自然没必要引入一个计时器资源 // 所以直接返回一个 Cancel Context 了 return WithCancel(parent) &#125; c := &amp;timerCtx&#123; cancelCtx: newCancelCtx(parent), deadline: d, &#125; propagateCancel(parent, c) dur := time.Until(d) if dur &lt;= 0 &#123; // 如果指定的时间点已经过了的话，则直接取消 c.cancel(true, DeadlineExceeded) return c, func() &#123; c.cancel(false, Canceled) &#125; &#125; c.mu.Lock() defer c.mu.Unlock() if c.err == nil &#123; c.timer = time.AfterFunc(dur, func() &#123; // 当时间到了后，会执行 cancel 方法 c.cancel(true, DeadlineExceeded) &#125;) &#125; return c, func() &#123; c.cancel(true, Canceled) &#125;&#125;// WithTimeout 指定超时时间的 Context，其实就是复用了 WithDeadline 方法func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) &#123; return WithDeadline(parent, time.Now().Add(timeout))&#125; timerCtx 是实现带定时功能的 Context 类型，它的实现比较简单：12345678910111213141516171819202122type timerCtx struct &#123; cancelCtx timer *time.Timer // timer 资源的访问是由 cancelCtx 中的 Lock 来保障的 deadline time.Time&#125;func (c *timerCtx) Deadline() (deadline time.Time, ok bool) &#123; return c.deadline, true &#125;// cancel 主要在 timerCtx 取消时，释放掉 timer 资源func (c *timerCtx) cancel(removeFromParent bool, err error) &#123; // 将当前节点的 done channel close 掉，同时取消相关子节点 c.cancelCtx.cancel(false, err) if removeFromParent &#123; removeChild(c.cancelCtx.Context, c) &#125; c.mu.Lock() if c.timer != nil &#123; // 释放 timer 资源 c.timer.Stop() c.timer = nil &#125; c.mu.Unlock()&#125; WithValue通常使用 WithValue() 方法给 Context 附加一些请求相关的上下文数据，它的实现如下：1234567891011121314151617181920212223func WithValue(parent Context, key, val interface&#123;&#125;) Context &#123; if key == nil &#123; panic("nil key") &#125; // 保证 Key 本身是可比较的即可 if !reflectlite.TypeOf(key).Comparable() &#123; panic("key is not comparable") &#125; return &amp;valueCtx&#123;parent, key, val&#125;&#125;type valueCtx struct &#123; Context key, val interface&#123;&#125;&#125;func (c *valueCtx) Value(key interface&#123;&#125;) interface&#123;&#125; &#123; if c.key == key &#123; return c.val &#125; // 往 parent 去找，一直找到为止 return c.Context.Value(key)&#125; 应用场景传递请求相关的数据使用 WithValue 将需要的请求数据存储在 Context 中，方便向下传递。我们一般要尽量避免在业务代码中直接解析 Context 中的某些 Key。 12345678910111213141516171819202122232425262728293031type contextKey struct&#123; name string &#125;var ( // 不要使用 string key，避免冲突 traceIDCtxKey = &amp;contextKey&#123;name: "request-trace-id"&#125;)// 建议使用函数封装下，对外提供统一的接口方便使用func WithTraceID(ctx context.Context, id string) context.Context &#123; return context.WithValue(ctx, traceIDCtxKey, id)&#125;func TraceIDFrom(ctx context.Context) string &#123; if traceID, ok := ctx.Value(traceIDCtxKey).(string); ok &#123; return traceID &#125; else &#123; return "" &#125;&#125;func exampleWithValue(ctx context.Context) &#123; doStuff := func(ctx context.Context) &#123; traceID := TraceIDFrom(ctx) fmt.Printf("got request trace id: %s\n", traceID) &#125; // 模拟传递请求 trace id，这些可以被日志框架等提取并存储到日志中 id, _ := uuid.GenerateUUID() ctx = WithTraceID(ctx, id) doStuff(ctx)&#125; 超时控制1234567891011121314151617181920212223242526// exampleWithTimeout 模拟一组请求，并且假设每个请求处理时间为 0~3 秒的随机时间// 同时我们将超时时间设置为 1 秒，这样在请求期间就会有些因为超时而主动结束后续执行流程// 的 goroutine 收到取消信号func exampleWithTimeout(ctx context.Context) &#123; doRequest := func(ctx context.Context, id int) &#123; // 模拟请求 time.Sleep(time.Duration(rand.Int63n(3)) * time.Second) select &#123; case &lt;-ctx.Done(): fmt.Printf("[%d]request canceled\n", id) default: // 处理其它业务逻辑 &#125; &#125; ctx, cancel := context.WithTimeout(ctx, time.Second*1) defer cancel() var wg sync.WaitGroup for i := 0; i &lt; 10; i++ &#123; wg.Add(1) go func(id int) &#123; defer wg.Done() doRequest(ctx, id+1) &#125;(i) &#125; wg.Wait()&#125; 总结 不建议将 Context 存放在结构体中，而应该作为参数显式传递；一般接收 Context 作为参数的函数，应该将该参数放在第一个参数位置（这个是惯例了）； 在给函数传递 Context 时，如果不知道用什么 Context，就可以使用 Context.TODO()，避免传递 nil Context Value 需要有约束，必须应该符合请求相关的上下文数据，并且一般是在框架或者 HTTP 中间件中设置 Value，业务代码中尽可能避免直接操作 Context Value。在我们的业务代码中应当显式传参，这样可以利用静态语言的特性，使得一些问题可以在编译阶段就能发现；不要为了图方便，用 Context 带一些可选参数。 在使用 WithValue(key, value) 时，Key 应该避免使用字符串，防止名字冲突和污染； 在使用 WithCancel, WithTimeout, WithDeadline 时，一定要保证返回的 cancel 方法至少被调用一次，避免 goroutine 泄露或者其它资源泄露； 由于目前在标准库以及一些第三方库中都在使用 Context，一路传递下来，整体链路很长。而当发生 Context Cancel 时，排查起来就非常麻烦。所以需要对所使用各类框架或者库在整个执行过程的生命周期需要有一定的了解，再配合日志等手段进行排查起来会更加有效。 参考 Go语言实战笔记（二十）| Go Context Go Concurrency Patterns: Context How to correctly use context.Context in Go 1.7 Go 1.7 httptrace and context debug patterns Go: Context and Cancellation by Propagation How to correctly use context.Context in Go 1.7 深入理解 Golang HTTP Timeout Pitfalls of context values and how to avoid or mitigate them in Go]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>Go</tag>
        <tag>标准库</tag>
        <tag>源码学习</tag>
        <tag>Context</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSS 学习笔记]]></title>
    <url>%2F2019%2F07%2F16%2Fcss-learning-notes%2F</url>
    <content type="text"><![CDATA[引言从 0 到 1 实现一个网站，前端部分自然是要了解 CSS 的。CSS 的全称是 Cascading Style Sheets，它是一种专门用于给结构化文档（如 Web HTML）添加样式的语言。我们可以通过使用 CSS 来为网页布局，设定字体的样式，设定动画等，让我们的网站更加炫酷，更加现代化。而这些通过传统的编程语言来实现会非常繁琐，使用 CSS 只需要按需定义即可，极大地提高了开发效率。本篇笔记主要是记录核心的 CSS 技巧，相关的练习位于 GitHub learning-css 仓库。 CSS 基础 多重样式优先级顺序（依次增加）： 通用选择器（*） 元素（类型）选择器 类选择器 属性选择器 伪类 ID 选择器 内联样式 !important 规则在被应用样式声明中时，该样式声明会覆盖 CSS 中任何其他的声明，使用它并非好习惯： Always：要优化考虑使用样式规则的优先级来解决问题，而非 !important Only：只有在需要覆盖全站或外部 CSS 的特定页面中使用它 Never：永远不要在全站范围使用它 Never：永远不要在你的插件中使用它 CSS 链接样式： 四种特殊状态可以分别设置： a:link: 正常，未访问过的链接 a:visited: 已访问过的链接 a:hover: 鼠标放在链接上时 a:active: 链接被点击的那刻 上述顺序很重要，简记：L(ink)OV(isited)E and H(over)A(ctive)TE 所有的 HTML 元素都可以看做是一个 Box。CSS 盒模型本质上就是封装了 HTML 元素的盒子。图示如下： 当指定 CSS 元素的高度和宽度时，只是在设置内容区域的高度和高度。实际元素尺寸计算： 总宽度 = 内容宽度 + 左填充 + 右填充 + 左边框 + 右边框 + 左边距 + 右边距 总高度 = 内容高度 + 顶部填充 + 底部填充 + 上边框 + 下边框 + 上边距 + 下边距 盒样式应用（适用于 margin, padding 等简写样式的情况）： 四个值：a, b, c, d -&gt; 上，下，左，右（逆时针方向） 三个值：a, b, c -&gt; 上，左右，下 两个值：a, b -&gt; 上下，左右 一个值：a -&gt; 上下左右 outline 是在 border 外部的，在元素周围绘制出元素的边缘，起到突出元素的作用。使用方式类似 border，可设定的属性包括：outline-style, outline-color, outline-width 等。需要注意的是，outline 是不占空间的，不会增加额外的宽度和高度。outline 也可能是非矩形的，和浏览器实现有关。 margin &amp; padding： 隐藏元素： display:none：不会占据空间，会从布局中移除 visibility:hidden：会占据空间，影响布局 块（ block）元素： 占据全部宽度，并且会产生换行 width, height, padding, margin 都是可控制的 块元素：&lt;address/&gt;, &lt;blockquote/&gt;, &lt;center/&gt;, &lt;dir/&gt;, &lt;div/&gt;, &lt;dl/&gt;, &lt;fieldset/&gt;, &lt;form/&gt;, &lt;h1/&gt;, &lt;h2/&gt;, &lt;h3/&gt;, &lt;h4/&gt;, &lt;h5/&gt;, &lt;h6/&gt;, &lt;hr/&gt;, &lt;isindex/&gt;, &lt;menu/&gt;, &lt;noframes/&gt;, &lt;noscript&gt;, &lt;ol/&gt;, &lt;p/&gt;, &lt;pre/&gt;, &lt;table/&gt;, &lt;ul/&gt;, &lt;li/&gt; 内联（inline）元素： 只占据必要的宽度，不会换行 width, height, padding-top, padding-bottom, margin-top, margin-bottom 都不可改变 内联元素：&lt;a/&gt;, &lt;abbr/&gt;, &lt;acronym/&gt;, &lt;b/&gt;, &lt;bdo/&gt;, &lt;big/&gt;, &lt;br /&gt;, &lt;cite/&gt;, &lt;code/&gt;, &lt;dfn/&gt;, &lt;em/&gt;, &lt;font/&gt;, &lt;i/&gt;, &lt;img/&gt;, &lt;input/&gt;, &lt;kbd/&gt;, &lt;label/&gt;, &lt;q/&gt;, &lt;s/&gt;, &lt;samp/&gt;, &lt;select/&gt;, &lt;small/&gt;, &lt;span/&gt;, &lt;strike/&gt;, &lt;strong/&gt;, &lt;sub/&gt;, &lt;sup/&gt;, &lt;textarea/&gt;, &lt;tt/&gt;, &lt;u/&gt;, &lt;var/&gt; 主要使用的三种样式： display:block：显式为块元素 display:inline：显示为内联元素 display:inline-block：显示为内联块元素，表现为同行显示，同时可以修改 width/height/padding/margin 等，效果如下： CSS 定位（Position）： static：元素默认定位方式，不受 top/bottom/left/right 的影响 relative：相对正常位置的偏移；原本空间依然会被预留出来，可能会与别的元素重叠 fixed：元素的位置相对于浏览器窗口是固定的，会和其它元素重叠；元素的位置和文档流无关，不占据空间 absolute：绝对定位的元素的位置是相对于最近的已定位父元素，若元素无已定位父元素，则它的位置是相对于 ；与文档流无关，不占据空间，会与其它元素重叠 sticky：粘性定位，与滚动有关，受限于浏览器 可以使用 overflow 指定当内容溢出时的行为（可选择是否展示滚动条），但其只可用于指定了高度的块元素上 元素的浮动： 会让元素向左或向右浮动，周围元素也会重新排列 元素水平浮动，意味着只能左右移动 浮动元素会尽量向左或向右移动，直到它的外边缘碰到包括框或另一个浮动框的边缘为止 设置居中： 元素居中：可以通过 margin: auto 解决，但是必须要设置元素的宽度 文本居中：可使用 text-align 组合选择器： 后代选择器：div p 子元素选择器：div&gt;p 相邻兄弟选择器：div+p 普通兄弟选择器：div~p 伪类（pseudo-classes）： 用于添加一些选择器的特殊效果 伪类选择的元素是基于当前元素所处的状态，或者是元素所具有的特性，而非静态标志（如 class, id, 属性）。而状态是动态的，所以当一个元素到达一个特定状态的时候，可能得到一个伪类的样式；当状态改变时，它会失去这个样式。基于文档之外的抽象，故称为伪类。 语法： selector:psedudo-class { property: value } selector.class:pseudo-class { property: value } 伪类名称不区分大小写 示例：a:hover { color: red } 伪元素（pseudo-element）： 用于添加一些选择器的特殊效果 语法：类似伪类 伪元素是对元素中特定内容选择并操作，操作层次要比伪类更深，动态性比伪类低。设计伪元素的目的就是选取诸如第一个字母（行）等，选取内容的前后并操作等，这些普通的选择器是无法完成的。本身是基于元素的抽象，不存在于文档中，故称为伪元素。 属性选择器： 语法：&lt;element&gt;[attr] { } 或者 &lt;element&gt;[attr&lt;op&gt;value]{ } 选择范围： =: equal_word *=: 相当于 contains，如 &lt;p title=&quot;buyfflowerrr&quot;&gt;&lt;/p&gt; ~=: 相当于 contains_word，如 &lt;p title=&quot;buy flower&quot;&gt;&lt;/p&gt; 中的 flower |= : 相当于 starts_with_word，当然这里的单词应是唯一的，或者是用 - 分隔的 ^=: 相当于 starts_with $=: 相当于 ends_with CSS 3 简记 CSS 3 被拆分成了「模块」，一些重要的模块如下： 选择器 盒模型 背景和边框 文字特效 2D/3D 转换 动态 多列布局 用户界面 渐变（Gradients）： 线性渐变（Linear Gradients）：向下/向上/向左/向右/对角线 径向渐变（Radius Gradients）：由相应的中心定义 语法：background: linear-gradient (direction, color-stop1, color-stop2, ...) box-shadow 顺序： 2D 转换： translate, translateX, translateY rotate, rotateX, rotateY scale, scaleX, scaleY skew, skewX, scaleY matrix： 接收六个参数：a, b, c, d, tx, ty 对照： 位移：matrix(1, 0, 0, 1, tx, ty) = translate(tx + &quot;px&quot;, ty + &quot;px&quot;) 缩放：matrix(sx, 0, 0, sy, 0, 0) = scale(sx, sy) 旋转：matrix(cosθ, sinθ, -sinθ, cosθ, 0, 0) = rotate(θ + &quot;deg&quot;) 倾斜：matrix(1, tan(θy), tan(θx), 1, 0, 0) = skew(θx + &quot;deg&quot;, θy + &quot;deg&quot;) 计算方式： 过渡效果：transition: property duration timing-function delay 其中，默认情况下，duration 为 0，所以如果不设置该值，将看不到效果 过渡动画时间曲线： ease：默认值 linear ease-in ease-out ease-in-out cubic-bezier(n, n, n, n)：贝塞尔曲线函数，可以通过指定值来实现上述效果，同时可以自定义其它值实现自定义效果 关键帧动画： 使用 @keyframes 创建动画，可以使用 n% 设定处于不同阶段时的属性，而 from 和 to 分别代表 0% 和 100% 使用 animation 属性绑定动画到选择器上，需要设定两个值： 动画名称 动画时长 Flex 布局： 当页面需要适应不同的屏幕大小及设备类型时，确保元素拥有恰当的行为布局方式 提供一种更加有效的方式对一个容器中的子元素进行排列、对齐和分配空间 组成： Flex container Flex item 属性设置：display: flex/inline-flex 设置主轴对齐方式：justify-content 设置侧轴对齐方式：align-items 设置换行：flex-wrap 设置各个行的对齐方式：align-content 参考 菜鸟教程：CSS block, inline-block 对比 Understanding the CSS Transforms Matrix CSS 2D 转换详解 CSS 3 中 Flex 弹性布局该如何灵活运用？ 30 分钟学会 Flex 布局 Flex 布局对性能的影响主要体现在哪方面？]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>CSS</tag>
        <tag>布局</tag>
        <tag>样式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redux 简记]]></title>
    <url>%2F2019%2F07%2F03%2Freact-redux-notes%2F</url>
    <content type="text"><![CDATA[引言根据官网介绍，Redux 是一个 JavaScript 状态管理容器，提供了可预测的状态管理能力。可以构建一致的应用，运行于多种环境下（客户端、服务器和原生应用等），且易于测试（甚至都不要在写界面之前进行测试）。 概念核心思想Redux 的核心就是管理状态，所有的状态是在 store 对象树中维护。使用 action 来描述 state 变化，而为了能够将 action 和 state 串联在一块，就有了 reducer 函数，它负责根据不同的 action dispatch 到不同的分支，然后返回新的状态。需要注意的是，reducer 是纯函数，不应该 inplace 那种方式修改 state，而是生成新的 nextState 并返回。通常一个应用中可能有多个小的 reducers ，我们可以使用 combineReducers 将它们组合在一起。 三大原则 单一数据源：整个应用的 state 是存储在一个 obj tree 中的，并且该 obj tree 只存在于唯一一个 store 中 state 是只读的：唯有触发 action 才会改变 state，使用 action 来描述发生了什么 使用纯函数执行修改：需要编写 reducer 实现状态改变 三驾马车Action Action 是把数据从应用传递到 store 的有效载荷，是 store 数据的唯一来源 一般通过 store.dispatch() 分发 action，传递到 store 当应用规模变大时，建议将 Action 使用单独的模块存放 尽量减少在 action 中传递的数据 Action 创建函数：返回 action 的函数，使用 bindActionCreators() 可以自动将多个 action 创建函数绑定到 dispatch() 方法上 Action 只是描述了有事情发生了这样的事实，但不会描述应用如何更新 state Reducer 在 reducer 中响应 action，并产生新的 state，达到改变 state 的目的 为什么叫 reducer？参考 Array.prototype.reduce(reducer, ?initialValue) 里面的回调函数，它们比较类似，都必须是纯函数。reducer 函数不欢迎如下操作： 修改传入参数 执行含有副作用的操作，如 API 请求和路由跳转 调用非纯函数，如 Date.now() 或 Math.random() 可以把所有顶级 reducer 放在独立的文件中，通过 export 暴露每个 reducer 函数： 1234import &#123; combineReducers &#125; from 'redux'import * as reducers from './reducers'const todoApp = combineReducers(recuders) Store Store 的职责如下： 维持应用的 state 提供 getState() 读取状态 提供 dispatch(action) 方法更新状态-提供 subscribe(listener) 方法注册监视器，其返回的函数用于注销监视器 Redux 应用的 store 只会有一个，一般会根据业务逻辑来拆分子状态分组，可以通过 reducers 组合完成 createStore(reducer, ?initialState) 创建应用 store 示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107import React, &#123; useRef &#125; from 'react'import ReactDOM from 'react-dom'import &#123; createStore, combineReducers &#125; from 'redux'function todos(state = [], action) &#123; switch (action.type) &#123; case 'ADD_TODO': console.log('Add todo: ' + action) return [ ...state, todo(undefined, action) ] case 'REMOVE_TODO': console.log('Remove todo: ' + action) return state.map((item) =&gt; todo(item, action)) case 'TOGGLE_TODO': console.log('Toggle todo: ' + action) return state.map((item) =&gt; todo(item, action)) default: return state &#125;&#125;function todo(state, action) &#123; switch (action.type) &#123; case 'ADD_TODO': return &#123; id: action.id, text: action.text, completed: action.completed, isDeleted: false, &#125; case 'REMOVE_TODO': if (state.id !== action.id) &#123; return state &#125; return &#123; ...state, isDeleted: true &#125; case 'TOGGLE_TODO': if (state.id !== action.id) &#123; return state &#125; return &#123; ...state, completed: !state.completed &#125; default: return state &#125;&#125;const todoApp = combineReducers(&#123; todos&#125;)const store = createStore(todoApp)let nextTodoId = 0function TodoItem(&#123; todo &#125;) &#123; return ( &lt;li&gt; &lt;label style=&#123;&#123; textDecoration: todo.completed ? 'line-through' : 'none' &#125;&#125; onClick=&#123;() =&gt; store.dispatch(&#123; type: 'TOGGLE_TODO', id: todo.id &#125;)&#125; &gt; &#123;todo.text&#125; &lt;/label&gt; &lt;button style=&#123;&#123; marginLeft: 10 &#125;&#125; onClick=&#123;() =&gt; &#123; store.dispatch(&#123; type: 'REMOVE_TODO', id: todo.id &#125;) &#125;&#125; &gt;移除&lt;/button&gt; &lt;/li&gt; )&#125;function TodoApp(&#123; todos = [] &#125;) &#123; const todoItems = todos .filter((todo) =&gt; !todo.isDeleted) .map((todo) =&gt; &lt;TodoItem key=&#123;todo.id&#125; todo=&#123;todo&#125; /&gt;) const input = useRef() const handleClick = () =&gt; &#123; const text = input.current.value if (!text) &#123; return &#125; store.dispatch(&#123; type: 'ADD_TODO', id: nextTodoId++, text: input.current.value &#125;) &#125; return ( &lt;div&gt; &lt;input ref=&#123;input&#125; /&gt; &lt;button onClick=&#123;handleClick&#125; style=&#123;&#123; marginLeft: 10 &#125;&#125;&gt;添加&lt;/button&gt; &lt;ul&gt; &#123;todoItems&#125; &lt;/ul&gt; &lt;/div&gt; )&#125;const render = () =&gt; &#123; const state = store.getState() ReactDOM.render( &lt;TodoApp todos=&#123;state.todos&#125; /&gt;, document.getElementById('root') )&#125;store.subscribe(() =&gt; &#123; console.log(store.getState()) render()&#125;)render() 实践按照 Redux 提供的几个官方示例，可以看出编写一个简单的 Todo 应用其实要考虑的还是挺多的，尤其是需要在分散的模块中分别定义 actions, reducers, containers, dumb components 等，然后搭配 react-redux 来实现整体功能。以下是一个经典的 React Redux 应用的示例的文件结构： 12345678src/ actions/ components/ consts/ containers/ reducers/ sotore.js index.js 看起来，分层结构很明晰。但这里有几个很大的问题： components 和 containers 可能会出现相互引用的问题； 对于某些情形，严格区分 smart components 和 dumb components 比较死板； 编写起来很复杂、啰嗦、冗余。 针对这个痛点，可以借助 rematch 框架解决。它本质上是一个基于 Redux 封装的框架，目的是提供最佳的 Redux 实践，减少大量的样板代码编写，解放生产力！ 使用 Rematch 时，有个非常重要的概念叫做 model。你可以在 models 里面将状态、引起状态变化reducers 及异步 actions 和 action creators 收敛到一起，方便维护和测试。总的来说，model 定义包含如下几个部分： state: 初始状态是什么 reducers: 如何改变状态 effects: 处理异步的 actions，带有副作用的操作 一个典型的 model 定义如下： 12345678910111213141516export const count = &#123; state: 0, // initial state reducers: &#123; // 使用同步函数，处理状态变更 increment(state, payload) &#123; return state + payload &#125; &#125;, effects: (dispatch) =&gt; (&#123; // 使用纯函数处理状态变更（异步 actions） async incrementAsync(payload, rootState) &#123; await new Promise(resolve =&gt; setTimeout(resolve, 1000)) dispatch.count.increment(payload) &#125; &#125;)&#125; 有了 models 后，就可以创建 Redux store，并使用 dispatch 来触发 reducers 和 effects 调用（无需手动编写 action creators 啦~）。当然，在展示层，我们依然可以结合 react-redux 来使用。具体可以参考官方示例，更详细的文档可以参考 这里。 参考 Redux 官网文档 Redux 中文译文 Redux 入门视频教程 以地道的方式使用 Redux 构建 React 应用 Redux and Why it’s Good For You What Does Redux Do Presentational and Container Components，作者其实已经不推荐这种写法了 React Redux 官方文档 延伸阅读 All About React Router 4 Learning React Redux Leveling Up With React: Container Components]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>JavaScript</tag>
        <tag>React</tag>
        <tag>Redux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[React 核心概念]]></title>
    <url>%2F2019%2F07%2F02%2Freact-core-concepts%2F</url>
    <content type="text"><![CDATA[引言React 是一个用于构建 UI 的 JavaScript 库，它有声明式、组件化的特点。使用 JSX 的语法可以非常轻松地编写各种组件，而基于各种组件又可以构造出更加复杂的前端页面。 基础篇JSX JSX 可以很好地描述 UI：const element = &lt;h1&gt;Hello, world&lt;/h1&gt; React 中认为渲染逻辑本质上和 UI 逻辑天然耦合，并没有认为地将标记与逻辑分类到不同文件，而是将它们放在组件这种松散耦合单元中，实现关注点分离 JSX 本身也是表达式，可以在 {} 中使用任意 JavaScript 的功能。在进行编译后，JSX 会被转换成普通的 JavaScript 函数调用，并对其取值后得到 JavaScript 对象 JSX 可以防止注入攻击，ReactDOM 在渲染所有输入内容前，默认会进行转义 元素渲染 与真实的浏览器 DOM 元素相比，React 元素是非常轻量级且创建开销很小的普通对象，ReactDOM 负责更新 DOM 保持与 React 元素一致 渲染元素：ReactDOM.render(element, container) ReactDOM 会将元素及其子元素与之前的状态对比，只进行必要的更新保证 DOM 达到预期状态 组件 组件的定义有两种方式： 1234567891011// 函数组件function Welcome(props) &#123; reuturn &lt;h1&gt;Welcome&lt;/h1&gt;&#125;// 基于 ES6 class 定义的组件class Welcome2 extends Component &#123; render() &#123; return &lt;h1&gt;Welcome&lt;/h1&gt; &#125;&#125; 每个组件都有自己的属性（props）和状态（state） 组件的 props 是只读的。React 组件必须要像纯函数一样保护它们的 props 不被修改 状态 state 组件的 state 是组件私有的，且完全受控于当前组件 除了在构造函数中可以直接给 this.state 赋值外，不要直接修改 state，否则不会渲染组件，要使用 setState() 更新状态 this.props 和 this.state 可能是异步更新，不要依赖它们的值进行下一个状态更新。示例如下： 123456789// 错误的做法，这种可能无法得到预期结果this.setState(&#123; counter: this.state.counter + this.props.incr&#125;// 正确的做法，使用一个箭头函数this.setState((state, props) =&gt; &#123; counter: state.counter + props.incr&#125;)) 不管是父组件还是子组件都无法知道某个组件有无状态，且也不会关心是函数组件还是 class 组件。数据流动是单向向下的，从某个组件 state 产生的任何数据或 UI 只会影响树中低于它们的组件 事件处理 React 事件命名是 camelCase 风格，而非像 HTML DOM 中纯小写的风格 如果想要阻止事件的默认行为，必须显式使用 e.preventDefault()；这里的 e 是 React 根据 W3C 规范定义的合成事件，无需担心跨浏览器兼容问题 React 中自定义的方法默认不会绑定 this，所以有多种方式可以进行绑定： 常规：在构造函数中使用 this.handleChange = this.handleChange.bind(this) 推荐：使用 public class fields 语法：handleChange = () =&gt; {} 在调用时，使用箭头函数或者 bind 绑定（注意，这种可能会带来性能问题，每次都会创建函数，如果是传递给子组件的，还可能会导致子组件重新渲染） 列表 &amp; Key 在列表元素或者组件中，必须要指定 Key。而如果没有设定，则默认使用索引。但是使用索引可能会带来性能问题和状态问题 Key 并不需要全局唯一，只是在相邻节点之间需要保持唯一即可 Key 会被传递给 React，但不会传递给组件 表单 受控组件：把 HTML 表单元素和 React state 结合起来，让渲染表单的 React 组件还控制用户输入过程中表单发生的事情 在受控组件上指定 value 的 prop 可以防止用户更改输入 其它 通常，如果多个组件反映相同的数据变更，可以将状态提升到最近的公共父组件 组合优于继承 有些组件无法提前知晓它们子组件的具体内容，可以通过 props.children 获取子组件渲染 高级篇Context（此 Context 有点特殊） 虽然可以通过 props 将属性从父组件一级级传递到子组件树，但这样毕竟比较繁琐。而有些比较全局的配置（如主题、地区等），则可以通过 Context 进行共享，方便组件树访问这些全局配置 创建 context：const ThemeContext = React.createContext(‘light’)` 示例如下： 1234567891011121314151617181920212223242526import React from 'react';const ThemeContext = React.createContext('light')class Button extends React.Component &#123; // 指定要读取的 Context 类型 // React 会自动查找最近的 theme provider // 然后使用它的值 static contextType = ThemeContext render() &#123; return ( // 使用 `this.context` 可以获取值 &lt;button className="Button"&gt;&#123;this.props.text&#125; + &#123;this.context&#125;&lt;/button&gt; ) &#125;&#125;function ToolBar(props) &#123; return &lt;Button text=&#123;props.text&#125;&gt;&lt;/Button&gt;&#125;function App() &#123; return ( // 使用 Provider 指定 ctx value &lt;ThemeContext.Provider value="yellow"&gt; &lt;ToolBar text="工具按钮"&gt;&lt;/ToolBar&gt; &lt;/ThemeContext.Provider&gt; );&#125;export default App; Context 使用会导致组件的复用性变差，会依赖 Context。如果只是想要避免层层传递属性，可以使用组件组合的方式 API createContext: const myCtx = React.createContext(defaultValue) 对于订阅了上述 ctx 的子组件，会自动在离自己最近的匹配 Provider 处获取设置的值 如果未能找到 Provider，则使用 defaultValue Provider 允许消费组件订阅 context 的变化 可以传递 value 给消费组件，可以嵌套 Provider value 变化时，内部消费组件也会重新渲染 Provider 及消费组件不受 shouldComponentUpdate 函数限制 contextType 挂载在 class 对象上，指向创建的 Context 对象 可以在任意生命周期通过 this.context 访问到最近 Context 的值 Consumer：订阅 context 变更 123&lt;MyContext.Consumer&gt; &#123;value =&gt; /* do stuff */&#125;&lt;/MyContext.Consumer&gt; Context 使用了 reference identity 来决定何时进行渲染，但也存在陷阱。当 Provider 父组件重新渲染时，也可能会导致消费组件意外被渲染 Fragment 常见模式是一个组件要返回多个元素，使用 Fragment 可以将子列表分组，且无需向 DOM 添加额外节点123456789101112131415161718192021222324252627function Column(props) &#123; return ( &lt;&gt; &lt;td&gt;hello 1&lt;/td&gt; &lt;td&gt;hello 2&lt;/td&gt; &lt;td&gt;hello 3&lt;/td&gt; &lt;/&gt; )&#125;function Row(props) &#123; return ( &lt;&gt; &lt;tr&gt;&lt;Column&gt;&lt;/Column&gt;&lt;/tr&gt; &lt;tr&gt;&lt;Column&gt;&lt;/Column&gt;&lt;/tr&gt; &lt;tr&gt;&lt;Column&gt;&lt;/Column&gt;&lt;/tr&gt; &lt;/&gt; )&#125;function Table(props) &#123; return ( &lt;table&gt; &lt;Row&gt;&lt;/Row&gt; &lt;/table&gt; )&#125; 高阶组件（High Order Component, HOC） HOC 是 React 中基于组合特性而形成的设计模式，是一种复用组件逻辑的技巧 HOC 的参数是组件，返回值是新组件的函数：const NewComponent = hoc(WrappedComponent) 面向切面编程，替代 Mixin 模式；纯函数，无副作用 约定：HOC 应该透传与自身无关的 props，使用类似下面的方式编写 render： 123456789101112function logProps(WrappedComponent) &#123; return class extends React.Component &#123; render() &#123; const &#123;level, ...props&#125; = this.props console.log(level) console.log(props) return ( &lt;WrappedComponent level=&#123;level&#125; &#123;...props&#125;&gt;&lt;/WrappedComponent&gt; ) &#125; &#125;&#125; 约定：最大化可组合性 1234567// compose 达到的效果就是：withRouter(connect(componentSelector)(WrappedComponent)))const enhance = compose( // 单纯的 HOC withRouter, connect(componentSelector))const EnhancedComponent = enhance(WrappedComponent) 约定：返回清晰的名称，便于调试。命名习惯：HOCName(wrappedComponentName) 123456789101112131415function logProps(WrappedComponent) &#123; class WithLogComponent extends React.Component &#123; render() &#123; return ( &lt;WrappedComponent &#123;...props&#125;&gt;&lt;/WrappedComponent&gt; ) &#125; &#125; WithLogComponent.displayName = `WithLogComponent($&#123;getDisplayName(WrappedComponent)&#125;)` return WithLogComponent&#125;function getDisplayName(c) &#123; return c.displayName || c.name || 'Component'&#125; 注意： 不要在 render() 中使用 HOC，避免 React 渲染性能问题（不是更新子树，而是卸载旧子树，挂载新子树，且导致组件状态也会丢失）。如果的确需要动态调用 HOC，可以在生命周期方法或构造函数中进行 静态方法需要显式拷贝，可以使用 hoistNonReactStatic 函数拷贝所有非 React 静态方法 Ref 不会被传递 PropTypes 对组件 props 类型进行检查，配置 propTypes 属性即可 考虑到性能问题，仅在开发模式下生效 可以配置 defaultProps 设定默认值 生命周期图谱 合成事件（Synthetic Event） SyntheticEvent 实例是传递给事件处理函数的参数，它是对浏览器事件的包装，兼容所有浏览器，同时提供了接近原生事件的接口。当然，也提供了 .nativeEvent 供你获取底层事件 重要的属性和方法： boolean bubbles boolean cancelable DOMEventTarget currentTarget boolean defaultPrevented number eventPhase boolean isTrusted DOMEvent nativeEvent void preventDefault() boolean isDefaultPrevented() void stopPropagation() boolean isPropagationStopped() DOMEventTarget target number timeStamp string type SyntheticEvent 在完成事件回调后，其属性会无效，无法异步访问该事件 Hook Hook 是 React 16.8 以后新增的特性，它可以让我们在不编写 class 组件的情况下使用 state, props 等 React 特性 Why Hook: 原有的写法中，组件之间状态逻辑复用很困难。Hook 可以提取状态逻辑，单独测试和复用，并且无需修改原有组件的结构 复杂组件变得难以理解。Hook 会将组件中相互关联的部分拆分成更小的函数，不会强制按照生命周期划分 难以理解的 class。Hook 可以在非 class 的情况下使用更多的 React 特性 Hook 可以理解为在函数组件中「钩入」React State 以及生命周期等特性的函数，并且不能再 class 组件中使用 使用规则： 只能在函数最外层调用 Hook，不要在循环、条件或嵌套函数中调用 Hook 只能在函数组件中调用 Hook 原先我们在编写函数组件时，如果需要给其引入状态，或者添加生命周期的钩子，需要转换成 class 组件。但有了 Hook 特性后，可以使用 useState 和 useEffect 来代替了。新的写法将会更加简洁，易于抽象复用和测试 State Hook 使用 useState Hook 可以在函数组件中添加内部 state，React 在重复渲染时保留该 state useState 返回的更新 state 的函数和 this.setState 行为有区别，前者不会把新旧 state 合并，而后者会 示例： 123456789function App() &#123; const [count, setCount] = useState(0) return ( &lt;div&gt; &lt;button onClick=&#123;() =&gt; setCount(count + 1)&#125;&gt;点我&lt;/button&gt; &lt;p&gt;点击计数：&#123;count&#125;&lt;/p&gt; &lt;/div&gt; )&#125; Event Hook 使用 useEffect Hook 给函数组件添加操作副作用的能力。相当于 class 组件中 componentDidMount, componentDidUpdate 和 componentWillUnmount 的合体，将副作用操作都聚集到该 Hook 中 调用 useEffect 时，就表明让 React 在对 DOM 完成更改后调用相应的副作用函数；同时可以返回一个回调函数，用于在清除时执行一些操作。React 会在组件卸载时执行清除操作 使用示例： 1234567891011121314151617function App() &#123; const [userInfo, setUserInfo] = useState(&#123; username: '游客', clickCount: 0 &#125;) useEffect(() =&gt; &#123; alert("当前用户信息：" + userInfo.username) return () =&gt; &#123; console.log("销毁组件，重新渲染") &#125; &#125;) return ( &lt;div&gt; &lt;button onClick=&#123;() =&gt; setUserInfo(&#123; username: 'iFaceless', clickCount: userInfo.clickCount &#125;)&#125;&gt;设置用户&lt;/button&gt; &lt;button onClick=&#123;() =&gt; setUserInfo(&#123; clickCount: userInfo.clickCount + 1, username: userInfo.username &#125;)&#125;&gt;点击计数&lt;/button&gt; &lt;p&gt;你好，&#123;userInfo.username&#125;&lt;/p&gt; &lt;p&gt;点击计数 &#123;userInfo.clickCount&#125;&lt;/p&gt; &lt;/div&gt; )&#125; 默认情况下，useEffect 会在每次渲染后都会执行（当然可以控制），我们不用关心「挂载」和「更新」这种概念 与 componentDidMount 和 componentDidUpdate 不同的是，uesEffect 调度的 effect 不会阻塞浏览器更新屏幕，从而获得更好的响应速度。如果需要同步执行，则使用 useLayoutEffect Hook 自定义 Hook 自定义 Hook 需要以 use 开头，这是约定，可以让 React 自动检查 Hook 是否违反相关规则 参考 React 官方文档 Index as a key is an anti-pattern Formik 组件生命周期图谱 How to fetch data with React Hooks? How to fetch data in React Making Sense of React Hooks]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>JavaScript</tag>
        <tag>React</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript ES6 学习笔记]]></title>
    <url>%2F2019%2F06%2F23%2Fjavascript-es6-learning-note%2F</url>
    <content type="text"><![CDATA[引言2015 年，ECMAScript 第六版得以发布，这就是众所周知的 ES6 标准，标志着 JavaScript 语言迎来新纪元。ES6 引入了一些新的语法糖，同时弥补了一些在 ES5 中存在的一些缺陷。 本篇笔记是在学习阮一峰老师的《ES6 入门教程》中做的笔记，主要是记录一些自己不太熟悉的或者和 ES5 差异很大的特性。在学习过程中，可以和别的语言（如 Python）进行对比，也可以看到在某些设计思想上，这些语言也是相通的。 简介 ES5 其实是 ES3 的升级版本，也就是 ES3.1 ES4 其实并没有发布，但是增加的一些功能在 ES6 中发布了 每年 6 月发布新的标准，ES6 泛指下一代 JavaScript 标准 Babel 转码器：将 ES6 代码转换成 ES5 代码 Google 的 Traceur 转码器也可以将 ES6 代码转为 ES5 代码 杂记 暂时性死区本质：只要一进入当前作用域，所需要使用的变量就已经存在，但是不可获取，只有等到声明变量的那一行代码出现，才可以获取和使用该变量 块作用域可以任意嵌套 块作用域内可以声明函数，但是只能在该作用域下使用 浏览器为了兼容历史代码，在块作用域中声明的函数会提升到全局，类似 var 声明的变量了 ES6 支持 6 中声明关键字： var function let const import class var, function 命令声明的全局变量，依然是顶层对象的属性；let, const, class 声明的全局变量，则不再属于顶层对象的属性。二者需要脱钩 JavaScript 中的顶层对象在各个环境下都是需要存在的，但是在 Node 和浏览器环境中用一套代码想要拿到顶层对象还是有些费劲的。可行的方案如下：1234567891011121314(typeof window !== 'undefined' ? window : (typeof process === 'object' &amp;&amp; typeof require === 'function' &amp;&amp; typeof global === 'object') ? global : this);var getGlobal = function () &#123; if (typeof self !== 'undefined') &#123; return self; &#125; if (typeof window !== 'undefined') &#123; return window; &#125; if (typeof global !== 'undefined') &#123; return global; &#125; throw new Error('unable to locate global object');&#125;; 解构 解构（类似 Python 中的用法，或者 Rust 中的模式匹配）： 12345678910let [a, b, c] = [1, 2, 3]// c 将接收剩余的数组元素[a, b, ...c] = [1, 2, 3, 4, 5][, , c] = [1, 2, 3]// 不完全解构也是支持的[a, b] = [1, 2, 3, 4]// 右值必须要是可迭代的，即实现了 Iterator 接口，否则会出错[a, b] = NaN // TypeError: undefined is not a function 可设置默认值：let [foo = true] = [];，只有数组成员严格等于 undefined 才会让默认值生效 解构失败，变量值为 undefined 对象也可以解构： 123456789let o = &#123;name: "chris", age: 26&#125;let &#123; name, age &#125; = o// 可以将对象赋值给某个已有的变量const &#123; log &#125; = consolelog('hello')// 可以有别名，name 是模式，n 才是被赋值的变量(&#123;name: n, age: a&#125; = o) 对象解构的本质是，先找到同名属性，再赋值给对应的变量 解构赋值的原则是，只要右值不是对象或数组，都要先转为对象（如数字会转成 Number）；而 undefined 和 null 无法转换为对象，所以会报错 函数的参数也支持解构赋值 字符串 &quot;\u{xxxx}&quot; 可以表示超过两个字节的 Unicode 字符 for (let c of &#39;foo&#39;) 可以直接遍历字符串，并且可以识别大于 0xFFFF 的码点 String.raw 返回转义字符串： String.includes() 是否存在子串 String.startsWith() + String.endsWith() String.repeat() 数值 多种进制写法： 二进制：0b010101 八进制：0o123 十六进制：0x1234 将字符串的多种进制转换成十进制：Number(target) 新增了 Number.isFinite 和 Number.isNaN 方法，但这两种方法只对数值有效，其它一律为 false。注意也有一对全局的函数 isFinite 和 isNaN，它们则会尝试先将输入的参数转换为 Number 后再进行判断，这是最重要的区别 ES6 将 parseInt 和 parseFloat 挪到 Number 上了，这样会更加统一 Number.EPSILON 浮点数计算会有精度损失，这个极小值可以用来指定误差范围 指数运算符 **，采用的是右结合的模式 V8 引擎中，指数运算符和 Math.pow 算法实现是不同的，对于特别大的结果，二者会有细微差别 函数 默认参数： function say(word = &#39;hi&#39;) { console.log(word) } 同一作用域中，不能出现同名函数的声明 默认参数是惰性计算，每次调用都会重新计算，这点和 Python 非常不同！！ 函数参数支持解构，且支持默认值 指定了参数默认值后，函数的 length 属性只会返回未设置默认值的参数个数 如果设置了参数，且不是尾参数，则其之后的参数都不算到 length 了：(function (a = 0, b, c) {}).length // 0 函数如果设置了默认值，则在初始化时会形成一个特殊的作用域： 1234567const x = 100// 这里的参数 `x` 和 `y` 处于一个作用域中，故 `y` 的默认值就是指向参数 `x`function foo(x, y = x) &#123; console.log(x, y)&#125;foo(200) //200, 200 ES6 规定，只要函数使用了默认值、解构和扩展运算符，就不能在内部显式指定为严格模式 箭头函数（更简洁的匿名函数写法）： 如果直接返回一个对象，需要将对象用圆括号包围，否则会被解释为代码块：let getObj = id =&gt; ({ id: id }) 函数体内的 this 是定义时所在的对象，而非使用时所在的对象，也就是在箭头函数中，this 是固定的。本质上是因为在箭头函数中，根本就没有 this，它指向的是外层的 this - 不可以作为构造函数，不能对它使用 `new` 命令 - 没有 `arguments` 对象 - 不能使用 `yield`，不可以作为 `Generator` 尾调用： 函数式编程中的一个重要概念，指的是函数的最后一步操作（不一定是最后一行，逻辑上是最后一步）是直接调用另一个函数并返回其结果：12345678function foo(x) &#123; return bar(x) &#125;// 以下不符合function foo(x) &#123; let y = bar(x); return y &#125;function foo(x) &#123; bar(x) &#125;function foo(x) &#123; return bar(x) + 1 &#125; 尾调用优化：只保留内层函数的调用帧，节约内存 ES6 中只要使用了尾递归，就不会出现调用栈溢出，因为只需要维护一个调用帧即可。但其实这个优化只有在严格模式下才会启用。正常模式下，需要通过变量 arguments, func.caller 来跟踪函数的调用栈 数组 数组复制：const a2 = [...a1] 或者 const [...a2] = a1 可以将字符串转换为数组：const a = [...&#39;hello&#39;] 扩展运算符 ... 可以将任何实现了 Iterator 接口的对象转换成数组 Array.from 可以接受任意实现了 Iterator 接口的对象，转换成数组；也支持 array-like 对象 Array.of 将一组值转换为数组，弥补 Array 构造函数在参数个数不同时，行为也不同的毛病。完全可以替代 Array() 或者 new Array() 提供了几个遍历的接口： keys() 实际就是索引 values() 值 entries() 键值 includes() 判断是否包含元素 flat 用于将嵌套数组展开，拉平，默认只展开一层，可指定多层或者 Infinity flatMap 和 flat 类似，但是会对每个元素执行一次回调函数，但它只能展开一层 对象 属性或者方法都可以简写啦： 1234567891011let [x, y] = [1, 2]const a = &#123;x, y&#125;// 等同于const a = &#123;x: x, y: y&#125;// 方法的简写const o = &#123; doSomething() &#123; return true &#125; // 常规写法 doSomething: function() &#123; return true &#125;&#125; 允许使用表达式作为对象的属性名： 123456let propKey = 'foo'let obj = &#123; [properKey]: true, ['a' + 'bc']: 123&#125; ES6 中属性遍历的方法： for...in：遍历对象自身和继承的可枚举属性（不含 Symbol 属性） Object.keys(obj)：对象自身可枚举属性（不含 Symbol 属性） Object.getOwnPropertyNames(obj)：对象自身的所有属性的键名（不含 Symbol 属性） Object.getOwnPropertySymbols(obj)：对象自身所有 Symbol 属性的键名 Reflect.ownKeys(obj)：对象自身所有的键名（无论是 Symbol 属性或者是别的属性，不关心可否枚举） super： 指向对象的原型对象，在这种用法下，只能在对象方法中使用 对象方法：必须采用 ES6 方法简写的方式，才会被认定为对象方法 对象解构赋值： let { x, y, ...z } = { x: 1, y: 2, a: 10, b: 20 } 解构赋值必须是最后一个参数 右值必须是对象 采用的是浅拷贝 Object.is()： 更加明确的比较对象是否符合 Same-value equlity Object.is(NaN, NaN) // true Object.is(+0, -0) // false Object.assign() 用于对象合并，就是将源对象所有可枚举的属性复制到目标对象（包括 Symbol 属性）。注意点： 浅拷贝 同名属性直接替换，不考虑嵌套 由于 Object.assign 只能进行值复制，对于取值函数，则会先取值再复制 Object.assign() 常见用途： 为对象添加属性：Object.assign(this, { x, y }) 为对象添加方法：Object.assign(Foo.prototype, { barMethod() { ... } }) 对象克隆：Object.assign(Object.create(originProto), origin) 属性提供默认值：Object.assign({}, DEFAULTS, options) Symbol ES6 引入 Symbol 的原因： ES5 中，属性名是字符串，容易造成属性名冲突 Symbol 可以保证每个属性独一无二 Symbol 是新增的原始类型，表示独一无二的值。用于对象的属性。使用 Symbol() 函数构造 Symbol 接收一个字符串作为参数，表示对 Symbol 实例的描述。如果是一个对象参数，则会调用 obj.toString() 得到对象的字符串，再生成一个 Symbol 值 注意点： 不可以直接与其它类型值运算，不会隐式转换为 string 可以显式转换为 string symbol.description 可以获取 Symbol 的描述信息 作为对象的属性（只能是公开属性）： 1234567891011121314151617const name = Symbol('name')let person = &#123;&#125;// 第一种定义方式person[name] = "Foo"// 获取的方式person[name]// 第二种定义方式let person2 = &#123; [name]: 'Bar' // 必须要放在方括号中&#125;// 第三种定义方式Object.defineProperty(a, mySymbol, &#123; value: 'Hello!' &#125;); 可以作为常量，保证值不同 可以类似我们在 Python 中那样定义 Enum： 12345const userType = &#123; guest: Symbol(), org: Symbol(), member: Symbol(),&#125; 由于不会被常规的方法如 getOwnPropertyNames 等遍历到，但其实又是公开。这种特性可以用来创建一些非私有、仅希望内部调用的方法 Symbol.for 和 Symbol.keyFor：复用相同参数构建的 Symbol，它会在全局注册参数，并在创建前进行搜索，如果存在则返回，否则新建。注意这个全局是全局环境，可以在不同的 iframe 和 service worker 中取到同样的值： 123456let s1 = Symbol.for('s1')Symbol.for('s1') === s1 // trueSymbol.keyFor(s1) // 's1'let s2 = Symbol('s2')Symbol.keyFor(s2) // undefined 内置的 Symbol 值，指向语言内部使用的方法： Symbol.hasInstance，每个对应可以自定义这个 Symbol 方法，从而让 instanceof 运算符按照期望的表现 Symbol.isConcatSpreadable 属性，表示在 Array.prototype.concat() 时，能否展开 Symbol.species 属性，指向一个构造函数。在创建衍生对象时，会使用该属性 Symbol.iterator 指向对象的默认遍历器 Symbol.toPrimitive 指向转换成原始类型的方法 Set 和 Map 数据结构 Set 构造函数可接受任意 Iterable 的对象 来看下消除数组中重复元素的方法与 Python 的区别： 12345678// Python 中的写法list(set([1, 1, 2]))// JS ES6 中的写法[...new Set([1, 1, 2])]// 或者Array.from(new Set([1, 1, 2)]) WeakSet 弱引用计数，只能存放对象。不可遍历 Map 的构造： 123456// 先看看 Python 中一个类似的构造方式dict(zip(['name', 'age'], ['chris', 22]))// 那么在 ES6 中的写法// 实际上任意 Iterable 的对象，且成员均为双元素的数组的数据结构都可以作为 Map 的构造函数new Map([['name', 'age'], ['chris', 22]]) WeakMap Proxy 属于元编程范畴，可以拦截一些操作，并进行重定义 构造函数：var proxy = new Proxy(target, handler) 要想让 Proxy 起作用，必须要针对其实例进行操作，而非目标对象 123456789101112131415161718let handler = &#123; get (target, name, receiver) &#123; if (name === "name" || name == "age") &#123; return Reflect.get(target, name, receiver) &#125; else &#123; throw ReferenceError(`property '$&#123;name&#125;' not found`) &#125; &#125;&#125;let user = &#123; name: "Chris", age: 26,&#125;let proxy = new Proxy(user, handler)console.log(proxy)console.log(proxy.age)console.log(proxy.name)console.log(proxy.foo) Proxy.revocable 可以返回一个可取消的 Proxy 实例 Reflect Reflect 也是为了操作对象而提供的新的 API，设计目标： 将 Object 对象中明显属于内部的方法剥离出来，放到 Reflect 对象上 修改某些 Object 方法的返回结果，更加方便使用 将某些命令式的操作，变成函数，如：name in obj =&gt; Reflect.has(obj, name)，delete obj[name] =&gt; Reflect.deleteProperty(obj, name) 与 Proxy 中拦截方法一样，可以替代执行对象的默认行为 Reflect.apply(Math.floor, undefined, [1]) Promise 异步编程解决方案。所谓 Promise，就是一个简单的容器，保存着未来才会结束的事情（通常是一个异步结果） 特点： 对象的状态不受外界影响（pending, fulfilled, rejected） 一旦状态改变，就不会再变，任何时候都可以得到结果 以更加同步的方式编程，易于提供统一的接口，便于维护 缺点： 无法取消 若不设置回调，Promise 内部抛出错误不会反馈到外部 pending 状态时，无法得知具体进展情况 Promise.prototype.then() 可接受两个回调，一个是 resolved 时的 回调，还有一个是 rejected 时的回调。第二个回调可选 Promise.prototype.then() 返回的是一個新的 Promise 實例 Promise.prototype.catch() 是 .then(undefined, rejection) 或 .then(null, rejection) 的别名，用于指定发生错误时的回调函数 Promise 对象的错误具有冒泡的性质，会一直向后传递，直到被捕获为止。错误总是会被下一个 catch 捕获 Promise.prototype.finally 用于指定不管 Promise 对象最终如何，都会执行的操作，ES2018 引入。无法在 finally 中获取 Promise 的状态，它的执行与状态无关 Promise.all： 参数必须是 Iterable 的对象，元素应当是 Promise 实例 状态由成员决定，只有都是 fulfilled 时，整体的状态才会变成 fulfilled 如果任何一个 rejcted ，则整体整体就是 rejected，并且返回第一个被 reject 的实例的返回值 Promise.race，类似 Promise.any 的感觉，就是只要有一个状态改变，整体状态就变化；率先变化的 Promise 实例返回值会传递给 p 的回调函数 Iterator &amp; for…of Iterator 遍历过程： 创建一个指向可迭代对象的指针对象 调用 next，可得到第一个成员（返回结果包括两个属性：value + done，可分别省略） 不断调用 next 直到消费完 实现了 Iterator 接口的数据结构，就是可遍历的（Iterable）。示例： 1234567891011121314151617181920class RangeIterator &#123; constructor(start = 0, stop = 100) &#123; this._value = start this._stop = stop &#125; [Symbol.iterator]() &#123; return this &#125; next() &#123; let val = this._value if (val &lt; this._stop) &#123; this._value++ return &#123;done: false, value: val&#125; &#125; return &#123;done: true, value: undefined&#125; &#125;&#125;for (const x of new RangeIterator()) &#123; console.log(x)&#125; 何时触发 Iterator （即 Symbol.iterator）接口调用？ 解构赋值 扩展运算符 yield* for...of Array.from() Map(), Set(), WeakMap(), WeakSet() Promise.all() Promise.race() 可以使用 Generator 函数实现可迭代： 123456789101112131415class RangeIterator &#123; constructor(start = 0, stop = 10) &#123; this._value = start this._stop = stop &#125; *[Symbol.iterator]() &#123; while (this._value &lt; this._stop) &#123; this._value++ yield this._value &#125; &#125;&#125;for (const x of new RangeIterator()) &#123; console.log(x)&#125; 遍历器对象除了有 next 方法外，还可以添加一个 return 方法，用于处理 for...of 提前退出（如出错，或者 break）时要做的事情。而 throw 方法一般是配合 Generator 函数使用 Generator 函数 定义方式：function* funcName() { yield 1; return &quot;end&quot; } 调用 Generator 函数，返回一个遍历器对象，代表 Generator 函数内部指针 yield 只能用于 Generator 函数中（这个和 Python 不同。在 Python 中，Generator 函数从表明上看和普通函数定义是一样的，只是实现不同） yield 表达式本身无返回值，或者总返回 undefined。next 方法可以带参数，作为 yield 表达式的返回值 第一次带参数调用 next 方法时，参数是无效的。因为 next 方法的参数表示上一个 yield 表达式的返回值 语义上，第一次调用 next 是启动遍历器对象 Generator.prototype.throw() 可以在函数体外向 Generator 函数抛错。如果生成器中没有 try...catch 块，错误会传递到外部 如果一个 Generator 执行过程中出错，且没有内部捕获，则会认为它已经执行结束了 Generator.prototype.return() 可以终止 Generator，如果 return 带参数，则会作为最后的返回值。如果 Generator 中含有 try...finally 语句块，则会优先执行 finally，延迟返回 yield* 表达式可以参考 Python 中的 yield from 异步编程模式： 回调函数 事件监听 发布/订阅 Promise 对象 async 函数 async 是 Generator 语法糖，写异步执行的函数更加便捷 改进点： 内置执行器，无需 co 之类的模块控制 Generator 执行流程了 更好的语义 更广的适用性。await 可以是 Promise 对象，如果是原始类型值，则会自动转换为 resolved Promise 对象 返回值是 Promise 定义方式： 123456789101112131415161718192021// 函数声明async function foo() &#123; &#125;// 函数表达式const foo = async function () &#123; &#125;// 对象的方法let o = &#123; async foo() &#123; &#125; &#125;// 类中定义class Storage &#123; constructor() &#123; this.cachePromise = caches.open("avatars") &#125; async getAvatar(name) &#123; const cache = await this.cachePromise return cache.match(`/avatars/$&#123;name&#125;.jpg`) &#125;&#125;const store = new Storage()store.getAvatar("jake").then().cach()// 箭头函数const foo = async () =&gt; &#123;&#125; 错误处理：如果 await 后面的异步操作出错，等同于 async 函数返回的 Promise 对象被 reject。捕获错误的两种方式： 123456789101112async function foo() &#123; try &#123; await doSomething() &#125; catch (e) &#123; console.error(e) &#125;&#125;// 另外一种async function bar() &#123; await doSomething().catch(e =&gt; &#123; console.error(e) &#125;)&#125; 对于不相互依赖的独立操作，不建议分别 await，那样和同步有毛线区别。建议用下面的方式： 1234567let [foo, bar] = await Promise.all([foo(), bar()])// 另外一种写法let fooPromise = foo()let bar Promise = bar()let fooResult = await fooPromiselet barResult = await barPromise 实现原理：就是将 Generator 函数和自动执行器包装在一起： 12345678910async function fn(args) &#123; // ...&#125;// 等价于function fn(args) &#123; return spaw(function *() &#123; //... &#125;)&#125; Class ES6 中的 class 本质上还是 Function 对象，所有定义的新方法都是在 prototype 上。但是，类内部定义的所有方法都是不可枚举的，这点和 ES5 中直接给 prototype 挂载方法不同 每个类都必要有 constructor，如果没有会有一个空的 constructor 存在 类必须使用 new 调用，否则会报错 this 指向： 类的方法内部如果含有 this，默认指向类的实例。但是如果单独使用，可能出错 解决方法有两种，固定 this： 采用 bind 使用箭头函数 静态方法： 使用 static 关键字修饰 不会被实例继承和调用（这点和 Python 不同，在 Python 中 static 方法可以被实例调用，而不需要通过类名） 如果静态方法中包含 this，其指向的不是实例，而是类 静态方法可以和非静态方法重名 父类的静态方法可以被子类继承 继承： 使用 extends 关键字 单继承 子类必须要在自定义的 constructor 方法中调用 super，触发父类构造函数调用后，才可以使用 this 判断一个类是否继承自某个类实例：Reflect.getPrototypeOf(ColoredPoint) === Point super 关键字： 当作函数使用，代表调用父类的构造函数（注意，此时 super 调用后返回的是基类的实例），只能用于构造函数 当作对象，在普通方法中指向父类的原型对象；在静态方法中，指向父类 ES6 规定，在子类普通方法中调用 super.xxx() 时，方法中的 this 指向的是当前的子类实例 在子类静态方法中通过 super 调用父类方法时，内部的 this 指向当前的子类，而非子类的实例 ES5 原生构造函数无法继承（子类无法获得原生构造函数的内部属性）。具体原因是 ES5 中，是新建子类的实例对象 this，再将父类的属性添加都子类上；而父类的内部属性无法获取，故无法继承： Boolean() Number() String() Array() Date() Function() RegExp() Error() Object() ES6 则允许继承上述原生构造函数了。原因是 ES6 中，是先新建父类的实例对象 this，再用子类的构造函数修饰 this，使得父类的行为可以继承 模块 早期 JS 无模块管理机制，不利于开发大型项目 社区提供了 CommonJS 和 AMD 两种方案，分别用于服务端和浏览器端；二者都是运行时确定模块依赖 ES6 模块的设计思想是尽可能静态化，编译时确定模块依赖关系及输入输出变量 import 使用注意： import { foo } from &#39;mod&#39; 导入的变量都是只读的 导入的路径既可以是相对路径，也可以是绝对路径 .js 后缀可省略 如果只是模块名称，无路径则需要配置文件告知 JS 引擎具体的模块位置 具有提升的效果 静态执行，无法使用表达式和变量 Single 模式，有缓存机制 整体加载带别名：import * as mod from &#39;longNameMod&#39; export default 本质上是输出一个叫做 default 的变量和方法，然后系统允许重名 在一条语句中同时输入默认方法和其它接口：import _, { each } from &#39;lodash&#39; 复合写法：export { foo, bar } from &#39;my_mod&#39;，注意不会在当前模块导入这两个变量，而只是转发到外面了 模块加载规则 浏览器中可使用的方式： &lt;script src=&quot;path/to/foo.js&quot; [async/defer]/&gt; ES6 模块加载（默认就是 defer 模式）：&lt;script type=&quot;module&quot; src=&quot;./mod.js&quot;/&gt; &lt;script type=&quot;model&quot;&gt; /可以正常写 import xx from xxx 这种，模块作用域/` ES6 与 CommonJS 前者输出是值引用，后者输出的是值拷贝 前者是编译时输出接口，后者是运行时加载 前者是动态引用，后者会缓存值 在 Node 中 import 是异步加载 ES6 模块中，顶层 this 指向 undefined；后者则指向当前模块 二进制数组（类数组） 二进制数组组成对象： ArrayBuffer 对象：代表内存中的一段二进制数据，可通过「视图」操作 TypedArray 视图：可用于读写简单的二进制数据，包括 9 种类型视图： Int8 Uint8 Uint8C：自动过滤溢出，DataView 视图不支持 Int16 Uint16 Int32 Uint32 Float32 Float64 DateView 视图：可自定义复合格式的视图，读写复杂类型的二进制数据 参考 ECMAScript 6 入门 ES5 和 ES6 中的继承 Babel]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>JavaScript</tag>
        <tag>ES6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript ES5 入门笔记]]></title>
    <url>%2F2019%2F06%2F23%2Fjavascript-es5-learning-note%2F</url>
    <content type="text"><![CDATA[引言最近抽空学习了下 JavaScript 语言，当然还是入门级别的那种。学习过程中也做了些笔记。总的来说，ES5 学完后，对 JavaScript 本身了解了大概，语言本身设计上也存在一些坑，所以搭配《JavaScript 精粹》这本书看看，可以进一步了解有哪些比较好的写法避免踩坑。 基础篇 判断是否为未定义的变量： 123456789// 错误的写法if (v) &#123;// ...&#125;// ReferenceError: v is not defined// 正确的写法if (typeof v === "undefined") &#123;// ...&#125; typeof null 也是 object 使用 instanceof 可以判断是否为数组：v instanceof Array null 和 undefined 非常类似，甚至 null == undefined 都成立，但是它们在 JavaScript 中还是有区别： null 表示空对象，可转换为数值 0：Number(null) //0 undefined 表示没有定义的原始值，转换为数值为 NaN JS 中所有数字都是以 64 位浮点数存储的，对于某些运算，只能用整数，JS 会将数字转换为 32 位整数再做运算 数值计算比较需要注意，因为浮点数有精度丢失的问题。比如：0.3-0.2 !== 0.2-0.。 JavaScript 对 15 位的十进制数都可以精确处理。 对于码点在 U+10000 到 U+10FFFF 之间的字符，JavaScript 总是认为它们是两个字符（length 属性为 2） base64 转换：btoa, atob 属性删除 delete： 不能删除对象本身 无论属性是否存在，删除总会返回 true 继承的属性不能删除，虽然也会返回 true 使用 defineProperty 定义的标记为不可删除的属性，delete 返回 false 对象属性存在新判断： in 可以判断，但是不能区分是继承的还是自身拥有的 hasOwnProperty 可以弥补上述缺点 for...in 用于遍历对象的属性： 对象属性必须是可遍历的（enumerable） 对于继承的属性也会被遍历到，如果不想要，可以搭配 hasOwnProperty 过滤掉 一般也可以使用 Object.keys(o).map(k =&gt; { /*do stuff*/ } 函数声明几种方式： function func_name(params) {} let say = function (word) {}，匿名函数 let say = function f(word) { console.log(f) }，注意，这里的函数名 f 只可以在该函数内部访问到，有两个好处： 遍历在函数内部调用自己 方便调试，排错时看到具体的函数名，而不再是匿名函数 使用 Function 构造函数，注意，返回的函数的 type 的确也是 function（不推荐使用） JS 引擎将函数名视为变量名，所以也存在「函数名提升」的效果，因此，在函数声明位置的上方调用也不会出错 函数执行时所在的作用域，是定义时的作用域，而不是调用时所在的作用域 arguments 对象可以获取到函数传入的参数值： 该对象不是数组，所以像 slice, forEach 方法就不存在 如果想要转换成数组，一种方式就是：let args = Array.prototype.slice.call(arguments) 在严格模式下，不能通过 arguments.callee 调用函数自身；对 arguments 的修改不会对原始传入的参数产生影响 立即调用函数的两种方式： (function () {console.log(10)})() (function () {console.log(10)}()) 数组是特殊的对象，其键名就是一组数字，可以通过 Object.keys 返回所有的键名 数组的 length 属性不过滤空位。所以，使用 length 属性进行数组遍历，一定要非常小心。如 delete arr[3] 之后，依然不会影响 length，只是产生了一个空位；所以可以使用 forEach 替代，可以过滤空位（但空位不等同于 undefined）。也就是说 var a = [, , ,] 表示的每个位置都是空位；var a = [undefined, undefined] 则是可遍历到的，只是值为 undefined 而已 类似数组的数组（Array like object）： 对象拥有类似下面的定义：12345678// 所有的键都是数字// 带有 length 属性var obj = &#123; 0: &apos;a&apos;, 1: &apos;b&apos;, 2: &apos;c&apos;, length: 3&#125;; 函数的 arguments，字符串，还有多数的 DOM 元素都是 array-like 的对象。可以使用 Array.prototype.slice.call(xx) 转换成数组 void 运算符：作用是执行一个表达式，不返回任何值（返回 undefined）： 推荐用法：void (x = 5) 使用场景，防止网页跳转：&lt;a href=&quot;javascript: void f()&quot;&gt;文字&lt;/a&gt; 逗号运算符返回最后一个值 &#39;a&#39;, &#39;b&#39; // &quot;b&quot; 语法专题 Number 用于强制转换成数值类型，与 parseInt 相比，转换要严格得多，只要遇到不可转换为数值的字符，转换就失败 Boolean 所有对象（含空对象）的转换结果都是 true，如 Boolean(new Boolean(false)) // true JS 中所有抛出的错误都是 new Error(xx) 出来的，Error 的基本属性： message：错误提示信息（必须） name：错误名称（非标准属性，看 JS 引擎） stack：错误的堆栈（非标准属性，看 JS 引擎） 派生错误对象： SyntaxError ReferenceError RangeError：数组长度为负数；Number 对象的方法参数超出范围；函数堆栈超过最大值 TypeError URIError throw 可以抛出任意类型的值，并且在 throw 的位置就中断了执行，JS 引擎会接收到抛出的信息 console 一些重要的方法： info error debug warn table log dir：类似 inspect 可以在需要的地方加 debugger 作为断点，用于调试 标准库 Object() 函数可以将任意值转换成对象，如果传入的参数是原始类型值，则会转换成其包装对象的实例；如果入参已经是对象了，则不会转换 可以利用上述特性判断变量是否为对象：value === Object(value) Object.keys() 静态方法可以返回对象的所有属性名（非继承，且可枚举），该遍历方法优先 Object.getOwnPropertyNames() 静态方法则会返回对象的所有属性名（包括不可枚举的） Object.prototype.xxx 实例方法： valueOf()：返回对象的值，默认为自身 toString()：返回对象的字符串表示 Object.prototype.toString.call(value) 返回 [object &lt;TypeName&gt;]，第二个元素可以得到具体的值类型 JS 提供了内部数据结构，描述对象的属性，控制其行为，示例如下： 12345678&#123; value: 123, writeable: false, enumerable: true, configurable: false, get: undefined, set: undefined&#125; Object.getOwnPropertyDescriptor(obj, &#39;a&#39;) 可以获取属性描述对象 默认情况下，如果属性被设置为 writeable=false 后，继承者将无法重新定义同名属性；除非可以通过覆盖属性描述对象来绕过限制 如果属性的 enumerable 为 false，则有三种操作不能取到该属性： for...in Object.keys：无法获取对象继承的属性，此时可以用 getOwnPropertyNames JSON.stringify configurable：控制是否可以修改描述符属性，并且当 configurable=fasle 时，无法删除 判断对象是否为数组：Array.isArray 面向对象 JavaScript 中的对象体系，是基于构造函数 constructor 和原型链 prototype 的。构造函数就是对象生成的「模板」 构造函数特点： 内部使用 this，指向生成的对象实例 需要配合 new 关键字 new 干了什么： 新建空对象，作为要返回的对象 将空对象的 __proto__ 指向构造函数的 prototype 将该空对象赋值给函数内部的 this 关键字 执行构造函数中的代码 函数内部可使用 new.target 判断是否使用了 new 调用构造函数 this 在函数体内部，指向当前的运行环境 如果 this 所在的方法不在对象的第一层，这时 this 只是指向当前一层的对象，而不会继承更上面的层 函数实例的 call 方法可以指定 this 指向的环境，此外可以跳过同名函数覆盖，直接使用原始的函数；appy 和 call 类似，只是接收一个列表参数 bind 也可以绑定对象，变换 this 指向 JS 继承机制的核心：原型中所有属性和方法都可以被多个实例共享 instanceof 运算符： 只能用于非原始类型对象 对象的原型 prototype 均为 null 时失效 undefined instanceof Object 和 null instanceof Object 均为 false 异步 Promise 的回调函数不是正常的异步任务，而是微任务。前者会追加到下一轮事件循环，而微任务则追加到本轮事件循环。所以微任务执行要早于常规异步任务。 setTimeout(f, 0) 可以让任务在下轮事件循环中执行 DOM 元素的 hidden 属性只有在 CSS 没有明确设定当前元素的可见性时才会生效，也就是 CSS 的 display 用于可见性控制的优先级高于元素自身的 hidden 属性 网页元素可以自定义 data-* 属性，添加数据，可以使用 .dataset 返回数据对象 为防止遭受攻击，对于文本内容，建议使用 textContent 替代 innerHTML 设置文本 CSS CSS 负责视觉效果；JavaScript 负责与用户的行为互动 可以通过 style 属性设置 CSS 样式 CSSStyleDeclaration 对象用于操作元素的样式，包括： 元素的 style 属性 CSSStyle 实例的 style 属性 window.getComputedStyle() 返回值（元素的全部样式需要它获取到） 需要注意的是，CSSStyleDeclaration 的属性名和原生 CSS 还是有点区别，命名需要修改，如 backgroud-color -&gt; backgroudColor；如果是 JS 的保留字，则需要加上 css 前缀 属性操作： setProperty removeProperty DOM 变动监控 Mutation Observer API：DOM 的变动（节点增减、属性变动、文本内容变动），都可以通过该 API 获得通知 与事件的区别： MO 事件是在 DOM 变动时异步触发，并且是等到当前所有 DOM 操作都结束才触发 事件则是同步触发，DOM 变动立刻触发 总结来说： 等待所有脚本任务完成后，才会触发 把 DOM 变动记录封装成一个数组处理，而非每条都分别处理 既可以观察 DOM 所有类型变动，也可以指定观察某类变动 用法： 12345const observer = new MutationObserver((mutations, observer) =&gt; &#123;&#125;)// 指定监听的元素和类型const article = document.querySelector("article")observer.observe(article, &#123;'childList': true, 'attritubes': true&#125;) 事件 DOM 的事件操作（监听、触发），都是 EventTarget 中定义的。主要接口如下： addEventListener removeEventListener dispatchEvent HTML 中可以直接在元素属性中，定义某些监听代码。如 onload，这类监听代码只在冒泡阶段触发 元素的 onclick 属性，也可以指定监听函数，并且在冒泡阶段触发 事件传播： 第一阶段：从 window 对象传导到目标节点（上层传到底层），即为「捕获阶段」（capture phase） 第二阶段：从目标节点上触发，叫做「目标阶段」（target phase） 第三阶段：从目标节点传导回 window 对象（从底层传回上层），叫做「冒泡阶段」（bubbling phase） e.StopPropagation 则是会阻止事件传播，但不会处理其它的监听事件 e.stopImmediatePropagation 会彻底取消同名的时间 网页中除了元素节点默认不可以拖拉，其它（图片、链接、选中的文字）都是可以拖拉的，可通过将元素节点的 draggable 属性设置为 true 实现 一旦某个元素节点被设置为可拖拽后，就无法通过鼠标选中节点内部的文字或子节点了 浏览器对象 嵌入脚本时，&lt;script&gt; 元素的 type 属性默认为 text/javascript，新浏览器可以写成 application/javascript。当然，也可以不填写。另外，integrity 属性可以设置脚本的 SHA256 签名，对于非法脚本浏览器会拒绝加载 async 和 defer 同时存在，则后者不起作用 window.navigator 指向包含浏览器和系统信息的 Navigator 对象，可以了解用户的环境信息 Cookie 是服务器保存在浏览器的一小段文本信息，每个 Cookie 的大小一般不超过 4KB，每次请求服务器，都会附带该信息 Cookie 包括的信息： 名字 值 到期时间 所属域名（默认当前域名） 生效的路径（默认当前网站） 浏览器的安全基础是「同源政策」（same-origin policy） 同源的含义： 相同的协议 相同的域名 相同的端口 非同源的限制： 无法读取非同源网页的 Cookie, LocalStorage 和 IndexedDB 无法接触非同源网页的 DOM 无法向非同源地址发送 AJAX 请求（即便发送，浏览器也会拒绝接受响应） document.domain 设置可共享 Cookie，适用于 ifame 和 Cookie，对于 LocalStorage 和 IndexedDB 无效；此外，服务器可以在设置 Cookie 时就指定好所属一级域名：.example.com，也可以对子域名达到共享 Cookie 的目的 对于完全不同源的窗口，想要通信有两种方式： fragment identifier：片段标识符。http://example.com/x.html#fragment 只是改变 #fragment 不会导致网页刷新，属于破解无法通信之法 H5 提供了新的 postMessage 方法发送消息，监听方可以监听 message 事件获取消息 AJAX 突破同源限制的方法： JSONP WebSocket CORS (Cross-Origin Resource Sharing) CORS 通信： W3C 标准，允许浏览器跨域请求 详细介绍 区分简单请求和非简单请求，流程不同 简单请求中，Origin Header 很重要 非简单请求，先进行 /OPTIONS 预先检查，然后后续流程类似简单请求 Storage 接口： sessionStorage：保存的数据用于浏览器一次会话，结束后会被清理 localStorage 保存数据长期存在 只有同域名下的网页才可以读取，跨域会报错 length 返回数据项个数 setItem 保存 key + value getItem 返回保存的 key 对应的 value clear key 返回对应位置的键值 参考 JavaScript 入门 MDN JavaScript]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>JavaScript</tag>
        <tag>ES5</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rocket Web 框架入门]]></title>
    <url>%2F2019%2F02%2F24%2Frust-rocket-quick-start%2F</url>
    <content type="text"><![CDATA[引言Rocket 框架 是 Rust 生态中比较流行的 Web 框架之一，其最大的特点是拥有类似 Flask 那样比较简洁的写法，可以非常轻松地编写 RESTful API，同时还支持中间件等机制，易于扩展。当然，目前该框架最大的缺点是使用了很多 rust-nightly 版本中的特性，导致无法在 rust-stable 分支下编译。这对于一个需要长期维护的较大的项目来说，就存在一定的升级风险。不过鉴于目前我们不大可能在生产环境中使用 Rust 来编写 Web API，暂且还不用担心这些问题。 你好，Rocket需要说明的是，下面的示例代码是在 rustc 1.34.0-nightly 环境下编译并运行的~ 首先，需要新建项目 hello-rocket：1cargo new hello-rocket --bin 由于需要使用 rust-nightly 版本，所以这里需要切换版本并更新工具链。方法如下：12# 将当前项目环境切到 nightly 版本rustup override set nightly &amp;&amp; rustup update 准备工作完成后，我们就需要给项目添加 rocket crate 依赖啦： 1cargo add rocket 可以在 Cargo.toml 中看到添加的依赖： 123...[dependencies]rocket = "0.4.0" 接下来，我们在 main.rs 中编写一个最简单的 API，负责在访问对应路由时打印出 Hello, Rocket。可以将下面的代码粘贴到你的文件中： 1234567891011#![feature(proc_macro_hygiene, decl_macro)]// 我们需要使用 rocket 中定义的路由创建宏 `routes!`#[macro_use]extern crate rocket;#[get("/")]fn index() -&gt; String &#123; "Hello, Rocket".to_string()&#125;fn main() &#123; rocket::ignite().mount("/", routes![index]).launch();&#125; 以上就完成了一个最简单的 API 编写。最后编译并启动 Web 服务后，可以在终端中看到下面的输出。你可以在浏览器中访问 localhost:8000 来查看响应内容： 123456789101112Configured for development. =&gt; address: localhost =&gt; port: 8000 =&gt; log: normal =&gt; workers: 8 =&gt; secret key: generated =&gt; limits: forms = 32KiB =&gt; keep-alive: 5s =&gt; tls: disabledMounting /: =&gt; GET / (index)Rocket has launched from http://localhost:8000 Rocket 的特性在其官网的 Overview 中，可以看到 Rocket 框架的主要特性。 路由（Routing）Rocket 的主要任务便是路由请求到合适的请求处理 Handler。路由是通过 get 属性声明的，看起来像是 Python 中的装饰器： 1234#[get("/")]fn index() -&gt; &amp;'static str &#123; "Hello, Rocket!"&#125; 以上面的代码块为例，这个路由的名称为 index，和 HTTP GET / 匹配。请求处理函数会返回一个字符串作为 HTTP 响应的 body。 动态参数（Dynamic Params）Rocket 可以动态地识别请求路径多个部分，并和处理函数的参数一一匹配，示例如下： 1234#[get("/hello/&lt;name&gt;/&lt;age&gt;")]fn hello(name: String, age: u8) -&gt; String &#123; format!("Hello, &#123;&#125; year old, named &#123;&#125;!", age, name)&#125; 上述示例表示，hello 路由会动态匹配到路径中的 &lt;name&gt; 和 &lt;age&gt; 部分。每个动态参数都要有具体的类型，Rocket 会尝试将 path 中对应位置的参数转换为目标类型。只有参数正确转换后，才会调用相应的路由处理函数。为了解析字符串，Rocket 会使用 FromParam trait，你也可以为自定义类型实现该 trait。 请求数据处理（Handling Data）请求的 body 数据是通过 FromData trait 来处理的。请求的 body 数据可以派生任何实现了 FromData 的类型。你可以像下面这样指定期望通过哪个参数使用请求的 body： 1234#[post("/login", data = "&lt;user_form&gt;")]fn login(user_form: Form&lt;UserLogin&gt;) -&gt; String &#123; format!("Hello, &#123;&#125;!", user_form.name)&#125; Form 类型是 Rocket 内建的类型，它可以将 Web 表单转换成结构体。Rocket 会自动尝试将请求的 body 数据转换成 Form，然后在转换成功后调用 login 处理函数。其它内建的 FormData 类型还有 Data、Json 和 Flash。 请求护卫（Request Guards）除了动态路径和数据参数外，请求处理函数还可以包含第三种类型的参数：request guards。Request guards 不用在路由属性中声明，而是出现在请求处理函数的参数签名中，并且支持任意多个。 Request guards 的作用是对请求的元信息进行判断，如果满足指定条件，才运行处理函数，起到保护作用。比如： 1234#[get("/sensitive")]fn sensitive(key: ApiKey) &#123;&#125; 例子中 ApiKey 用于保护 sensitive 处理函数，只有在请求头中的 API 密钥认证通过后，才会执行。ApiKey 类型需要过实现 FromRequest trait，然后在实现逻辑中检查 API 密钥头。Request guards 是 Rocket 中非常强大且独特的概念。 响应（Responder）请求处理函数的返回类型可以是任何实现了 Responder 的类型：12#[get("/")]fn route() -&gt; T &#123;&#125; 上述例子中，T 必须要实现 Responder。Rocket 已经为标准库中很多类型实现了 Responder：&amp;str、String、File、Option 以及 Result。Rocket 也实现了一些自定义的 Responder，如 Redirect、Flash 和 Template。 Responder 的任务就是尽可能生成 Response，它也可以在失败时提供状态码。如果指定了状态码，Rocket 就会调用相应的错误捕获函数。catch 路由的定义如下： 12#[catch(404)]fn not_found() -&gt; T &#123;&#125; 运行（Launching）为了运行 Rocket 应用，首先需要挂载路由；然后才可以启动。示例如下： 123rocket::ignite() .mount("/base", routes![index, another]) .launch(); 调用 launch 后会启动服务器，开发环境中，Rocket 会打印出一些比较有用的状态信息： 1🚀 Rocket has launched from http://localhost:8000 Rocket 是如何工作的？每一个 Rocket Web 应用从接受到请求到进行响应，都会经历标准的三个步骤（这也是常规 Web 框架都会做的事情）。 校验首先，Rocket 会校验匹配的请求，确保处理函数中的每个类型都可以派生自当前请求。如果某个类型无法派生，则会定向到下一个匹配的路由，直到所有类型校验都没问题或者没有任何可尝试的路由为止。如果所有的路由都不匹配，则会返回自定义的 404 错误： 1234#[post("/user", data = "&lt;new_user&gt;")]fn new_user(admin: AdminUser, new_user: Form&lt;User&gt;) -&gt; T &#123; ...&#125; 以上述例子来说明： 请求方法必须是 POST 请求路径必须是 /user 请求中必须包含 body 数据 请求的元信息必须是通过认证的 AdminUser 请求体必须能够转换成 User 结构体 处理接下来，请求会被任意的 Handler 处理。这里就是执行具体的业务逻辑了。Rocket 中的 Handler 就是简单的函数，唯一要注意的是返回值必须要是实现了 Responder trait 的类型。 响应最后，Rocket 会将 Handler 返回值转换成 HTTP 响应，然后给客户端发送响应： 1fn route() -&gt; T &#123;&#125; 上述例子中的 T 必须是实现了 Responder 的类型，Rocket 目前提供了很多常用的响应类型： Json&lt;T&gt;: 将类型 T 转换成 JSON 并返回 Template: 渲染模板并返回 Redirect: 返回合适的重定向响应 NamedFile: 向客户端流传输指定的文件，Content-Type 设置为文件夹的扩展名 Stream: 向客户端流传输任意 Read 值 更多扩展功能Rocket 框架可插拔的特性能能够给你带来很多额外的特性，这些特性在其文档中有详细的介绍。 模板 Cookies 流传输 易于配置的开发环境 内建单元测试工具 类型安全的 URIs 参考 Rocket Overview]]></content>
      <categories>
        <category>Web 开发</category>
      </categories>
      <tags>
        <tag>Web</tag>
        <tag>Rust</tag>
        <tag>Rocket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Thrift 初探]]></title>
    <url>%2F2019%2F02%2F18%2Fexplore-thrift%2F</url>
    <content type="text"><![CDATA[引言知乎使用的 RPC 框架是基于 Thrift 构建的。自然就很有必要了解下 Thrift 是什么？如何使用？以及有什么最佳实践？ Thrift 官方是这样介绍自己的： Thrift is a software framework for scalable cross-language services development. It combines a software stack with a code generation engine to build services that work efficiently and seamlessly between C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, JavaScript, Node.js, Smalltalk, and OCaml. 以下是 Thrift 协议栈示意图： Input Code：是依照 Thrift 语法编写的服务（包含变量、服务方法、异常等定义） Generated Code：使用 thrift gen 编译生成的指定某种语言的客户端代码，以便于在业务中调用服务的 RPC 接口 Service Client write()/read() TProtocol：提供了可选的协议层 TTransport：提供了满足不同需求的传输层服务 运行时库（Runtime Library）整个协议层和传输层都是运行时库的一部分。这就意味着，我们可以在上层定义好服务后，在需要的时候随时替换协议层或传输层，而无需重新编译生成客户端代码。 协议层（Protocol Layer）协议层的主要作用是提供序列化和反序列化的能力，目前支持的类型如下： TBinaryProtocol：直接二进制格式，数字会被编码成二进制，而非文本 TCompactProtocol：异常高效、紧凑的数据编码格式 TDenseProtocol：类似于 TCompactProtocol，但是在传输时会移除 meta 信息，而在接收时补回 meta 信息 TJSONProtocol：使用 JSON 格式进行编码 TSimpleJSONProtocol：使用 JSON 编码，且只用于写的协议。适用于脚本语言解析 TDebugProtocol：使用人类友好的文本格式，便于调试 服务端支持传输层负责读取和写入。目前支持的几种方式如下： TSocket：使用阻塞式网络 IO 传输 TFramedTransport：逐帧发送数据，每帧数据都在前面加上长度信息。对于使用非阻塞式的服务来说，需要使用这种传输方法 TFileTransport：使用文件作为传送媒介 TMemoryTransport：借助内容传输。Java 的实现中使用了一个简单的 ByteArrayOutputStream 来实现 TZlibTransport：使用 zlib 压缩，可以和其它传输方式组合在一块 ProcessorProcessor 将输入和输出协议作为参数。它负责从输入读取数据，通过用户自定义的 Handler 处理数据，然后再将数据写到输出。 支持的服务模式（Supported Servers）服务器自然是用于在指定端口监听请求，并将接收到的数据发送到 Processor 处理。有这么几种服务可以用使用： TSimpleServer：单线程阻塞 IO，方便测试 ThreadPoolServer：多线程阻塞 IO TNonblockingServer：多线程非阻塞 IO，需要使用 TFramedTransport 传输方式 Thrift 语言指南类型系统Thrift 类型系统主要包括如下几个部分： 预定义的基本类型 用户定义的结构体 容器类型 异常 服务 基本类型 bool：布尔类型（可选值 true 或 false），占用一个字节 byte：有符号单字节 i16：16 位有符号整型 i32：32 位有符号整型 i64：64 位有符号整型 double：64 位浮点数类型 binary：字节串 string：编码未知文本或二进制字符串 需要注意的是，Thrfit 并不支持无符号整数，因为在很多编程语言中并没有直接的映射。 容器 list&lt;T&gt;：列表，类似 Python 中的 list set&lt;T&gt;：无序集合 map&lt;K, V&gt;：字典，类似 Python 中的 dict 容器使用的类型可以是任意合法的 Thrfit 类型（如结构体、异常等），但「服务」除外。 结构体与异常Thrift 结构体定义类似 C 语言中的 struct，对于某些 OO 语言，结构体会被翻译成 Class。 异常的定义类似结构体，可以包含不同的字段组成，但是用 exception 关键字。我们在定义服务 RPC 时，可以让某些方法抛出异常（如资源未找到）。 服务服务的定义类似 OO 编程中定义的 interface，或者 Rust 中的 trait。Thrift 编译器会生成完整的实现了接口的客户端和服务端桩（Stub）。 类型定义12typedef i32 inttypedef Tweet ReTweet 枚举类 C 的枚举定义：123456enum TweetType &#123; TWEET, RETWEET = 2, DM = 0xa, REPLY &#125; 需要注意的是，不像 Protocol Buffers，Thrift 还不支持嵌套 Enum 定义（或者嵌套结构体），枚举值必须是 32 位正整数。 注释1234567# 这是合法的注释/* * 多行注释，类似 C 语言支持的那样 */// 单行注释 命名空间Thrift 中的命名空间类似 C++ 中的那样，或者 Java 中的包的概念。由于每种语言都有自己的包管理机制（如 Python 有模块的概念），Thrift 允许针对不同的语言定制命名空间行为： 12345// 翻译成 C++ `namespace com &#123; namespace example &#123; namespace project &#123;`namespace cpp com.example.project// 翻译成 Java 包就是 `package com.example.project`namespace java com.example.project Includes我们通常可以将 Thrift 定义拆分到多个文件中以便维护、复用，使用模块化的方式进行组织。Thrift 运行在一个文件中 include 其它文件。被 include 的文件会在当前目录或者使用 -I 编译标志指定的目录中查找。 123456include &quot;tweet.thrift&quot; // 注意没有 `;` 结尾...struct TweetSearchResult &#123; 1: list&lt;tweet.Tweet&gt; tweets;&#125; 常量12345const i32 MAX_PROCS = 120; // 分号是可选的// 也可以定义复杂类型的常量，支持结构体、字典等// 使用 JSON 的格式初始化const map&lt;string, string&gt; MAP_CONST = &#123;&quot;hello&quot;: &quot;world&quot;&#125;; 结构体定义在 Thrfit IDL (Interface Defenition Language) 中，结构体是基本的构建基石。结构体组合了多个字段，每个字段有独立的标识符，类型，名称以及可选的默认值。 123456789101112struct Location &#123; 1: required double latitude; 2: required double longitude;&#125;struct Tweet &#123; 1: required i32 user_id; 2: required string user_name; 3: required: string description; 4: optional: Location loc; 5: optional: string contry = &quot;China&quot;;&#125; 对于使用 required 标记的字段，实例化时必须要赋值，否则会报错。对于 optional 字段，如果没有设置值，就不会在序列化时传输。如果 optional 字段设置了默认值，当解析结构体的时候会给相应字段赋予默认值。 不同于服务，结构体是不允许继承的，也就是说不允许扩展自其它结构体。 Required Is Forever在将一个字段设置为 required 之前一定要三思啊！如果你想在什么时候停止发送某个 required 字段时（如设置为 optional），就很容易出问题：旧版本的读取器会认为没有原先 required 字段的消息是不完整的，可能会拒绝甚至无意中丢弃掉。所以这时可能就需要编写特定的自定义校验逻辑来解决问题。有些人认为使用 required 弊大于利；他们更喜欢只用 optional。然而，这个也是因人而异，看场景需要的了。 定义服务虽然已经有很多流行的序列化/反序列化框架（如 Protocol Buffers）了，但很少有框架提供开箱即用的跨语言 RPC 服务的支持，这也是 Thrift 最主要的亮点之一。 可以把服务定义当做 Java 中的接口定义，你需要提供相应的方法名称、签名等；此外，服务也可以扩展自其它服务（使用 extends 关键字）。 Thrift 编译器会根据选择的目标编程语言生成相应的接口代码（Server 端）以及 Stubs（客户端）。Thrift 为大多数语言提供了用于运行客户端和服务端的 RPC 库。 123456789101112service Twitter &#123; // 方法定义格式类似 C 语言。需要指定返回类型、参数列表，可能会抛的异常列表 // 需要注意的是参数列表和异常列表使用的定义方式类似结构体字段定义 void ping(); // 看到没，也可以使用逗号结尾 // 不过还是建议使用分号吧 bool post_tweet(1: Tweet tweet) throws (1: TwitterUnavailable unavailable), TweetSearchResult search_tweets(1: string query); // `async` 表示客户端尽管请求，而无需等待其响应。这种方法必须是 `void` async void zip();&#125; 代码生成在前面的 协议栈 小节对整个 Thrift 协议栈有了概括性的了解，接下来将从代码生成的角度讲讲 Thrift 协议栈。 基本概念以下是 Thrift 网络栈的概念图： 1234567891011121314151617+-------------------------------------------+| cGRE || Server || (single-threaded, event-driven etc) |+-------------------------------------------+| cBLU || Processor || (compiler generated) |+-------------------------------------------+| cGRE || Protocol || (JSON, compact etc) |+-------------------------------------------+| cGRE || Transport || (raw TCP, HTTP etc) |+-------------------------------------------+ 传输层（Transport Layer）传输层提供了网络读写的简单抽象，这样可以将底层的传输和系统其它部分解耦开来（如序列化、反序列化等）。以下是 Transport 接口提供的方法： open close read write flush 除了 Transport 接口，Thrift 也使用了 ServerTransport 接口接收或创建原始的传输对象。顾名思义，ServerTransport 主要用于服务端为进入的连接创建 Transport 对象。其提供的方法如下： open listen accept close 以下是大部分 Thrift 支持的语言都会提供的传输方式： file: 从磁盘这两个读取或写入 http 协议层（Protocol Layer）协议抽象提供了将内存数据结构映射成传输格式的机制，也就是说，协议定义了数据类型如何利用底层的 Transport 层来编解码自己。因此，协议层实现负责 Schema 编码以及序列化/反序列化。常用的协议包括：JSON、XML、纯文本和压缩二进制等。 以下是 Protocol 接口定义： 12345678910111213141516171819202122232425262728293031323334353637383940writeMessageBegin(name, type, seq)writeMessageEnd()writeStructBegin(name)writeStructEnd()writeFieldBegin(name, type, id)writeFieldEnd()writeFieldStop()writeMapBegin(ktype, vtype, size)writeMapEnd()writeListBegin(etype, size)writeListEnd()writeSetBegin(etype, size)writeSetEnd()writeBool(bool)writeByte(byte)writeI16(i16)writeI32(i32)writeI64(i64)writeDouble(double)writeString(string)name, type, seq = readMessageBegin() readMessageEnd()name = readStructBegin() readStructEnd()name, type, id = readFieldBegin() readFieldEnd()k, v, size = readMapBegin() readMapEnd()etype, size = readListBegin() readListEnd()etype, size = readSetBegin() readSetEnd()bool = readBool()byte = readByte()i16 = readI16()i32 = readI32()i64 = readI64()double = readDouble()string = readString() Thrift 协议层采用面向流（Stream Oriented）的设计。例如，没必要在知道字符串或列表中的元素数量的长度的情况下，才可以序列化它们。 以下是 Thrift 支持的语言中通常会提供的协议： binary compact json 处理器（Processor）Processor 对于从输入流读取数据和写出到输出流操作做了封装，输入和输出流使用 Protocol 对象表示。接口定义非常简单： 123interface TProcessor &#123; bool process(TProtocol in, TProtocol out) throws TException&#125; 服务器（Server）服务器包含如下功能： 创建 Transport 为 Transport 创建输入、输出 Protocols 基于输入输出 Protocols 创建一个 Processor 等待连接，并将它们丢给 Processor 处理 最佳实践版本化、兼容性考量协议随着时间会不断进化的。如果现有的消息类型不再满足当前需求（例如希望给某个结构体新增一个字段）时，但是希望旧版本格式生成的代码继续兼容（向前兼容），不要担心！你可以非常轻松地更新协议而不用担心破坏之前的任何代码。不过，前提是需要遵循一些规则： 对于任何已有的字段，不要修改前面的 Tag Number 任何新增的字段都应标记为可选的。也就是说，使用旧版本消息格式生成的代码序列化的消息是可以被新生成的代码正确解析的，因为它们不会丢失任何必须的字段。对于这些字段应当设置合理的默认值，这样新的代码可以正确地与旧代码生成的消息交互。同样地，使用新代码生成的消息也可以被旧代码正确解析，只是忽略掉新增的字段。然而，未知字段并不会被遗弃，如果消息之后被序列化，未知字段还是会参与序列化的。因此，如果消息被发送到新版本代码，新增字段依然可用。 非必须的字段可以被移除掉，前提是 Tag Number 不要再次使用（推荐重命名废弃字段，可以添加 OBSOLETE_ 前缀） 可能造成版本不匹配的情况分析 参考 Thrift Tutorial Thrift The Missing Guide Thrift docs Paper: Scalable Cross-Language Services Implementation Paper: Apache Thrift 竞争对手 Data Serialization Comparison Schema evolution in Avro, Protocol Buffers and Thrift]]></content>
      <categories>
        <category>Thrift</category>
      </categories>
      <tags>
        <tag>Thrift</tag>
        <tag>RPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Beanstalkd 源码初探]]></title>
    <url>%2F2019%2F02%2F04%2Flearning-beanstalkd-source-code%2F</url>
    <content type="text"><![CDATA[引言Beanstalkd 是一个比较轻量级的消息队列服务，对于性能和稳定性要求不是特别高（相对于 RabbitMQ, Redis, Kafka 等），并且需要延迟执行任务的场景非常合适；此外，它也支持给任务设置不同的优先级、执行超时时间等。在我们的业务中，经常会借助 Beanstalkd 执行队列任务，常见的用例如下： 用户完成会员购买并激活后，发送私信通知、重置账号重命名状态等； 用户完成评论后，异步更新评论计数； 用户对私家课收听记录上报后，异步更新最近收听的小节、累积收听时长、同步到其它系统等； 用户记录添加后，会同步至 Redis，为保证数据库和 Redis 的数据最终一致性，会提前启动一个延迟校验的任务（如 5s 后），检查 Redis 中与数据库记录是否一致。 Beanstalkd 初识特点 基于 TCP 并采用 ASCII 编码的文本协议。详细定义参见：protocol.txt： 客户端负责与服务端的交互：连接、发送命令和数据、等待响应、关闭连接 服务端串行处理每个客户端连接 协议由两个部分组成：文本行（用于客户端命令和服务端响应）和非结构化的数据块（用于传送任务 body 和 stats 信息） 队列消息是存储在内存中的，但用户可以选择开启 WAL 机制（binlog），这样重启后可以回放任务，提高了可用性 采用类似 Redis 的单线程模型（IO 多路复用机制），因此不必考虑多线程环境下线程同步、加锁等，简化实现 关键词 Tube：类似 Kafka 中的 Topic，或者其它队列系统中的 Channel Job：客户端生产和消费的基本单元。每个任务都有特定的 id，可设定优先级，超时时间，延迟执行时间等 WAL (Write Ahead Log)：负责 binlog 管理（写入、压缩、日志文件清理、任务恢复等） Server：Beanstalkd 服务端 Conn：Beanstalkd 客户端连接处理 任务状态流转 任务典型生命周期 工作方式描述 服务端会有一到多个 tubes（在数组中维护）。每个 tube 都会包含一个就绪队列（在最小堆维护）以及一个延迟队列（也在最小堆维护）。每个任务都会在一个特定的 tube 中度过全部的生命周期 客户端可以使用 watch 指令订阅某个 tube，也可以使用 ignore 取消订阅，消费者可以同时订阅多个 tube，当消费者 reserve 任务时，该任务可能来自其 watch list 中的任意一个 tube 当客户端连接时，默认会使用 default tube，可以使用 use 切换 tube tube 是会根据需要随时创建的，当没有客户端引用时，就会被删除 安装借助 Docker 启动一个 Beanstalkd 服务非常轻松，请运行下面的命令行即可： 1docker run -d -p 11300:11300 schickling/beanstalkd 如果上述命令行执行正常，则 Beanstalkd 服务应该启动了，其默认监听的端口号为 11300，运行 docker ps 可以查看服务是否正常启动并运行： 编译 &amp; 运行 &amp; 调试首先，需要前往 beanstalkd 仓库克隆 Master 分支源码至本地。 为了方便管理 C 项目，这里使用了 JET BRAINS 家族的 Clion。当然，你也可以使用自己喜欢的工具打开。 由于 Clion 使用了 CMake 管理 C&amp;C++ 项目，所以打开项目时需要在其根目录下创建一个 CMakeLists.txt 文件，并填写如下内容： 12345678cmake_minimum_required(VERSION 3.13)project(beanstalkd C)set(BUILD_DIR .)add_custom_target(beanstalkd ALL COMMAND make WORKING_DIRECTORY $&#123;CMAKE_CURRENT_SOURCE_DIR&#125;)add_custom_command(TARGET beanstalkd POST_BUILD COMMAND echo copy $&#123;PROJECT_NAME&#125; to $&#123;CMAKE_CURRENT_BINARY_DIR&#125; COMMAND cp $&#123;CMAKE_CURRENT_SOURCE_DIR&#125;/beanstalkd $&#123;CMAKE_CURRENT_BINARY_DIR&#125;) 🎉 至此，准备工作已经做完啦。接下来，可以尝试点击「构建」按钮，进行编译。编译结束后，就可以点击运行启动 Beanstalkd 服务啦。哦，对了，如果需要调试支持的话，直接在需要的地方打上断点，并点击「调试」按钮即可开始。 关于 Makefile查看 Makefile 文件，可以看到有如下几个命令可以执行： make all: 编译、链接并生成可执行的二进制文件 beanstalkd。由于我们已经将该命令放到 CMakeLists.txt 文件中，在使用 Clion 构建时可自动触发 make install: 将生成的可执行文件 beanstalkd 安装到 BINDIR=$(DESTDIR)/usr/local/bin 目录下 make clean: 清理生成的 *.o 文件 make bench: 跑 Benchmark 用 客户端使用示例下面看一个简单的例子。生产者负责将一组待抓取的 URLs 放到队列中，再由一组消费者并发访问队列中的 URLs。主流程的示例代码如下： 12345678910111213141516171819// 会首先启动 NUM_WORKERS 个消费者在不同的线程中监听// 然后让生产者向队列中填充 URLs，供消费者使用fn main() &#123; const NUM_WORKERS: isize = 5; let mut handles = vec![]; for i in 0..NUM_WORKERS &#123; // 启动 NUM_WORKERS 个消费者 let hd = thread::spawn(move || consume_urls(i)); handles.push(hd); &#125; produce_urls(); // 等待消费者结束 for hd in handles &#123; hd.join().unwrap(); &#125;&#125; 生产者1234567891011121314151617181920fn produce_urls() &#123; let mut client = Beanstalkd::localhost().unwrap(); client.tube("urls").unwrap(); let urls = vec![ "https://github.com/iFaceless/ifaceless.github.io", "https://github.com/iFaceless/gic", "https://github.com/iFaceless/rust-exercises", "https://github.com/iFaceless/learning-rust", "https://github.com/iFaceless/fixture", "https://github.com/iFaceless/rest", "https://github.com/iFaceless/bigcache", "https://github.com/iFaceless/leetgogo", "https://github.com/iFaceless/freecache", ]; for url in urls &#123; client.put(url, 0, 0, 1000).unwrap(); &#125;&#125; 消费者123456789101112131415161718fn consume_urls(id: isize) &#123; println!("[Consumer &#123;&#125;] started...", id); let mut client = Beanstalkd::localhost().unwrap(); client.watch("urls").unwrap(); loop &#123; let (job_id, url) = match client.reserve() &#123; Ok(job) =&gt; job, Err(e) =&gt; &#123; println!("[Consumer &#123;&#125;] error happens: &#123;&#125;", id, e); break; &#125; &#125;; println!("[Consumer &#123;&#125;] got job &lt;&#123;&#125;&gt;: &#123;&#125;", id, job_id, url); client.delete(job_id).unwrap(); &#125;&#125; 源码探索模块分类图为了方便阅读源码，粗略地根据自己的理解给各个文件做了简单的分类： 模块 UML 图虽说 Beanstalkd 的源码是使用 C 编写的，但是其中的设计思想依然可以从面向对象的角度来解释。比如模块化设计、接口设计、多态等。根据自己的理解，对其中的一些核心模块做了梳理，并绘制了一个简单的 UML 图来加深理解： 基本数据结构最小堆二叉堆（Heap） 是一种很常见的数据结构，本质上是一棵完全二叉树。其分为最大堆（也叫大根堆） 和 最小堆（也叫小根堆）： 最大堆：根结点的键值是所有堆结点键值中最大者的堆 最小堆：根结点的键值是所有堆结点键值中最小者的堆 在 beanstalkd/heap.c 是对最小堆的实现。那么，beanstalkd 中哪些地方用到了最小堆呢？ Tube 中的延迟任务队列（最先到期的任务会在堆顶，这样可以在 O(1) 时间复杂度获取到） Tube 中的就绪任务队列（基于优先级排列，优先级最高的任务会在堆顶） Server 中的客户端连接队列（基于 tickat 时间排列） 接下来，我们看看最小堆的实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566intheapinsert(Heap *h, void *x)&#123; int k; // 扩容策略：2 倍长度 if (h-&gt;len == h-&gt;cap) &#123; void **ndata; int ncap = (h-&gt;len+1) * 2; /* allocate twice what we need */ ndata = malloc(sizeof(void*) * ncap); if (!ndata) &#123; return 0; &#125; memcpy(ndata, h-&gt;data, sizeof(void*)*h-&gt;len); free(h-&gt;data); // 指向新的位置 h-&gt;data = ndata; // 更新容量 h-&gt;cap = ncap; &#125; k = h-&gt;len; h-&gt;len++; set(h, k, x); siftdown(h, k); return 1;&#125;void *heapremove(Heap *h, int k)&#123; void *x; if (k &gt;= h-&gt;len) &#123; return 0; &#125; x = h-&gt;data[k]; h-&gt;len--; // 用原来的数组最后一位覆盖被删除的位置 set(h, k, h-&gt;data[h-&gt;len]); siftdown(h, k); siftup(h, k); h-&gt;rec(x, -1); return x;&#125;static voidset(Heap *h, int k, void *x)&#123; h-&gt;data[k] = x; // 这里会去调用相应的回调函数 h-&gt;rec(x, k);&#125;// 判断位置 a 指向的对象是否小于 b 指向的对象static intless(Heap *h, int a, int b)&#123; // h-&gt;less 是一个判断大小的回调 // 其实要在面向对象的语言中，完全可以自定一个实现了比较大小的接口 // 比如在 Rust 中，可以使用 `PartialEq` 限定... return h-&gt;less(h-&gt;data[a], h-&gt;data[b]);&#125; 变长数组在 C 语言标准库中是没有可变长度的数组实现的，所以在 beanstalkd/ms.c 实现了一种类似的数据结构，它具有如下特点： ms 结构体维护一个可动态扩容的数组（**items） 扩容策略很粗暴，直接扩充为原来容量的两倍 插入的平均时间复杂度为 O(1) 删除的平均时间复杂度为 O(1) 由于删除时，会将尾部 item 替换掉被删除的 item，所以不能依赖数组中的元素顺序（顺序不保证和添加时一致） 删除 item 后，其实数组占用的内存空间还在（并没有动态缩容的策略） 那具体在哪些地方用到了 ms 这种数据结构呢？梳理后，主要发现以下几处： 全局的 Tube 列表 客户端连接的 Conn 中维护的 watch list 与 Tube 关联的等待连接（conns）列表 下面看看其具体的实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// 初始化数组，并注册插入和移除的回调函数voidms_init(ms a, ms_event_fn oninsert, ms_event_fn onremove)&#123; a-&gt;used = a-&gt;cap = a-&gt;last = 0; a-&gt;items = NULL; a-&gt;oninsert = oninsert; a-&gt;onremove = onremove;&#125;// 控制数组增长static voidgrow(ms a)&#123; void **nitems; // 倍速增长：1, 2, 4, ... size_t ncap = (a-&gt;cap &lt;&lt; 1) ? : 1; nitems = malloc(ncap * sizeof(void *)); if (!nitems) return; // 旧的数据拷贝到新开辟的空间 memcpy(nitems, a-&gt;items, a-&gt;used * sizeof(void *)); // 释放旧的内存空间 free(a-&gt;items); // 指向新的位置 a-&gt;items = nitems; // 更新数组容量 a-&gt;cap = ncap;&#125;// 在数组尾部插入新的 item// O(1)intms_append(ms a, void *item)&#123; // 按需扩展容量 if (a-&gt;used &gt;= a-&gt;cap) grow(a); // 扩容失败，就返回，也就是不能再新增 item 了 if (a-&gt;used &gt;= a-&gt;cap) return 0; a-&gt;items[a-&gt;used++] = item; // 如果有回调，则触发回调函数 if (a-&gt;oninsert) a-&gt;oninsert(a, item, a-&gt;used - 1); return 1;&#125;// 删除指定位置的 item// O(1)static intms_delete(ms a, size_t i)&#123; void *item; if (i &gt;= a-&gt;used) return 0; item = a-&gt;items[i]; // 相当于把尾部 item 写到被删除的位置，并「缩容」 a-&gt;items[i] = a-&gt;items[--a-&gt;used]; /* it has already been removed now */ if (a-&gt;onremove) a-&gt;onremove(a, item, i); return 1;&#125; 字典 在 beanstalkd/job.c 中，为了方便基于 job_id 快速定位到具体的任务，作者实现了一个字典数据结构。这里是和 job 耦合在一起实现的，根据对源码的分析，可以得出该字典数据结构的特点如下： 采用基于 job_id 哈希取模的方式计算 slot_id 使用链地址法解决哈希冲突 根据负载因子自动进行 rehash（进行扩容或缩容），扩容或者缩容的系数根据 beanstalkd/primes.c 设置 rehash 过程并没有采用类似 Redis 中渐进式 rehash 机制，而是阻塞式完成整个哈希表的 rehash 后才可以进行后续操作 存放 job 及 rehash 的详细源码分析如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566// 存放一个 jobstatic voidstore_job(job j)&#123; int index = 0; index = _get_job_hash_index(j-&gt;r.id); j-&gt;ht_next = all_jobs[index]; // 如果存在冲突，就采用链地址法 all_jobs[index] = j; all_jobs_used++; /* accept a load factor of 4 */ // 负载因子设置为 4，超过阈值时就会进行 rehash // 看起这里是阻塞的方式来进行 rehash 了，如果 hash 表太大，会被阻塞 // 并没有使用类似 redis 那样渐进式 rehash 思路 if (all_jobs_used &gt; (all_jobs_cap &lt;&lt; 2)) rehash(1);&#125;// 支持扩容和缩容static voidrehash(int is_upscaling)&#123; job *old = all_jobs; // 记录下旧的 hash 表容量，元素个数 size_t old_cap = all_jobs_cap, old_used = all_jobs_used, i; int old_prime = cur_prime; int d = is_upscaling ? 1 : -1; if (cur_prime + d &gt;= NUM_PRIMES) return; if (cur_prime + d &lt; 0) return; if (is_upscaling &amp;&amp; hash_table_was_oom) return; cur_prime += d; all_jobs_cap = primes[cur_prime]; all_jobs = calloc(all_jobs_cap, sizeof(job)); if (!all_jobs) &#123; // 针对扩容失败的处理，恢复原来的不变，但是标记 OOM twarnx("Failed to allocate %zu new hash buckets", all_jobs_cap); hash_table_was_oom = 1; cur_prime = old_prime; all_jobs = old; all_jobs_cap = old_cap; all_jobs_used = old_used; return; &#125; // 重置 hash 表状态 all_jobs_used = 0; hash_table_was_oom = 0; // 其实就是把 Hash 表上所有的 jobs 全部映射到新的空间 for (i = 0; i &lt; old_cap; i++) &#123; while (old[i]) &#123; job j = old[i]; old[i] = j-&gt;ht_next; j-&gt;ht_next = NULL; store_job(j); &#125; &#125; // 然后把原来的内存空间释放掉 if (old != all_jobs_init) &#123; free(old); &#125;&#125; 链表链表这种数据结构在 Beanstalkd 实现中用得比较频繁，比如 beanstalkd/walg.c 中使用了单向链表的串联了一些列的日志文件（参见三个游标指针：head, cur, tail） beanstalkd/conn.c 使用双向链表连接了一些列被 reserve 的任务 在 beastalkd/job.c，可以看到任务双向链表实现： 123456789101112131415161718192021222324252627282930intjob_list_any_p(job head)&#123; return head-&gt;next != head || head-&gt;prev != head;&#125;jobjob_remove(job j)&#123; if (!j) return NULL; if (!job_list_any_p(j)) return NULL; /* not in a doubly-linked list */ j-&gt;next-&gt;prev = j-&gt;prev; j-&gt;prev-&gt;next = j-&gt;next; j-&gt;prev = j-&gt;next = j; return j;&#125;voidjob_insert(job head, job j)&#123; if (job_list_any_p(j)) return; /* already in a linked list */ j-&gt;prev = head-&gt;prev; j-&gt;next = head; head-&gt;prev-&gt;next = j; head-&gt;prev = j;&#125; 部分模块源码学习main.c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657intmain(int argc, char **argv) &#123; int r; // 存放任务的链表 struct job list = &#123;&#125;; progname = argv[0]; // 设置使用行缓存，表使用标准输出作为打印目标 // 详细文档参见：https://linux.die.net/man/3/setlinebuf // 意思是，只有在满足一行（换行）时才输出 setlinebuf(stdout); // 命令行处理 optparse(&amp;srv, argv + 1); if (verbose) &#123; printf("pid %d\n", getpid()); &#125; // 服务器端 socket 初始化等，返回一个指向 socket 的 file descriptor r = make_server_socket(srv.addr, srv.port); if (r == -1) twarnx("make_server_socket()"), exit(111); srv.sock.fd = r; // 协议处理模块初始化 prot_init(); if (srv.user) su(srv.user); set_sig_handlers(); if (srv.wal.use) &#123; // We want to make sure that only one beanstalkd tries // to use the wal directory at a time. So acquire a lock // now and never release it. // WAL 即 Write Ahead Log Directory，主要是记录日志用 // 这里是要保证每次只能有一个 beanstalkd 实例使用 WAL 目录，防止相互写入冲突 // 那估计以后就没法从 binlog 恢复任务了。。。 if (!waldirlock(&amp;srv.wal)) &#123; twarnx("failed to lock wal dir %s", srv.wal.dir); exit(10); &#125; // 初始化任务链表（双向链表） list.prev = list.next = &amp;list; // 初始化 WAL，如果 log 中有任务，还要恢复回来，挂载到 job list walinit(&amp;srv.wal, &amp;list); // 回放任务执行 r = prot_replay(&amp;srv, &amp;list); if (!r) &#123; twarnx("failed to replay log"); return 1; &#125; &#125; // 正式启动 server，并监听请求，处理请求了 srvserve(&amp;srv); return 0;&#125; serv.c1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556voidsrvserve(Server *s)&#123; int r; Socket *sock; int64 period; if (sockinit() == -1) &#123; twarnx("sockinit"); exit(1); &#125; s-&gt;sock.x = s; // 指定回调，当接收到 `r` 事件后，就会触发这个回调 s-&gt;sock.f = (Handle)srvaccept; // Server 维护了关联的客户端连接（最小堆） s-&gt;conns.less = (Less)connless; s-&gt;conns.rec = (Record)connrec; r = listen(s-&gt;sock.fd, 1024); if (r == -1) &#123; twarn("listen"); return; &#125; // 注册 r = sockwant(&amp;s-&gt;sock, 'r'); if (r == -1) &#123; twarn("sockwant"); exit(2); &#125; for (;;) &#123; // 执行周期性的任务 // 如果 tick 中执行的任务时间过久，会阻塞后面的 socket connection 处理 // 严重会导致超时，而如果客户端重试过多，则回增加服务端负载 period = prottick(s); // 轮询是否有就绪的请求（rw），其实就是个适配器，将具体平台下返回的状态 // 转换成统一的 `r`, `w`, `h` // Linux 使用 epoll 封装（参见 `linux.c`） // Unix 使用 kqueue 封装（参见 `darwin.c`） int rw = socknext(&amp;sock, period); if (rw == -1) &#123; twarnx("socknext"); exit(1); &#125; if (rw) &#123; // 如果轮询到需要处理的请求，则执行相应的回调 Handle // 注意，这里的回调依然在主线程中执行的，所以如果主线程被阻塞，就呵呵哒了 sock-&gt;f(sock-&gt;x, rw); &#125; &#125;&#125; tube.c12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394// 新建 tube，这里需要给定 tube 名称// 这里可以看到一个 tube 有几个比较重要的组成：// 1. 维护就绪任务的堆// 2. 维护延迟执行任务的堆// 3. 维护处于 buried 状态的任务链表// 4. 维护一个等待列表tubemake_tube(const char *name)&#123; tube t; // 分配内存空间，用于存储 tube 结构体值 t = new(struct tube); if (!t) return NULL; // 初始化 tube 名称 t-&gt;name[MAX_TUBE_NAME_LEN - 1] = '\0'; strncpy(t-&gt;name, name, MAX_TUBE_NAME_LEN - 1); if (t-&gt;name[MAX_TUBE_NAME_LEN - 1] != '\0') twarnx("truncating tube name"); // ready 堆维护着一些已经就绪的 jobs，这里是指定按照 job 优先级的方式比较大小 // 这样，这个堆顶就是优先级最高的 job t-&gt;ready.less = job_pri_less; // delay 堆维护着一些被延迟执行的 jobs，这里是按照 job delay 时间比较大小 // 这样，这个堆顶就是延迟时间最短的 job t-&gt;delay.less = job_delay_less; // 用于记录 job 在堆上的位置 t-&gt;ready.rec = job_setheappos; t-&gt;delay.rec = job_setheappos; t-&gt;buried = (struct job) &#123; &#125;; // 使用链表维护着被 bury 掉的 job t-&gt;buried.prev = t-&gt;buried.next = &amp;t-&gt;buried; // 初始化排队列表 ms_init(&amp;t-&gt;waiting, NULL, NULL); return t;&#125;// 释放 tubestatic voidtube_free(tube t)&#123; // 实际就是从全局的 tubes 列表中移除该 tube prot_remove_tube(t); // 释放就绪的任务 free(t-&gt;ready.data); // 释放延迟的任务 free(t-&gt;delay.data); // 清空等待列表 ms_clear(&amp;t-&gt;waiting); // 释放 tube 指向的内存 free(t);&#125;// 引用计数：减引用voidtube_dref(tube t)&#123; if (!t) return; if (t-&gt;refs &lt; 1) return twarnx("refs is zero for tube: %s", t-&gt;name); --t-&gt;refs; // 没有引用后就可以释放该 tube 了 if (t-&gt;refs &lt; 1) tube_free(t);&#125;// 引用计数：增加引用voidtube_iref(tube t)&#123; if (!t) return; ++t-&gt;refs;&#125;// 新建一个 tube，然后注册到全局 tubes 列表static tubemake_and_insert_tube(const char *name)&#123; int r; tube t = NULL; t = make_tube(name); if (!t) return NULL; /* We want this global tube list to behave like "weak" refs, so don't * increment the ref count. */ // 这里是想让全局 tube 列表表现为弱引用，所这里并没有做增加引用的操作 r = ms_append(&amp;tubes, t); // 如果注册 tube 失败，减引用，必要的话会被释放掉 if (!r) return tube_dref(t), (tube) 0; return t;&#125; job.c在 Tube 中有两个最小堆数据结构分别存放被延迟的任何和就绪的任务，这两种使用的排序方式是不同的。我们看到在上面的 Tube 初始化时，给两个堆绑定了不同的比较大小的回调： 12t-&gt;ready.less = job_pri_less;t-&gt;delay.less = job_delay_less; 以下可以看到具体的排序方式： 12345678910111213141516171819// 回调函数，先基于优先级比较哪个小，再基于 id 比较哪个小intjob_pri_less(void *ax, void *bx)&#123; job a = ax, b = bx; if (a-&gt;r.pri &lt; b-&gt;r.pri) return 1; if (a-&gt;r.pri &gt; b-&gt;r.pri) return 0; return a-&gt;r.id &lt; b-&gt;r.id;&#125;// 回调函数，先基于到期时间比较哪个小，再基于 id 比较哪个小intjob_delay_less(void *ax, void *bx)&#123; job a = ax, b = bx; if (a-&gt;r.deadline_at &lt; b-&gt;r.deadline_at) return 1; if (a-&gt;r.deadline_at &gt; b-&gt;r.deadline_at) return 0; return a-&gt;r.id &lt; b-&gt;r.id;&#125; 读后感整个 Beanstalkd 的核心的代码不过五千行左右，但这就实现了一个生产级别的消息队列，的确是很厉害。不过，也正因为其实现比较简单，所以也没有提供类似 Redis 的主从机制等。当然，在这篇文章中，并没有完整地剖析所有的模块实现，只是列出了个人比较感兴趣的模块；关于 binlog 管理的源码（比如垃圾回收，压缩，预留空间申请，任务恢复等）只是粗略地阅读了下，就不在此处献丑啦~ 总的来说，对于单机消息队列实现感兴趣的同学还是推荐阅读下该系统的源码，可以学习其中的一些设计思想，实现思路等~ 参考 beanstalkd 的一些看法 beanstalkd repo beanstalkd docs 消息队列 beanstalkd 源码详解 最大—最小堆 延伸阅读 Kqueue 与 Epoll 机制 从 0到 100——知乎架构变迁史]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>源码学习</tag>
        <tag>消息队列</tag>
        <tag>Beanstalkd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《架构整洁之道》学习笔记之编程范式]]></title>
    <url>%2F2019%2F01%2F03%2Fclean-arch-notes-paradigms%2F</url>
    <content type="text"><![CDATA[引言近来开始阅读 Robert C. Martin 的新著《架构整洁之道》（Clean Architecture）。没有人愿意看到团队内的项目逐渐发展成一团乱麻，相互纠缠。那如何从根本上减少这种问题的发生呢？这就需要我们掌握一些宏观层面的设计思想，从给项目打基础时就应该考虑好各个模块、类、函数等如何设计成高内聚、低耦合的结构。整洁的项目架构是利于长远发展的，这篇笔记将会记录一些从书中学习到的重要知识点，便于后期复习和参考。 当然，作者还有一本大名鼎鼎的著作《代码整洁之道》也非常值得阅读，关于这本书也做了点笔记，参见《代码整洁之道》读书笔记~ 要点记录三大编程范式是根基，每种范式其实都给我们带走了一些东西：goto 语句、函数指针、赋值。三种编程范式的总结： 结构化编程：Discovered by Edsger Wybe Dijkstra in 1968. Structured programming imposes discipline on direct transfer of control. 面向对象编程：Discovered by Ole Johan and Kristen Nygaard in 1966. Object-oriented programming imposes discipline on indirect transfer of control. 函数式编程：Invented by Alonzo Church in 1936. Functional programming imposes discipline upon assignment. 以上三种编程范式会影响到架构的方方面面：我们使用多态机制跨越架构边界；使用函数式编程影响数据位置和访问；使用结构化编程构建基础算法模块（基石）。可以对照软件架构三大概念：功能、组件隔离和数据管理。 结构化编程 任何程序都可以由三种结构组成： Sequence Selection Iteration 结构化编程允许模块可以被递归地分割成很多小的可被证明的单元，这也就意味着模块可以按照功能解耦 科学并非依靠证明某些声明正确而存在，而是证明它们是错误的（Science does not work by proving statements true, but rather by proving statements false）。并非所有的事情都可以被证实的~ Mathmematics is the discipline of proving provable statements true. Science, in contrast, is the discipline of proving provable statements false Dijkstra 曾经说过 Testing shows the presence, not the absence, of bugs。测试并不能保证你的程序一定正确，但是可以通过测试证明你的程序存在错误，并通过充分测试，让你的程序更加正确，直到满足我们的预期 面向对象编程 设计良好的架构需要我们理解并应用 OO 的一些原则 什么是面向对象： 数据 + 行为的组合 为真实世界建模 封装（Encapsulation）、继承（Inheritance）和多态（Polymorphism） UNIX 系统要求每个 IO 设备驱动都需要提供五个标准函数：open, close, read, write 和 seek 多态实际上就是函数指针的应用，自从冯诺依曼架构诞生以来，程序员们就一直在使用这种技术了。但是显式地使用函数指针是很危险的，并且使用时需要遵循一些原则，比较麻烦。OO 则将你从中解放出来，让你更加轻松地实现多态。 OO 允许在任何地方，为任何情形使用插件式架构（主要是多态的威力，其实在其它语言中，如 Rust/Go，使用接口机制也能达到类似的目的） 使用 OO 语言可以完全控制系统中源码的依赖方向。多态机制可以让任何源码依赖都可以被倒置，无论它们在哪儿 OO 带来的好处，用几个关键字概括： 依赖倒置（Dependency inversion） 可独立部署性（Independent deployability） 可独立开发性（Independent developability） 从软件架构的角度看，面向对象可以通过使用强大的多态机制，来控制系统源码依赖。这样可以创建出插件式架构，可以将更高层的抽象策略和底层的实现隔离开。底层的实现细节交给各个插件去完成，并且它们可以被独立开发和部署，而不会和更高层的模块耦合。 函数式编程 所有的竞争条件、死锁条件和并发更新的问题都是由可变变量导致的。函数式编程则限制了变量修改 将可变和不可变的组件隔离开来：不可变组件使用函数式执行任务（不使用任何可变量）；不可变组件通过和可变组件通信的方式来做状态变更 Event Sourcing: 核心策略是不存储状态，而是存储事务。当需要获取状态时，只需要从最开始回放事务，最终得到想要的状态。这样的系统就只有 CR（创建、读取） 了，而不会存在状态更新和删除。因此，很多并发引来的更新问题都不会发生（其实可以对比下基于日志式 LSM 的存储引擎）。 总结结构化编程、函数式编程以及面向对象编程都分别给我们带来了不同的限制（To tell us what not to do），而非带来新的功能。软件并非快速发展的高科技，因此很多原则至今依然适用。不管机器怎么变化、工具如何变得更好，但软件的本质还是一样。所谓的软件程序不过就是由顺序、选择、循环结构（间接）组成，不多不少。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>架构</tag>
        <tag>设计思维</tag>
        <tag>编程范式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rust 入坑记]]></title>
    <url>%2F2018%2F12%2F31%2Frust-learning-notes%2F</url>
    <content type="text"><![CDATA[引言谢天谢地，总算赶在 2018 年结束前完成了 Rust 之旅（当然还是入门级别）。之所以想要入坑这门语言，也是想要在研究 TiKV 时候不要被语言卡主。另外，学习新的语言也是为了开阔视野，学习新的思路~正如很多前辈所言，Rust 的门槛其实挺高的，所以绝对不适合新手作为入门语言！幸运的是，早些年就接触并学习了 C, Java, C#, Python, Go 等语言，所以对于其中某些类似的概念理解起来就比较轻松（如 trait, struct 和一些面向对象的模式等）。但是，这门语言还是有很多比较新的概念非常与众不同： 所有权和生命周期、生命周期注解 Trait 和 Trait Objects 声明宏和过程宏 智能指针（我没了解过 C++ 的智能指针，不好对比） 非常强大的模式匹配（花样非常多） 非常可爱的错误处理方式（对比下 Go 呆板处理方式就知道了） 关于语法方面，倒是觉得可以「忍受」，毕竟习惯了也就可以了。但是由于概念很多，包括使用的符号太多（键盘上你能看到的符号基本都用上了），还是需要强大的理解力和记忆力才可以把持住吧，至少像我这样的老人家表示看完一遍根本不行，不管怎么样，先入坑~ 入坑时学习的是官方推荐的 Rust Book，对应的中文翻译版本可以参考 Rust 程序设计语言。但是需要注意的是，中文译本有些翻译不太通顺的地方，所以可以对照着去看英文版~ 前段时间 Rust 1.31.0 发布了，所以也跟着升级了下。由于书中的例子应该是以 Rust 2015 版本为主的，所以有极少部分示例不能在 Rust 2018 中使用，可以参照提示，使用 cargo fix 一下即可完成迁移~ 学习过程中敲了些代码，参见 Learning Rust 仓库，有兴趣也可以去看，代码中添加很多注释，应该可以帮助理解~ 下面把学习期间做的笔记做个汇总，方便老人家回顾~ 变量 Rust 中变量分为两种： 不可变的变量（只读） 可变的变量（mut 声明） 声明的同名变量具有 shadowing 效果 可以定义常量，使用关键词 const 定义 变量与常量的区别： 变量的赋值可以来自某个函数（运行时确定） 常量的赋值则需要则只能来自简单的表达式 作用域不同，常量的作用域全局 声明方式不同，常量在定义时需要指定类型，无法使用类型推断 所有权Rust 的所有权机制相对其它语言还是比较独特的。可以看到它是如何借助所有权来管理所有在堆上申请的内存空间的。与其它拥有 GC 或者需要手动管理内存的语言来说，通过所有权管理内存还是挺特别的。 Rust 编译器能够在编译时提供很多安全检查，比如存在数据写入竞争的程序都无法通过编译，这样就大大减少了运行时排查错误的可能。 规则 Rust 中每一个值都有一个被称为其所有者 Owner 的变量 值有且只能有一个所有者 当所有者（变量）离开作用域，值会被抛弃（内存回收） 注意点 Rust 中变量的赋值，和传统语言不通，它做的是所有权转移的工作，也就是之前的变量就会被失效了 如果一个类型有 Copy trait，一个旧的变量在将其赋值给其它变量后仍然可用（如在栈上分配的整数） Rust 永远不会自动创建数据的「深拷贝」，所以任何自动的复制，可以认为对运行时的性能影响较小 引用和借用 在任意给定的时间，要么只能有一个可变引用，要么只能有多个不可变引用 引用必须总是有效 Slice 切片 没有所有权的数据类型，允许引用集合中一段连续的元素序列，而不用引用整个集合 切片语法（感觉和 Python 或者 Go 类似）： start..end 对应的是 [start, end) 这样的区间 而 start..=end 则表示 [start, end] 区间 start.. 表示从 start 开始到结尾 .. 则表示从头到尾 字符串字面值就是 Slice &amp;str 结构体 struct 可以用来自定义数据类型，类似面向对象语言中的数据属性 结构体初始化，每个字段都需要显式赋值，字段初始化顺序可以不用关心 mut 和 imut 是针对整个结构体而言的，不允许结构体部分字段设置为 mut 变量与字段同名时，可以简化结构体初始化写法 元组结构体，相当于给元组类型命名了，这样可以有别于其他类型元组，只需要指定类型，不需要命名字段 类单元结构体（unit-like structs）： 没有任何字段的结构体 类似 () 适用于在某个类型上实现 trait，但不需要存储数据 生命周期会保证结构体引用的数据有效性和结构体保持一致 很多基本类型都实现了 Display trait，所以在使用 println!(&quot;{}&quot;) 时可以正常打印；但 rust 默认不会打印出结构体的展示信息，使用 {:?} 会使用 Debug trait，从而打印出结构体的调试信息。使用 derive 注解，可以使用 trait。 Rust 有自动引用和解引用的功能，会自动为 object 添加 &amp;, &amp;mut 或 *，从而和方法的签名匹配 Rust 中的关联函数（associated functions）是放在 impl 块中， 和结构体本身有较大的相关性，但不是方法 第一个参数也不是 self 依然是函数 类似其它语言中的类的静态方法 每个结构体都允许拥有多个 impl 块 结构体并非创建自定义类型的唯一方法！ 枚举与模式匹配 Rust 中的枚举类似于 F#, OCaml 和 Haskell 这种函数式编程语言中的**代数数据类型（algebraic data types） 枚举还可以存储数据（自定义的那种，类似的概念可以用结构体来表达，但是比较麻烦） 枚举的每个成员可以处理不同类型和数量的数据（可以将任意类型数据放入枚举成员中） Rust 枚举实在太强大了，甚至可以实现方法，远不是 Python/Go 中那种简单的枚举可比的 一个常用的标准库枚举类型 Option，应对的场景：一个值要么有值要么没值（WTF?） Rust 中没有空值（Null）的功能：空值和非空值 只要一个值不是 Option&lt;T&gt; 类型，就可以安全的认为它的值不为空 match 是非常强大的控制流运算符，可以将一个值和一系列的模式相比较，并根据相匹配的模式执行相应的代码 Rust 不允许 match 没有匹配处理各种情况，Rust 中的匹配是穷尽的 （） 是一个 unit 值 if let 适合匹配一种情况的时候替代 match，减少样板代码编写，match 的语法糖 模块与代码复用 模块（module）是一个包含函数或类型定义的命名空间 mod 声明新模块，模块中的代码要么直接位于声明后的大括号中，要么位于另一个文件 函数、类型、常量和模块默认都是私有的，pub 可以控制其在模块外可见 use 关键字将模块或者模块中的定义引入到作用域中以便于引用它们 Rust 中多个模块可以位于一个文件中，且模块可以嵌套，以构成更符合逻辑的结构 Rust 默认只知道 lib.rs 内容，所以模块的声明或者定义都需要放在该文件 模块文件系统的规则： 如果 foo 模块没有子模块，应该将 foo 的声明放在 foo.rs 的文件中 如果 foo 模块有子模块，应该将 foo 的声明放在 foo/mod.rs 的文件中 Rust 中模块和函数默认均为私有的，必须要同时设置为公有，才能在外部访问模块中的函数 私有性规则： 如果一个项是公有的，它能被任何父模块访问 如果一个项是私有的，它能被直接父级模块及其任何子模块访问 use 只将指定的模块引入作用域，但不会将其子模块也引入 通用集合类型 集合 是一些列有用的数据结构体，不同于内建数组和元组，这些集合指向的数据是存储在堆上的 三种广泛使用的集合： vector：变长，连续存储一系列值（类似 Python 的 list） 字符串：字符集合 哈希：就是 map vector 只能存储相同类型的值，其存储的值在内存中彼此相邻排列 vector 的结尾在新增元素时，如果没有足够空间将所有元素依次相邻存放的情况下，可能会要求分配内存，并将老的元素拷贝到新的空间。所以 Rust 是不允许在引用的某个元素时，不可以进行修改 可以借助 enum 实现在 vector 中存储多种类型元素目标 Rust 的核心语言中只有一种字符串类型：str，即字符串 slice，以借用的形式出现 &amp;str，UTF-8 编码 String 类型是由标准库提供的，可变长、有所有权、UTF-8 编码的字符串类型 Rust 标准库还提供了其他字符串类型：OsString, OsStr, CString, CStr，它们和 String 或者 str 拥有不同的编码或内存表现形式，各自拥有一些使用场景 String 支持 + 运算符、format! 拼接字符串 format! 和 print! 宏类似，并且不会获取参数的所有权 Rust 中，String 或者 str 类型是不支持索引获取的： String 在底层使用 Vec&lt;u8&gt; 存储字符字节，由于不同的语言使用 UTF-8 编码时，需要的字节是不一样的，为了避免返回无效的（无意义）字节值，Rust 选择不编译这种索引访问的情况 由于索引操作预期是常数时间 O(1)，但 String 中实现索引不能保证这样的性能 使用字符串 Slice 时需要谨慎，防止 &amp;s[n..m] 操作取出来的是非法的字符（编译时会让通过），当然 Rust 会在运行时直接 panic 可以对 &amp;String.chars() 遍历获得每个字符，对 &amp;String.bytes() 遍历获得每个字节 HashMap&lt;k, v&gt; 类似其它语言中的字典（map）。其并不在 preclude 中，所以在使用时，需要 use 导入到作用域 错误处理 Rust 中将错误分为两大类：可恢复错误（recoverable） 和 不可恢复错误（unrecoverable）。可恢复的错误通常代表向用户报告错误和重试操作是否合理的情况，如文件不存在。而不可恢复的错误则通常是很严重的 bug 可恢复的错误是 Result&lt;T, E&gt;，而 panic! 会在遇到不可恢复的错误时终止执行。注意这个和其它语言中的异常机制还是不太一样的 panic 时，默认会开始展开（unwinding），从而回溯栈并清理遇到的每个函数的数据，但这个回溯并清理的过程有很多工作。你可以选择直接终止（abort），让操作系统来清理内存。 如果希望二进制文件越小越好，可以在 Cargo.toml 中添加下面的配置，这样在 panic 时直接终止执行： 12[profile.release]panic = 'abort' 我们使用 Result 类型来作为返回，用于应付一些常规错误（如文件不存在），定义如下： 1234enum Result&lt;T, E&gt; &#123; Ok(T), Err(E),&#125; 可以使用闭包（closure）来减少因错误处理而嵌套多层 match 的问题 当然，还可以使用 unwrap 和 expect 处理错误 错误传递在 Rust 中很常见，所以有个 ? 操作符语法糖可以替代繁琐的 match 写法。此外，? 还将错误值传递给 from 函数（定义于 From trait` 中），用于将一种错误类型转换为另一种类型 ? 操作符只能被用于返回 Result 类型的函数中 关于数据校验，可以定义一个新的类型，把校验逻辑收敛到 new 方法，这样所有函数均使用该类型，从而让各个依赖该参数的函数不用编写繁琐的校验逻辑 要不要 panic!这里给出一些指导性原则，来帮助你在不同场景下，如何更好的处理错误，决定是否需要 panic! 还是传递错误到上层。 在编写示例、原型代码或者测试时，建议用 unwrap 或者 expect，简单处理错误的情况（直接 panic! 掉），把焦点放在核心功能实现上，然后再处理具体的错误 遇到非常规可预期的错误状态时，建议 panic! 掉 泛型、Trait 和生命周期 很多语言都有处理重复概念的工具，Rust 中的工具之一就是泛型（generics） 泛型可以认为是具体类型的高层抽象，我们可以基于泛型去实现一些通用的关联方法，而不需要知道 concrete type。想想 Go 没有泛型，就知道多惨了 trait 可以与泛型结合，将泛型限制为拥有特定行为的类型，而不是任意类型 任何字符都可以作为类型参数名，之所以用 T 是 Rust 的习惯用法，T 作为 type 的缩写也很合适 使用 &lt;&gt; 来定义泛型 Rust 中使用泛型实现的代码和使用具体类型实现的代码，在性能上不会有任何损失。Rust 通过在编译时进行泛型代码单态化（monomorphization）来保证效率。单态化是指通过填充编译时使用的具体类型，将通用代码转为特定代码的过程 trait 以一种抽象的方式定义共享行为，可以使用 trait bounds 指定泛型是任何拥有特定行为的类型 trait 定义是一种将方法签名组合起来的方法，目的是定义一个实现某些目的所必须的行为集合 注意：只有当 trait 或者要实现 trait 的类型位于 crate 的本地作用域时，才能为该类型实现 trait trait 中定义的方法是可以有默认实现的，具体类型在实现 trait 时可以选择重载方法，但不支持调用默认方法（Oops） trait 可以作为参赛（类似 Go 里面的函数接收一个 interface） 注意下面两种是不同的： 123456// 这里允许 item1 和 item2 是不同的类型，只要都实现了 `SomeTrait`pub fn notify(item1: impl SomeTrait, item2: impl SomeTrait);// 这里就会要求 item1 和 item2 是不同的类型，也就是只有 trait bound 这种写法// 才可以做到这样的限制pub fn notify&lt;T: SomeTrait&gt;(item1: T, item2: T); 与 Go 的函数可以返回 interface 类似，Rust 支持返回 trait，但是不同的是，只能返回一种实现了该 trait 的类型。不过依然会有更高级的方法做到，请继续往后学习！ 任何满足特定 trait bound 的类型实现 trait 被称为 blanket implementations，广泛应用于 Rust 标准中。如标准库为任何实现了 Display trait 的类型实现了 ToString 方法 生命周期和引用有效性 生命周期的主要目标是避免悬垂引用 Rust 编译器中的借用检查器（borrow checker）是用来比较作用域，从而确保所有的借用都是有效的 生命周期注释： 12345678910&#123; let r; // ---------+-- 'a // | &#123; // | let x = 5; // -+-- 'b | r = &amp;x; // | | &#125; // -+ | // | println!("r: &#123;&#125;", r); // |&#125; // ---------+ 生命周期的注解并不会改变任何引用的生命周期长短。当函数指定了泛型生命周期后，可以接受任何生命周期的引用。生命周期注解描述了多个引用生命周期的相互关系，而不影响其生命周期。生命周期注解在借用检查器的帮助下，会指出不遵守协议的入参。 泛型生命周期 &#39;a 的具体生命周期等同于多个函数参数中生命周期较小的那个 生命周期语法是用于将函数的多个参数与其返回值的生命周期进行关联的，一旦它们形成了某种关联，Rust 就有足够的信息来允许内存安全的操作并阻止产生悬垂指针或违反内存安全的行为 Rust 存在生命周期省略规则（lifetime elision rules），这些规则是一系列特定场景，如果符合规则，无需手动指定生命周期 生命周期省略规则： 函数或方法的参数生命周期叫做输入生命周期 返回值的生命周期叫做输出生命周期 规则适用于 fn 和 impl 块 规则一：每一个是引用的生命周期都有其自己的生命周期参数（各个生命周期参数是不同的） 规则二：如果只有一个输入生命周期参数，则它会被赋予所有输出生命周期参数 规则三：如果方法有多个生命周期参数（&amp;self 和 &amp;mut self），则 &amp;self 的生命周期被赋予给所有输出生命周期参数 静态生命周期： &#39;static，生命周期存活于整个程序运行期间 所有字符串字面值都有 &#39;static 生命周期 如果编译器提示加 &#39;static 生命周期建议时，应该看看是不是自己的实现方式有问题，而不是盲目添加 &#39;static 生命周期 单元测试与集成测试 Edsger W. Dijkstra: Program testing can be a very effective way to show the presence of bugs, but it is hopelessly inadequate for showing their absence. Rust 中的测试函数是用于验证非测试代码是否按照预期方式运行的。测试函数体通常要执行的操作如下： 设置任何所需的数据或状态 运行需要测试的代码 断言其结果是否为期望的 Rust 中的测试是一个带有 test 属性注解的函数。属性是 Rust 代码片段的元数据，为了将一个函数变成测试函数，需要在 fn 之前加上 #[test]。cargo test 命令执行时，Rust 会构建一个测试执行程序调用标记了 test 属性的函数，并报告测试通过与否 Rust 会编译在 API 文档中的代码示例，所以也可以进行文档测试 Doc-tests，这样可以保证稳定和代码同步 每个测试都在一个新线程中运行，当主线程发现测试异常，就将对应测试标记为失败 测试相关的宏，如果测试失败，会打印出详细的断言失败原因，便于排查： assert!: 是否为 True assert_ne!: 是否不等于 assert_eq!: 是否等于 需要注意的是，assert_ne! 和 assert_eq! 在底层使用了 == 和 !=，意味着被比较的值必须实现 PartialEq 和 Debug trait。所有的基本类型和大部分的标准类型都实现了这些 trait，对于自定义的结构体和枚举类型，通常可以在结构体上加 #[derive(PartialEq, Debug)] 注解解决 对于上述三个断言用的宏，任何其它参数都会被传入 format 宏，所以可以借助这个特性自定义错误提示 使用 #[should_panic] 属性来测试某些预期会 panic 的场景；对于希望检查 panic 的文本中是否含有指定文本的情况，可以加个 expected 参数： 123456789mod tests &#123; use super::*; #[test] #[should_panic(expected = "message to be contained")] fn should_panic_with_msg() &#123; foo_will_panic(); &#125;&#125; 测试函数可以返回 Result&lt;T, E&gt;，和断言失败直接 panic 不同，这里是通过 Result&lt;T, E&gt; 结果来判断测试结果。此外也不能在这样的测试函数上加 #[should_panic] 属性，否则提示： 1error: functions using `#[should_panic]` must return `()` cargo test 默认行为是采用并行运行测试的方式，并且会截获测试运行中的输出，阻止显示，从而方便阅读测试结果 测试常用的控制参数： 指定并行执行测试的线程数：cargo test -- --test-threads=1 测试时显示函数打印的信息：cargo test -- --nocapture，由于测试时并行的，为了方便查看输出，所以你可能需要指定使用单线程运行测试 运行指定一个或多个测试（直接指定测试函数全名或部分字符串用于匹配）：cargo test name 使用 #[ignore] 属性过滤不希望运行的测试 只运行被忽略的测试：cargo test -- --ignored 关于 cargo test 参数需要注意的点： 完整使用方式 cargo test [OPTIONS] [TESTNAME] [-- &lt;args&gt;...] -- 前的参数传递给 cargo -- 后的参数传递给二进制测试程序（test binaries），进而传递给 libtest（这个是 Rust 内建的单元测试和 micro-benchmark 框架），可以使用 cargo -- --help 了解详细参数 单元测试（unit tests） 侧重于小而集中，在隔离环境中一次测试一个模块，或者私有接口： 单元测试与要测试的代码同在 src 目录下相同的文件中 规范是在每个文件中创建包含测试函数的 tests 模块，并使用 cfg(test) 注解 集成测试（integrated tests） 则是在外部测试你的库，只测试公有接口，且每个测试可能会测试多个模块： 使用单独的 tests 目录和 src 同级别 cargo 会将每个文件当做单独的 crate 编译 tests 目录很特殊，里面的测试不需要 #[cfg(test)] 注解，并且只会在 cargo test 时编译并执行 tests 目录中的文件 cargo test --test &lt;filename&gt; 运行某个特定的集成测试文件中的所有测试 cargo test --test &lt;filename&gt; &lt;TESTNAME&gt; 运行某个集成测试文件中某个 case tests 目录中的子目录不会被当作单独的 crate 编译或作为一个测试结果部分出现在测试输出中，所以可以将一些公用的帮助函数放到子目录中实现（新增一个模块） 命令行小工具：rgrep std::env::args 在其任何参数包括无效 Unicode 时会报错。如果需要处理这种情况，可以使用 std::env::args_os，该函数返回一个 OsString，而非 String，但细节处理起来还是比较麻烦 二进制程序关注点分离基本步骤： 将程序拆分成 main.rs 和 lib.rs，并将程序的逻辑放入 lib.rs 中 当命令行解析逻辑比较小时，可以保留在 main.rs 中 当命令行解析开始变得复杂时，也同样将其从 main.rs 提取到 lib.rs 中 经过这些后，保留在 main 函数的责任应该被限制为： 使用参数值调用命令行解析逻辑 设置任何其它的配置 调用 lib.rs 中 run 函数 如果 run 返回错误，则处理这个错误 错误输出到 stderr，使用 eprint! 和 eprintln! 迭代器和闭包 Rust 的 闭包（closures） 是可以保存进变量或作为参数传递给其它函数的匿名函数。可以在一个地方创建闭包，然后在不同的上下文中执行闭包运算，闭包运行捕获调用者作用域的值 闭包不要求像 fn 函数那样在参数和返回值上注明类型，因为它不会被暴露给库的用户调用 闭包通常很短，并且只用于有限的上下文中，且编译器能可靠地推断参数和返回值类型 每个闭包实例拥有自己独有的匿名类型，即便签名相同，它们的类型依然可以被认为是不同的 所有的闭包和函数都实现了 trait Fn, FnMut 或 FnOnce 中的一个 当闭包从环境中捕获一个值，闭包会在闭包体中存储这个值以供使用 闭包获取环境的三种方式（对应参数获取的方式：所有权、可变借用和不可变借用）： FnOnce：闭包周围的作用域叫做环境，Once 表示闭包不能多次获取相同变量的所有权，也只能被调用一次。由于所有闭包都至少被调用一次，所有都实现了 FnOnce FnMut：获取可变借用值，可以改变环境。对于没有移动被捕获变量的所有权到闭包内的闭包也实现了 FnMut Fn：获取不可变借用。不需要对被捕获的变量进行可变访问的闭包实现了 Fn 1.迭代器模式允许你对一个项的序列进行某些处理，迭代器（iterator） 负责遍历序列中的每一项和决定序何时结束 迭代器是惰性的，联想下 Python 的生成器、迭代器就好了 迭代器 trait 中 type Item 和 Self::Item 定义了 trait 的关联类型 iter 方法生成一个不可变应用的迭代器；into_iter 则返回拥有所有权的迭代器；如果需要迭代可变引用，则使用 iter_mut 迭代器 是 Rust 零开销抽象之一，它意味着抽象并不会引入运行时开销 展开是一种移除循环控制代码的开销，并替换为每个迭代中的重复代码的优化 开起来 Rust 是比较推荐使用迭代器和闭包的，而且对函数编程风格更是偏爱~ Cargo 和 crates.io 文档注释使用的是 ///，并且支持 Markdown 注解 使用 cargo doc 可以生成 HTML 文档到 target/doc 中，使用 cargo doc --open 可以构建后打开文档 文档中还可以包含 Panics, Errors 和 Safety //! 在 crate 根文件（`src/lib.rs）或模块根文件提供一个概要性的介绍 使用 pub use 可以重导出，使共有结构不同于私有结构，方便用户使用（其实在 Python 中也有很多库是这么干的） 工作空间是一系列共享同样的 Cargo.lock 和输出目录的包 使用 cargo install &lt;name&gt; 可以安装来自 creates.io 的二进制文件 智能指针 指针 是一个包含内存地址的变量的通用概念。Rust 中最常见的指针是 引用，使用 &amp; 表示，除引用数据没有任何其它特殊功能，没有任何额外开销 智能指针 是一类数据结构，表现类似指针，但是拥有额外的元数据和功能 Rust 中，普通引用和智能指针的一个额外区别是 引用是一类只借用数据的指针；大部分情况，智能指针拥有它们指向的数据 智能指针通常使用结构体实现，区别于常规结构体，它实现了 Deref 和 Drop trait： Deref 运行智能指针结构体实例表现得像引用 Drop 则允许自定义当智能指针离开作用域时运行的逻辑 标准库中常用的智能指针（你也可以实现自定义的智能指针）： Box&lt;T&gt; 用于在堆上分配值 Rc&lt;T&gt; 引用计数类型，数据可以拥有多个所有者 Ref&lt;T&gt; 和 RefMut&lt;T&gt;，通过 RefCell&lt;T&gt; 访问，在运行时而非编译时执行借用规则的类型 Box 使用场景： 当有一个在编译时未知大小的类型，而又想要在需要确切大小的上下文中使用该类型时 当有大量数据且希望在确保数据不被拷贝的情况下转移所有权时 当希望拥有一个值，且只关心它的类型是否实现了特定 trait 而不是其具体类型时 递归类型 是在编译器无法知道大小的类型，也是 Box&lt;T&gt; 适用的场景 Deref 实现 Deref trait 允许重载「解引用运算符（dereference operator）*」，这样智能指针就可以被当作常规引用对待 实现了 deref 方法后，就是向编译器提供了获取任何实现了 Deref trait 类型的值，提供了解引用的能力 以 let z = Box::new(10) 为例，*z 在底层其实是 *(z.deref()) 操作 一般所有权依然要保留在智能指针结构体中，不用把所有权转移出去 解引用强制多态（deref coercions） 是 Rust 表现在函数或方法传参上的一种便利。当所涉及的类型定义了 Deref trait，Rust 会分析这些类型并使用任意多次 Deref::deref 调用获得匹配参数的类型（都发生在编译时），而且也让代码可读性更好： 123456789101112131415161718fn main() &#123; let m = MyBox::new(String::from("world")); // 正式因为「解引用强制多态」机制存在，这种传参是支持的，会自动做类型转换 // 第一次 deref 拿到 &amp;String （针对 Box 类型） // 第二次 deref 拿到 &amp;str（针对 &amp;String 类型） print_box(&amp;m); // 否则，你可能要这样写 print_box(&amp;(*m)); // 甚至这样 print_box(&amp;(*m)[..])&#125;fn print_box(s: &amp;str) &#123; println!("hello, &#123;&#125;", s);&#125; 解引用强制多态生效情况： 当 T: Deref&lt;Target=U&gt; 时，&amp;T -&gt; &amp;U 当 T: DerefMut&lt;Target=U&gt; 时，&amp;mut T -&gt; &amp;mut U 当 T: Deref&lt;Target=U&gt; 时，&amp;mut T -&gt; &amp;U Rust 可以将可变引用强制变成不可变引用（反过来不行，考虑下为什么？） Drop 当值要离开作用域时，可以为该类型实现 Drop trait，这样可以在离开时做一些自定义的清理工作：网络资源、文件或者内存空间释放等 我们不能直截了当地禁用自动 drop 功能，通常也不需要。Drop trait 存在的意义就是它会被自动处理 如果需要提前执行 drop，可以使用 std::mem::drop 函数，但不能直接调用值的 drop 方法，因为离开作用域后 Rust 会自动调用值的 drop 方法，从而导致 double free 错误 Rc 多数情况下，所有权是很清晰的。但有时候某个值却可以有多个所有者，比如图数据结构中，多条边可能指向相同的节点 Rc&lt;T&gt; 会追踪值的引用计数，保证没有引用时，才可以被清空 Rc&lt;T&gt; 用于当我们希望在堆上分配内存供多个部分读取，但又不能在编译时确定哪个部分会在最后结束使用它。 Rc&lt;T&gt; 只能用于单线程场景 Rc::new 和 Rc::clone 方法比较常用，Rc::clone 做的是浅拷贝，并且每次调用只会给引用计数加 1 Rc::strong_count 可以查看引用计数（注意还有个 Rc::weak_count，避免循环引用使用） RefCell 和内部可变模式 内部可变性（Interior mutability） 是 Rust 中的一个设计模式，允许你在有不可变引用时也能改变数据。使用 unsafe 来模糊 Rust 的常规的可变性和借用规则 RefCell&lt;T&gt; 代表其管理的数据的唯一所有权 借用规则： 在任意给定时间，只能拥有一个可变引用或任意数量的不可变引用之一 引用必须总是有效的 对于 RefCell&lt;T&gt;，不可变性作用于 运行时；如果在运行时违反借用规则，程序会 panic RefCell&lt;T&gt; 用于你确信代码遵守借用规则，但编译器这个大笨蛋不能理解和确定的时候 只能用于单线程场景 在不可变值内部改变值就是 内部可变性 模式，一个典型的应用场景是 mock 对象 测试替身（test double） 是一个通用编程概念，它代表一个在测试中替代某个类型的类型 borrow 方法返回 Ref；borrow_mut 返回 RefMut Rc&lt;T&gt; 和 RefCell&lt;T&gt; 结合，可以做到值有多个所有者并且可以被修改 循环引用 Rust 的内存安全机制使得内存泄漏更加少见，除非你刻意创建类似循环引用这种数据结构 Rc::clone 增加实例的 strong_count Rc::downgrade 创建值的 弱引用（weak ref） ，会得到 Weak&lt;T&gt; 类型的智能指针，并会将 weak_count 增加。weak_count 无需计数器为 0 就能使 Rc 实例被清理 强引用代表如何共享 Rc&lt;T&gt; 实例所有权，弱引用不代表所有权关系 Weak&lt;T&gt; 实例的 upgrade 方法返回 Option&lt;Rc&lt;T&gt;&gt;，需要检查指向的值是否被清理了 并发线程 并发编程 代表程序的不同部分相互独立执行；并行编程 代表程序不同部分同时执行 多线程环境下编程其实还是要小心点，但是不要害怕，需要的时候就大胆用 Rust 标准库使用 1:1 线程模型实现，足够底层 thread::spawn 可以启动新的线程 如果要在别的线程中使用主线程中的值，需要使用 move 关键字 消息传递 使用 消息传递 的方式在多线程中通信 Do not communicate by sharing memory; instead, share memory by communicating Rust 中实现消息传递的主要工具是 通道（channel）： 发送方：transmitter/producer 接收方：receiver/consumer 当发送方或接收方任意一个被 drop，都可以认为通道被关闭了（不像 Go 中的显式 close(chan)） mpsc::channel，这里 mpsc 全称是 多生产者，单消费者（multiple producer, single consumer） recv 是阻塞接收，try_recv 则会立即返回 可以对 receiver 进行迭代，消费 channel 中的消息（注意，这里的 channel 是带缓冲的） mpsc::Sender::clone 可以用来克隆生成多个生产者 状态共享：Mutex 与 Arc 基于 channel 的机制类似于单所有权，一旦值被发送出去，发送方将失去所有权 共享内存模式则类似多所有权，多个线程可以同时访问相同的内存地址 互斥信号量（mutex, mutual exclusion），只允许一个线程访问某些数据 Arc&lt;T&gt; 类似于 Rc&lt;T&gt;，A 表示 Atomic，即原子的。引用计数在多线程环境下是安全的，但因为需要并发原语加持，所以相对 Rc&lt;T&gt; 会存在性能损耗 Mutex&lt;T&gt; 提供了内部可变性 RefCell&lt;T&gt; 和 Mutex&lt;T&gt; 具有相似的作用 Rc&lt;T&gt; 和 Arc&lt;T&gt; 也是类似 Sync 和 Send Rust 语言本身对并发知之甚少，前面提到的只是标准库实现方案，但并发方案不受标准库或语言所限 std::marker 中 Send 与 Sync trait： Send 允许在多线程之间转移所有权 几乎所有的 Rust 类型都是可 Send 的，任何由 Send 类型组成的复合类型也是 Send 的 Sync 允许多线程访问：实现了 Sync 的类型可以安全地在多个线程中拥有其值的引用 对于任意类型 T，如果 &amp;T 是 Send 的，那么 T 就是 Sync 的 完全由 Sync 的类型组成的类型也是 Sync 的 手动实现 Send 和 Sync 是不安全的，它们是标记 trait，甚至都不需要实现任何方法，用于加强并发相关性的不可变性 Rust 面向对象特征面向对象语言特点 Design Patterns: Elements of Resuable Object-Oriented Software 中对于面向对象的定义： 12Object-oriented programs are made up of objects. An object packages both data and the procedures thatpeople on that data. The procedures are typically called methods or operations. 面向对象编程语言的共享特性：对象、封装 和多态 Rust 的结构体和 Enum 是符合对象包含数据和行为定义的；另外，通过 pub 关键字可以控制是否对外提供访问权限，对于细节可以私有化，不用对外暴露 继承：复用代码；子类型可以替代父类型被使用的地方（即多态）。继承存在的一个问题是常常会共享多于需要的代码（有这种风险） Rust 使用 trait 对象替代继承，实现多态（一种可用于多种类型代码的广泛概念） Trait Object trait 对象指向一个实现了指定 trait 的类型实例，通过指定某些指针（&amp; 或 Box&lt;T&gt; 等），接着指定相关 trait 不能向 trait 对象中增加数据，没有那么通用：具体作用是允许对通用行为进行抽象 与定义了使用 trait bound 的泛型类型参数不同的结构体不同，trait 对象允许运行时替代多种具体类型，而泛型参数则一次只能替代一个具体类型 类似动态语言中的 鸭子类型 概念，我们不需要知道组件的具体类型，只需要确定是否实现了指定的 trait 即可执行期望的操作 使用 trait 对象和 Rust 类型系统进行类似鸭子类型操作的优势是无需在 运行时 检查一个值是否实现了特定的方法或担心调用时因为值没有实现方法而产生错误 trait 对象执行动态分发（编译器会生成在运行时确定调用什么方法的代码），动态优化会导致编译器禁用一些优化 只有对象安全（object safe）的 trait 才可以组成 trait 对象。如果一个 trait 中的方法有如下属性时，则该 trait 是对象安全的： 返回值类型不是 Self 方法没有任何泛型类型参数 状态模式实现 状态模式 是一个面向对象设计模式：一个值拥有某些内部状态（体现为一系列 状态对象），同时值的行为会随着内部状态而改变。每一个状态对象代表负责自身的行为和当需要改变为另一个状态时的规则状态。持有任何一个这种状态的值不同于状态的行为及何时状态转移毫不知情 优点：易于扩展和维护 缺点： 因为需要实现状态之间的转换，产生相互联系 存在重复逻辑 模式匹配 模式可由下面的内容组合而成： 字面值 解构的数组、枚举、结构体或元组 变量 通配符 占位符 match 表达时必须是穷尽的（exhaustive） if let, else if, else if let 可以混合使用的条件表达式 while let 条件循环 for (x, y) in 循环 let 语句 如果希望忽略元组中的一个或多个值，可以使用 _ 或 .. 函数参数也可以是模式 Refutable（可反驳的）：能够匹配任何传递的可能值的模式 if let 表达式 while let 表达式 Irrefutable（不可反驳的）：对某些可能的值进行匹配会失败的模式 let 语句 函数参数 for 循环 char 和 numeric 值是 Rust 可以知道范围是否为空的类型 匹配守卫（match guard） 是一个在 match 分支后指定的额外的 if 条件，当匹配到该分支时，额外的 if 条件也必须满足才可以。匹配守卫对于表达非常复杂的匹配条件时很有帮助 Rust 高级特性（难）Unsafe Rust 可以提供 Super Power: 解引用裸指针 调用不安全的函数或方法 访问或修改可变静态变量 实现不安全的 trait：当至少有一个方法中包含编译器无法验证的变量时 trait 是不安全的 之所以需要 Unsafe Rust，是因为： 静态分析（编译器）本质上是保守的，有时候程序可能是有效的，但被拒绝编译 底层计算机硬件固有的不安全性 unsafe 并不会关闭 borrow-checker 或者禁用其它 Rust 安全检查 unsafe 不代表代码块真的很危险或者必然导致内存安全问题，真正意图是程序员会确保 unsafe block 中的代码是以有效的方式访问内存 可以为不安全的代码提供安全的抽象接口 裸指针（raw pointers） 类型：*const T 和 *mut T，区别于引用和智能指针的地方： 允许忽略借用规则，可同时拥有不可变和可变的指针，或多个指向相同位置的可变指针 不保证指向有效的内存 允许为空 不能实现任何自动清理功能 可以在安全的代码中创建裸指针，但不能直接 解引用 裸指针（必须要在 unsafe 环境下） 裸指针的一个常见的应用场景就是调用 C 接口 extern 关键字可以创建和使用 外部函数接口（Foreign Function Interface, FFI） 常量与静态变量： 静态变量的内存地址总是固定的，且生命周期为 &#39;static，使用静态变量值总会访问相同的地址 常量允许在任何被用到的时候复制其数据 静态变量是可变的，访问和修改可变静态变量都是 不安全 的 高级生命周期 涉及的主题： 生命周期子类型（lifetime subtyping）：确保某个生命周期长于另一个生命周期的方式 生命周期绑定（lifetime bounds）：用于指定泛型引用的生命周期 trait 对象生命周期（trait object lifetimes）：如何推断，何时需要绑定 匿名生命周期：省略写法 trait bound 可以帮助 Rust 验证泛型的引用不会存在的比其引用的数据更久：如 T: &#39;a&#39; &#39;_ 匿名生命周期，简化写法 高级 trait 关联类型（associated types） 是一个将类型占位符与 trait 相关联的方式，这样 trait 的方法签名中就可以使用这些占位符 为何要使用关联类型而非泛型呢： 泛型的话，每次实现 trait 都需要注明类型；支持多次实现 trait 关联类型，则只能针对一种类型实现一次，且无需注明类型 当使用泛型参数时，可以为泛型指定默认的具体类型。为泛型指定默认类型的语法是在声明泛型类型时使用：&lt;PlaceholderType=ConcreteType&gt; std::ops 中列出的运算符和 trait 可以重载 RHS 全称是 right hand side RHS=Self：默认类型参数（default parameters） Rust 不会阻止你为一个类型实现某个方法，再去实现一个或多个具有同名的 trait 方法。但是在调用时，默认会调用直接实现在类型上的方法。要想调用指定 trait 的某个方法，可以使用类似 TraitName::method(&amp;obj) 这种写法 完全限定语法消除同名关联函数歧义示例：&lt;Dog as Animal&gt;::baby_name()，完整语法： 1&lt;Type as Trait&gt;::function(receiver_if_method, next_arg, ...); 可以选择在任何函数或方法调用处使用完全限定语法 高级类型 必须将动态大小类型的值置于某种指针之后 动态大小类型 (DST，dynamically sized types)，只有在运行时才可以知道大小的类型 Sized trait，决定一个类型的大小是否在编译时可知，自动为编译器在编译时就知道大小的类型实现 Rust 隐式地位每个泛型函数增加了 Sized bound 12// 默认添加了 `Sized` 绑定fn generic&lt;T: Sized&gt; (t: T) &#123;&#125; ?Sized 可以放宽限制，但是需要使用 &amp;T，保证参数是类型是 Sized，但 T 可以不用是 Sized 的： 1fn generic&lt;T: ?Sized&gt; (t: &amp;T) &#123;&#125; 高级函数和闭包 除了可以向函数传递闭包外，还可以传递常规函数。通过函数指针允许使用函数作为另一个函数的参数 fn 叫做 函数指针（function pointer） 函数指针实现了三个闭包 trait（Fn, FnMut 和 FnOnce），总是可以在调用期望闭包的函数时传递函数指针作为参数 宏 宏（Macro） 是 Rust 中一些列的功能： 声明（Declarative）宏：使用 macro_rules! 过程（Procedural) 宏： 自定义 #[derive] 宏 类属性（Attribute）宏 类函数宏 宏是一种为其它代码而写代码的方式，即所谓的 **元编程（meta programming） 元编程对于减少大量编写和维护的代码非常有用 宏只接受一个可变参数 宏可以在编译器翻译代码前展开 宏比普通函数更加难以阅读、理解和维护 在调用宏 之前 必须定义并引入到作用域，而函数则可以在任何地方定义和调用 宏模式所匹配的是 Rust 代码结构而非值，所以和 match 模式匹配不同 过程宏更像函数（一种过程类型），接收 Rust 代码作为输入，在这些代码上进行操作，再产生另一些代码作为输出，而非像声明式宏那样匹配模式，再用另外一部分代码替换当前代码 #[derive(xx)] 属性可以生成代码 类属性宏则允许创建新的属性 #[some_attribute] derive 只能用于结构体和枚举；属性则可以用于其它的项，如函数 类函数宏定义看起来像函数调用的宏，如 let sql = sql!(SELECT * FROM users) 参考 The Rust Book Rust 程序设计语言 self, Self in Rust Paradigms of Rust for the Go developer]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Rust</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《架构整洁之道》学习笔记之介绍]]></title>
    <url>%2F2018%2F12%2F22%2Fclean-arch-notes-intro%2F</url>
    <content type="text"><![CDATA[引言近来开始阅读 Robert C. Martin 的新著《架构整洁之道》（Clean Architecture）。没有人愿意看到团队内的项目逐渐发展成一团乱麻，相互纠缠。那如何从根本上减少这种问题的发生呢？这就需要我们掌握一些宏观层面的设计思想，从给项目打基础时就应该考虑好各个模块、类、函数等如何设计成高内聚、低耦合的结构。整洁的项目架构是利于长远发展的，这篇笔记将会记录一些从书中学习到的重要知识点，便于后期复习和参考。 当然，作者还有一本大名鼎鼎的著作《代码整洁之道》也非常值得阅读，关于这本书也做了点笔记，参见《代码整洁之道》读书笔记~ 要点记录什么是设计和架构 计算机代码这么多年没有发生本质的变化，导致软件架构的规则保持了一致。软件架构的规则其实就是排列组合代码块的规则 让一个程序可以工作非常容易（小孩子都能做到），但让它正确地工作则是另外一回事。而让软件正确工作则更加困难，因为这需要开发人员有独到的思想和远见，掌握一定的设计规则 在软件设计中，底层的细节和上层的结构是一个整体，不可分割 软件架构的目标是最小化构建和维护系统所需要的人力资源 不要总是寄希望于以后来解决技术债务，因为你会发现以后总是很遥远 事实是 making messes is always slower than staying clean 走得快的唯一办法，是先走好（The only way to go fast, is to go well） 价值对比：表现 vs 结构（架构）(Behavior and Structure） 任何软件系统都会在两个方面产生价值：Behavior 和 Structure 表现（Behavior）：软件被开发用来让计算机按照预期的方式工作并产生价值，或者为人们解约开支 架构（Architecture）： 软件应该易于更变其行为表现（灵活、可扩展） 如果大部分需求变更只是局部变化，而不是影响到整体架构「外形（shape）」的话，那应该没什么难度，但如果架构本身无法满足需求实现，则会带来很大的开发成本 架构本身如果只局限于某种「外形（shape）」（或者更偏向于），那新增功能可能会越来越复杂。所以说，架构本身不要把自己限制死，应该是能灵活应对变化频繁的需求的。更为实际的架构应该是对「外形」无感知的（更强的包容性） 作为软件工程师，我们不能一味地满足产品经理们各种功能堆积，而忽略了软件质量，也同样要让软件架构变得更灵活 Dwight D. Eisenhower: “I have two kinds of problems, the urgent and the important. The urgent are not important, and the important are never urgent” 我们可以根据重要性和紧急性对任务做如下分类： 紧急 + 重要（比如出现了影响用户的大 Bug） 不紧急 + 重要（架构、工程质量、代码重构） 紧急 + 不重要（需求通常比较紧急，但并不总是非常重要的） 不紧急 + 不重要 很多情况下，项目经理会误判优先级，把「紧急 + 不重要」的任务认为是优先级最高的，这样就导致开发人员忽略了软件架构，让系统变得越来越脆弱 开发人员的职责就是要确定架构和所谓的紧急需求哪个是真的更重要的 作为开发团队的一员，守护你的项目质量是你的职责所在；而作为架构师，更需要重点关注系统结构而非各种特性和功能，良好的架构应该允许各种特性和功能易于添加，修改和扩展 小结正所谓「理想很丰满，现实很骨感」，现实开发中如果想要保证快速迭代的同时，尽可能不破坏项目结构，虽然有点困难，但并非做不到。首先项目本身在最初设计时就应该是为方便扩展考虑的（如模块化、编写风格等）；其次，团队的成员应该是要有较强的责任心来保护这种良好的设计，这样在扩展新功能时就会更加顺利。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>架构</tag>
        <tag>设计思维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go Web 工程实践总结]]></title>
    <url>%2F2018%2F12%2F16%2Fgolang-web-dev-practice-summary%2F</url>
    <content type="text"><![CDATA[引言早期我们在一些小的 Web 项目中使用了 Go 来开发简单的 REST API，主要参考的是其它部门的核心项目。但当时只是为了尝鲜和入门 Go Web 开发，并没有花较多的时间考虑工程结构、项目质量这些至关重要的问题。 再后来，组内陆续多个项目使用了 Go 语言开发。整体来说，项目结构上大体是相同的，但是在工程实践上还是有不太统一的地方。我们希望新的项目能够在项目结构、工程质量上有所改善，提高工程稳定性与开发幸福感是需要我们共同努力的目标。 后来找到机会从一个大的项目中拆出可以完全独立的服务，这次并没有完全照搬其它 Go 项目的工程实践。很多时候，所谓的最佳实践是需要权衡各种利弊得来的。在这次实践中，我们着重于改善如下几个方面： 项目结构：层次结构调整、包命名风格统一 统一 Model 层接口：通过一个类似 GORM 的工具实现 可能更加优雅的 REST API 写法：基于 chi 框架做了一层封装；路由注册尽可能统一到一个文件，集中管理 API Schema 数据聚合：实现了一个类似我们在 Python 项目中使用的 marshmallow 库解决 单元测试：运行时 Patch，不需要在写 Handler/Controller/RPC 时都以 interface 优先的方式 返回 Error 而不是 Panic 掉 项目结构1234567891011121314151617181920212223242526272829303132333435363738394041424344454647.├── Gopkg.lock（Dep 包管理工具自动生成、维护）├── Gopkg.toml（依赖包管理）├── Makefile├── README.md（项目文档）├── bin（二进制可执行文件，可以直接运行的服务：RPC 和 HTTP 服务等）├── cmd│ ├── service（对外提供的 RPC 服务入口）│ │ └── main.go│ └── web（对外提供的 HTTP API 服务入口）│ └── main.go├── gen-go（基于 thrift 编译生成的文件，在实现对外提供的 RPC 服务接口时需要使用）├── joker.yml├── pkg（核心代码放到这个目录下）│ ├── configs（资源配置：MySQL, Redis 等）│ │ ├── mysql.go│ │ ├── redis.go│ ├── consts（常量定义，包括枚举）│ │ ├── enum.go│ │ └── macro.go│ ├── controllers（复杂的业务逻辑放到这儿实现）│ │ ├── foo.go│ ├── errs（业务自定义错误类型）│ ├── middlewares（业务相关的中间件，如果可以复用，就抽到公共仓库维护）│ ├── models（顾名思义，定义 Model，关联数据库表）│ ├── rpcs（依赖的第三方 RPC 服务）│ │ ├── bar.go│ ├── service（对外提供的 RPC 服务实现）│ │ ├── demo-service.go│ │ └── protos│ │ └── demo-service.thrift│ ├── utils（可复用的工具：单元测试等）│ └── web（REST API 服务）│ ├── handlers│ ├── routers│ │ ├── router.go（路由注册）│ │ └── urls.go（URL 与 Handler 的绑定）│ ├── schemas│ │ ├── dump（聚合数据源，定义对外的 API Schema）│ │ └── load（处理输入，字段校验规则配置）│ └── validators（可复用的自定义校验规则定义）├── scripts（脚本）├── testdata（业务逻辑测试需要用的测试数据）│ ├── fixtures（造一些测试数据放在里面，默认使用 YAML 格式）│ │ ├── foo.yml│ └── schema.sql（数据库表创建语句集合）└── vendor（各种依赖包） MVC 怎么实践Model关于 Model 层怎么写，这个看起来还是有点争议。之前去听了其它部门 Go 实践经验分享，提倡半手写 SQL（本质上使用了 SQL 构建器）的方式。但这么做感觉还是存在很多问题（主要是考虑到后期维护者的感受）： 接口复用性不够好 写法难以统一，且代码量容易膨胀 手工组装 SQL 比较繁琐，且不易于后期变更（如新增字段） 重复逻辑不可避免 应用层更应该关注的是核心业务逻辑，而非繁琐重复的代码编写（Keep It Simple）。参照我们在 Python 中的实践，采用了轻量级的 ORM 工具后很大程度上统一了增删改查接口，这样每个维护者都不用烦心了解各种类似 get_xxx_by_wtf_balabala 函数了。因为加了一层抽象，可被复用的逻辑完全从我们的业务层抽离出去维护，也可以大大简化应用层代码。 对于常规业务，如果我们能够接受一定的性能开销，不妨引入一些工具，来改善项目质量并且提高开发效率。 为了方便我们在自己的 Go 项目中，能够使用较为一致的方式实现常规的增删改查需求，所以就花了些时间造了个类似 GORM 的工具 BORM。在经历多次迭代后，目前基本趋于稳定。目前我们已经在多个内部项目中使用，并在实践中修复了不少细节问题，增加了一些非常实用的功能。 以下是该工具提供的一些常用接口： 接口 注释 Create/MustCreate 新建记录 Save/MustSave 全量更新 Update/MustUpdate 更新指定单个字段 Updates/MustUpdates 更新指定多个字段 Delete/MustDelete 删除记录 One/MustOne 根据条件匹配一条记录 All/MustAll 匹配所有符合条件的记录 FindByPK/MustFindByPK 基于主键查询记录 Begin/Commit/Rollback 事务相关接口 总的来说，希望 BORM 能够解决以下几个问题： 统一且清晰的增删改查接口 SQL 自动组装，无需人肉拼接 基于 Model 层的缓存管理统一到工具层解决 引入 BORM如果需要在项目中引入 BORM，可以采用类似下面的目录结构： 123pkg/models├── init.go└── material.go 在 init.go 中，配置 BORM 的数据库连接（或者添加缓存支持）： 1234567891011121314151617package modelsimport ( "url/to/borm" "project/pkg/configs")func init() &#123; mysqlConfig := configs.GetMySQLConfig("demo") borm.Setup(borm.NewMySQLConfig( mysqlConfig.Masters[0], mysqlConfig.Slaves, )) // 如果需要的话，可以添加 Model 缓存支持 // borm.Use(cache.New(configs.GetRedisConfig("cache-redis"), false))&#125; 编写 Model接下来，表演下如何编写 Model，以及如何给 Model 以「属性」的方式关联资源（类似于我们在 Python 中使用 property 获取某个 Model 关联的资源）等： 12345678910111213141516171819202122232425262728293031323334// MaterialModel 是广告素材资源type MaterialModel struct &#123; // 对于 BORM 而言，默认会使用名叫 `id` 的字段作为主键（注意，这里的大写字段名在生成 SQL 时会自动变成小写模式） // 假如你需要指定某个字段为主键，可以另加 tag `borm:pk` ID int64 Category string // 可以看到，这里使用了一个自定义的类型（实际数据库是 tinyint，BORM 会根据自定义类型实现的接口完成自动映射） // 另外，使用 `column:type` 表示可以让 Model 的对外暴露的字段名和数据库实际字段名不同 Kind consts.TemplateKind `borm:"column:type"` // 这里的 AdScale 在数据实际上是个 JSON 字符串，但由于 *AdScale 类型实现了 BORM // 指定的接口，便能实现自动反序列化，这样你不需要在上层左一个又一个 `json.Unmarshal` 操作 AdScale *AdScale `borm:"column:adscale" portal:"nested"` // 由于默认的自动转换字段名的策略会将 LandURL 转换成 land_url，与实际数据库字段名不符 // 这里依然用 `column:landurl` 自定义字段名 LandURL string `borm:"column:landurl"` DeepLinkURL string `borm:"column:deeplinkurl"` // 之所以不能直接用 bool 类型，是因为数据库是 tinyint // borm.Bool 实现了指定接口，所以可以实现自动映射 IsDeleted borm.Bool // 这里使用了 `readonly` 表明我们不用关心这个时间戳的更新，交给数据库自动更新即可 CreatedAt time.Time `borm:"readonly"` UpdatedAt time.Time `borm:"readonly"`&#125;// TableName 告诉 BORM 查哪张表func (m *MaterialModel) TableName() string &#123; return "material"&#125; 下面表演下如何通过实现特定接口完成数据库的 JSON 字符串与自定义结构体类型之间的转换的。通过把这种低级别的转换操作放在 Model 层完成，可以让业务上层写起来更爽！ 12345678910111213141516171819202122232425262728293031323334353637type AdScale struct &#123; Width int `json:"width"` Height int `json:"height"`&#125;func NewAdScale(w, h int) *AdScale &#123; return &amp;AdScale&#123;w, h&#125;&#125;// Value 接口会在写入数据库时调用，在实现该接口// 时调用了 json.Marshal 转换成了 JSON 字符串// 这样在业务层就可以快快乐乐使用 AdScale 结构体// 如果需要存储，BORM 会自动获取这里序列化后的结果// 换成 YAML 都不是梦，上层对此无感知！func (a *AdScale) Value() (interface&#123;&#125;, error) &#123; result, err := json.Marshal(a) if err != nil &#123; return nil, err &#125; return string(result), nil&#125;// SetValue 会在读取数据时调用，当处理到该类型时，// 通过 `json.Unmarshal` 自动反序列化成 AdScale 类型了// 对于上层来说依然是透明的func (a *AdScale) SetValue(v interface&#123;&#125;) error &#123; jsonBody, ok := v.([]byte) if !ok &#123; return errors.New("models.material: expect []byte type") &#125; if len(jsonBody) != 0 &#123; return json.Unmarshal(jsonBody, &amp;a) &#125; else &#123; return nil &#125;&#125; 对了，还有资源的关联呢？在 Python 中我们可以用属性的方式实现，在 Go 中依然可以实现类似的功能，只是写法不太相同而已： 12345678910// Attributes 是广告素材关联的一组自定义「属性」// 这里就涉及到对另一张关联表的查询func (m *MaterialModel) Attributes(ctx context.Context) []*AttributeModel &#123; var results []*AttributeModel err := borm.New().Filter("material_id", m.ID).OrderBy("created_at").All(ctx, &amp;results) if err != nil &#123; log.Errorf("models.material: failed to get attributes of material '%d': %s", m.ID, err) &#125; return results&#125; 当然啦，如果有资源关联的属性值来自 RPC，也可以放在 Model 层编写一个类似上面的属性。我们希望能够在 Model 层绑定资源的关联数据，这样在业务上层只需要 .Foo() 即可获取关联资源。 注意到，上面的「属性」函数接收了一个 ctx 参数，那是因为在进行数据库查询或者 RPC 服务调用时需要。但有时候我们的「属性」函数并不需要 ctx 参数，比如下面这样这样： 12345// IsInPromotion 是否在促销中func (m *Model) IsInPromotion() bool &#123; now := time.Now().Unix() return now &gt;= m.PromotionStartsAt &amp;&amp; now &lt; m.PromotionEndsAt&#125; Controller其它项目的写法我们先来看下其它项目中是如何编写 Controller 层的。首先看下目录结构： 1234567controller├── user.go├── impl│ ├── user.go│ └── user_test.go└── mock └── user.go 其中在 controller/user.go 中定义了该 Controller 的接口，而在 mock 目录下的文件则是由 mock 工具生成的文件。而在 impl 放置的是真正的实现逻辑，写法如下： 123456789101112131415161718192021type UserControllerImpl struct &#123; userDao dao.UserDao&#125;var _ controller.UserController = (*UserControllerImpl)(nil)var DefaultUserController *UserControllerImplfunc init() &#123; DefaultUserController = NewUserController()&#125;func NewUserController() *UserControllerImpl &#123; return &amp;UserControllerImpl&#123; userDao: daoImpl.DefaultUserDao, &#125;&#125;func (c *UserControllerImpl) GetBar(ctx context.Context, uid int64) int64 &#123; return c.userDao.GetBar(ctx, uid)&#125; 之所以采用这样的目录结构和实现方法，可能也是为了方便编写单元测试时 Mock 掉关键接口。但通过分析这些代码，也发现了几个问题： Controller 层好像也没干啥，调用了 Dao 层的接口？ 不太符合 Go 圣经中所倡导的方式，接口写太多了 每个 Controller 都必须写一个结构体？ 但是为了满足 mock 工具苛刻的生成条件（总是基于 interface 生成），也不得不那样实现。但我们在实践中，有个单元测试需要去 Mock time.Now() 函数。这时就遇到了问题，虽然可以基于 time 再定义一个结构体来，再定义下接口，让 mock 工具生成 Mock 版本。但是这样感觉还是比较繁琐，且容易让代码膨胀。明明就是要解决一个看起来并不复杂的问题，却要因为单元测试引入那么多啰嗦的代码。其实我们并不希望因为单元测试而造成业务代码以某种妥协的方式实现。在经过一番调研和实践后，我们发现运行时 Mock 也是能够做到的（细节会在讲单元测试时说明），自然也就不必写得如此啰嗦~ 我们的做法对于比较复杂的业务逻辑，我们依然推荐你在 Controller 层去实现，但是不用教条式地定义一个结构体，再定义一个方法。基本原则就是，能有简单清晰明了的写法即可。比如下面这个例子： 123456789101112131415161718192021// UpdateMaterial 做一次全量更新吧func UpdateMaterial(ctx context.Context, materialID int64, schema *MaterialSchema) (err error) &#123; material, err := GetMaterial(ctx, materialID) if err != nil &#123; return &#125; tx := borm.New().Begin(ctx) // 素材更新，这里分为两块 err = updateMaterial(ctx, tx, material, schema) // 然后是素材的属性更新（但由于是全量，为了方便，会删除先前的属性，然后替换成新的） err = updateMaterialAttributes(ctx, tx, material, schema) if err != nil &#123; tx.Rollback(ctx) &#125; else &#123; tx.Commit(ctx) &#125; return nil&#125; ViewHandler为了方便编写 REST API，实现了一个基于 go-chi 的轻量级 API 框架，其原型可以参考 REST 项目。 REST 工具提供了如下特性： 能够以更加优雅简洁的方式基于一个 ResourceHandler 编写 GET/POST/PATCH/DELETE 等方法 采用 return resp, err 模式替代原先 RenderJSON/RenderError 的方式： 框架层可以自动去匹配调用 renderJSON 或者 renderError 再也不怕原先调用 RenderError 后又忘记 return 的问题了 可以更好的支持返回错误，意味着我们不用到处 panic 业务错误，然后在上层又 recover 封装了一些常用的接口： 通用的分页 Schema 渲染 各种易用的参数获取接口 接下来，看看一个典型的 REST API Handler 实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103type MaterialsHandler struct &#123; rest.BaseHandler&#125;// Get 获取素材列表页func (hd *MaterialsHandler) Get() (rest.Response, error) &#123; ctx := hd.R.Context() output, err := controllers.ListMaterials( ctx, hd.OffsetInt64(), hd.LimitInt64(), hd.QueryArgumentWithFallback("order_by", "-created_at")) if err != nil &#123; return nil, err &#125; var schemas []dump.MaterialSchema return rest.Pagination&#123; Context: ctx, Data: output.Materials, ToSchemaPtr: &amp;schemas, IsAdmin: true, Total: int(output.Total), &#125;, nil&#125;// Post 新建广告素材func (hd *MaterialsHandler) Post() (rest.Response, error) &#123; var materialSchema load.MaterialSchema err := JSONArgs(hd.R, &amp;materialSchema) if err != nil &#123; return nil, err &#125; err = controllers.CreateMaterial(hd.R.Context(), &amp;materialSchema) if err != nil &#123; return nil, err &#125; return map[string]bool&#123;"success": true&#125;, nil&#125;type MaterialHandler struct &#123; rest.BaseHandler&#125;// Get 获取某个广告素材详情func (hd *MaterialHandler) Get() (rest.Response, error) &#123; id, err := hd.getMaterialID() if err != nil &#123; return nil, err &#125; material, err := controllers.GetMaterial(hd.R.Context(), id) if err != nil &#123; return nil, err &#125; var schema dump.MaterialSchema err = portal.New().Dump(hd.R.Context(), material, &amp;schema) if err != nil &#123; log.Errorf("handlers.material.get: failed to dump material: %s", err) &#125; return schema, nil&#125;// Put 更新素材信息func (hd *MaterialHandler) Put() (rest.Response, error) &#123; // 参数处理 materialID, err := hd.getMaterialID() if err != nil &#123; return nil, err &#125; var materialSchema load.MaterialSchema err = JSONArgs(hd.R, &amp;materialSchema) if err != nil &#123; return nil, err &#125; // 更新逻辑交给 controller 完成 err = controllers.UpdateMaterial(hd.R.Context(), materialID, &amp;materialSchema) if err != nil &#123; return nil, err &#125; return map[string]bool&#123;"success": true&#125;, nil&#125;// Delete 删除指定素材func (hd *MaterialHandler) Delete() (rest.Response, error) &#123; id, err := hd.getMaterialID() if err != nil &#123; return nil, err &#125; err = controllers.DeleteMaterial(hd.R.Context(), id) if err != nil &#123; return nil, err &#125; return map[string]bool&#123;"success": true&#125;, nil&#125; SchemaPORTAL 目前已经开源：https://github.com/ifaceless/portal，以下说明已经过时，可以参考 这篇文章 的介绍了解更多特性！ 我们通常会在 Schema 层定义接口需要的字段及其类型，并在这层完成数据聚合后，生成 JSON 格式的内容吐给前端使用。由于感受到 marshamllow 引入后给我们的 Python 项目带来了诸多好处后（如更加一致清晰的 Schema 定义方式），就斗胆实现了一个 Go 版本的 marshmallow 工具 PORTAL。但 PORTAL 实际上只是注重数据的聚合，因为 Go 社区已经有很多成熟的工具可以实现 Schema Struct 校验了，自然不用重复造轮子。 PORTAL 的主要特点如下： Schema 支持组合，提高 Schema 复用性 Schema 字段值支持灵活的取值方式（联想 marshamallow 中常用的方式） 支持并发填充字段（如不同的字段值可能来源于 RPC/数据库等） 字段支持灵活的类型定义，PORTAL 负责尝试类型转换 支持可选字段渲染（赋值） 尽可能减少冗余且愚蠢且不应该让人类来写的代码（机械式赋值）（脑补下给一个 Schema 的嵌套 List Schema 填充值要写得多么壮观，那如果再嵌套比较深呢？）！ 接下来我们看看如何定义用于聚合数据的 Schema： 12345678910111213141516171819202122232425// TrackSchema 音频信息type TrackSchema struct &#123; ID string `json:"id"` Title string `json:"title"` // 这里我们对外的字段名实际是 audio，但对应取值来源 Model 的 AudioURL Audio string `json:"audio,omitempty" portal:"attr:AudioURL"` AudioDuration int `json:"audio_duration" portal:"attr:Duration"` // 这里我们可以使用自定义的方法取值 PlayedAt int `json:"played_at" portal:"meth:GetPlayedAt"` Description string `json:"description,omitempty" portal:"attr:Description.Description"`&#125;// GetPlayedAt 返回用户播放的进度func (*TrackSchema) GetPlayedAt(ctx context.Context, track interface&#123;&#125;) int &#123; return 90&#125;// SpeakerSchema 主讲人信息type SpeakerSchema struct &#123; // 嵌套一个可复用的 MemberSchema UserSchema // 额外信息 Role string `json:"role"`&#125; 接下来表演下如何使用类似上面定义的 Schema： 123456789// 从 DB 查询得到 Model 示例var track models.Trackborm.New().FindByPK(ctx, &amp;track, pk)// 调用 Dump 即可完成 Schema 字段数据填充var trackSchema dump.TrackSchemaportal.New().Dump(ctx, &amp;track, &amp;trackSchema)// 接下来将 trackSchema 序列化成 JSON 返回即可 当然，虽然引入 PORTAL 可以让我们更加聚焦业务逻辑的编写，尽可能减少冗余且机械的代码，但也由此带来了一些问题： 使用 reflect 机制带来的性能损耗就看能不能接受 有些因为类型转换的不成功的问题可能到运行时才会发现，排查较困难（但出现情况很少） 所以，这还是一个需要权衡的利弊后才能考虑的方案，但个人觉得它还是有一定价值的~ 聊聊路由注册说到路由注册，个人觉得其它部门的 Go 项目采用的方式并不是很优雅，且相对比较分散。所以，就给 REST 工具引入了类似我们在使用 Tornado 时采用的那种路由注册方式。因为是基于 chi.Mux 封装的 Router，所以完全兼容原先的接口。 对于比较简单的路由，可以采用下面的注册方式： 1r.MountHandler("/hello", &amp;hello.DemoHandler&#123;&#125;) 而对于 API 较多的那种项目，推荐的目录结构如下： 123routers├── router.go└── urls.go 在 router.go 中编写 Router 初始化的代码，包括中间件配置和路由注册： 12345678910// NewRouter web 路由实例创建func NewRouter() Router &#123; r := rest.NewRouter() // 注册各种需要的中间件 r.Use(FooMiddleware) r.MountHandlers(handlers) return r&#125; 接下来在 urls.go 中定义 URL 和 Handler 的映射： 1234var handlers = map[string]rest.Handler&#123; "/tasks": &amp;task.TasksHandler&#123;&#125;, "/tasks/&#123;id:(\\d+)&#125;": &amp;task.TaskHandler&#123;&#125;,&#125; 单元测试很重要先说结论，我们使用了 gomonkey 实现运行时 Monkey Patch。这样我们的 Controller/Handler/RPC 等层无需写得特别啰嗦。 如果想知道其工作原理的话，可以参考 monkey 项目和 Monkey Patching in Go。当然，下面几篇和单元测试有关的文章也可以看看： GoConvey框架使用指南 Monkey 框架使用指南 GoStub 框架使用指南 GoMock 框架使用指南 gomonkey 1.0 正式发布！ 此外，还有个用于初始化测试数据的工具也很有帮助，详细可以参见 Fixture 项目。 Panic 还是直接返回 Error对于业务异常来说，相对系统级错误等严重错误发生地更加频繁，这样一来频繁地 Panic/Recover 会带来一些额外开销。此外，无脑地对任何业务异常都采取 Panic 的式方，真的好吗？不过看起来其它组的项目的确很乐意采用这种方式。 但个人推荐的方式是对于业务错误，依然采用 Go 中典型的方式：返回错误！如果是比较严重的错误（如网络中断等），则可以进行 Panic，然后在上层捕获。 12345678910111213// DeleteMaterial 删除素材func DeleteMaterial(ctx context.Context, materialID int64) error &#123; material, err := GetMaterial(ctx, materialID) if err != nil &#123; return err &#125; err = borm.New().Model(&amp;material).Update(ctx, "is_deleted", true) if err != nil &#123; log.Errorf("controllers.material.DeleteMaterial: failed to update: %s", err) &#125; return err&#125; 枚举定义我们一般定义完枚举后，都希望能够根据给定的值获得对应的枚举变量，或者得到枚举变量名映射的名称。这里给出一种可行的定义方式： 1234567891011121314151617181920212223242526272829303132333435363738394041// AuditStatus 审核状态type AuditStatus int// 定义三种审核状态const ( AuditAwaiting AuditStatus = iota AuditPassed AuditRefused)// auditStatusNames 定义每种枚举状态对应的名称var auditStatusNames = []string&#123; "awaiting", "passed", "refused",&#125;func (s AuditStatus) String() string &#123; return auditStatusNames[s]&#125;// AuditStatusByName 可以根据名称映射得到枚举变量func AuditStatusByName(name string) AuditStatus &#123; for i, v := range auditStatusNames &#123; if v == name &#123; return AuditStatus(i) &#125; &#125; panic(fmt.Sprintf("audit status name not found: '%s'", name))&#125;// Value 实现的是 BORM 指定的接口，完成和数据库类型（tinyint）映射（写入）func (s *AuditStatus) Value() (interface&#123;&#125;, error) &#123; return int(*s), nil&#125;// SetValue 实现的是 BORM 指定的接口，完成和数据库类型（tinyint）映射（读取）func (s *AuditStatus) SetValue(v interface&#123;&#125;) error &#123; *s = AuditStatus(cast.ToInt(v)) return nil&#125;]]></content>
      <categories>
        <category>Web 开发</category>
      </categories>
      <tags>
        <tag>Go</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go 语言编写 RESTful API 的一些思考]]></title>
    <url>%2F2018%2F12%2F02%2Fthoughts-about-writing-restful-api-in-go%2F</url>
    <content type="text"><![CDATA[引言近来实践了下 Go Web 开发，也一并做了些 Web 开发相关的效率工具，目的也是为了提升开发体验，进而改善项目质量和提高开发效率。 之前在使用 Python 做 Web 项目时，比较习惯基于类的方式为某个资源提供 RESTful 接口。和采用纯函数的方式不同，基于类的方式可以使得资源管理更清晰，当逻辑代码较多时，代码结构也不至于太混乱。 所以在使用 Go 语言实践时，我们会采用类似 ResourceHandler 的结构体的方式来替代类，并给该结构体绑定相应的 GET/POST/DELETE/PUT/PATCH 方法，用以和 HTTP 相应的请求方法匹配。 遇到的问题我们使用的 Web 框架是基于 go-chi/chi 封装的，这个框架本身的特点就是简单，与 Go 标准库 http 无缝衔接。主要用它来做路由分发，方便编写 HTTP API。 但在实践中，路由注册那块感觉很繁琐。比如，我们先前的写法大致是下面这样的： 1234567r := chi.NewRouter()hd := NewTasksHandler()r.Get("/tasks/&#123;task_id:(\\d+)&#125;", hd.Get)r.Post("/tasks/&#123;task_id:(\\d+)&#125;", hd.Post)r.Delete("/tasks/&#123;task_id:(\\d+)", hd.Delete&#125; 显然，上面的写法有点啰嗦，且容易出错。比如在单元测试中，我们就可能会因为疏忽大意，给 test server 绑定的路由和实际的不同（别问我怎么知道的）。所以就希望能有一种简单的方式注册路由，并且让程序自己根据请求的 Method 分发到 Handler 对应的方法上。 既然遇到问题，那就得想个优雅的方法解决，尽可能保证性能损耗不大，但又能带来较好的开发体验。于是乎，rest 包诞生了。 说说 REST 包rest 包的实现很简单，就是对 go-chi/chi 框架做了简单的包装，实现了一个自定义的 BaseHandler 实现请求分发到所谓的「子类」结构体对应的方法进行处理。由于并不会进行类型断言或者使用反射，所以带来的性能开销不会很高。 那么，在有了 rest 包后，我们如何使用它呢？ 使用示例假如我们要编写一个任务管理服务，需要提供的接口如下： 功能 方法 URL 示例 获取任务列表 GET /tasks 新建任务 POST /tasks 获取单个任务 GET /tasks/1 删除单个任务 DELETE /tasks/1 在 rest 的助攻下，我们可以这样来写： 123456789101112131415161718192021222324252627282930func main() &#123; r := rest.NewRouter() r.MountHandler("/tasks", &amp;TasksHandler&#123;&#125;) r.MountHandler("/tasks/&#123;task_id:(\\d+)&#125;", &amp;TaskHandler&#123;&#125;) rest.Run(r, 8000)&#125;type TasksHandler struct &#123; rest.BaseHandler&#125;func (hd *TasksHandler) Get() &#123; hd.RenderJSON(map[string]string&#123;"message": "Get Tasks"&#125;)&#125;func (hd *TasksHandler) Post() &#123; hd.RenderJSON(map[string]string&#123;"message": "Create Task"&#125;)&#125;type TaskHandler struct &#123; rest.BaseHandler&#125;func (hd *TaskHandler) Get() &#123; hd.RenderJSON(map[string]string&#123;"message": "GET Task"&#125;)&#125;func (hd *TaskHandler) Delete() &#123; hd.RenderJSON(map[string]string&#123;"message": "Delete Task"&#125;)&#125; 项目结构这个项目结构仅供参考，也没啥特别的： 123456789101112131415161718192021222324252627282930.├── Gopkg.lock (dep 包管理使用，锁定版本)├── Gopkg.toml (dep 包管理使用)├── Makefile (一些环境准备命令等)├── README.md (项目简介)├── bin│ ├── web (Web 服务二进制程序，单个文件即可运行)├── cmd│ └── web (Web 服务的入口)│ └── main.go├── pkg│ ├── configs (项目资源配置，通过资源发现获取)│ ├── consts│ │ ├── enum.go (定义一些枚举类型)│ │ └── macro.go (定义一些常量)│ ├── controllers (核心的业务逻辑)│ ├── errs (业务错误定义，放在一块维护)│ ├── middlewares (业务自定义中间件)│ ├── models (顾名思义，ORM Model 层)│ ├── rpcs (依赖的第三方服务)│ ├── utils (常用的小工具)│ └── web│ ├── handlers (处理请求的 handlers 实现)│ ├── schemas (定义聚合数据的 API Schema)│ └── router.go (路由注册)├── scripts (一些脚本)├── testdata (放单元测试需要的 Mock 数据)│ ├── fixtures (测试数据，用于导入测试库)│ │ └── foo.yml└── vendor (一些第三方依赖包，因为有墙😭，所以得存下来避免部署时因为网络等太久) 总结怎么样，新的路由注册方式是不是更加简单了？其实这正是借鉴了 Python Tornado 的一些思想。我不认为这种做法是所谓的反模式，或者不符合 Go 的风格（欢迎来喷）。其实这压根和语言无关，为什么不愿意去实践一些能够改善开发体验的新方法呢？况且还能够减少犯错！]]></content>
      <categories>
        <category>Web 开发</category>
      </categories>
      <tags>
        <tag>Go</tag>
        <tag>RESTful</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TiDB 学习笔记（二）]]></title>
    <url>%2F2018%2F12%2F02%2Ftidb-academy-learning-notes-part-two%2F</url>
    <content type="text"><![CDATA[引言TiDB Academy 提供了 TiDB 的视频学习资源，方便了解这个全新的数据库。在学习过程中，做了这个系列的笔记，方便后期回顾。 TiDB 平台 虽说 TiDB 在上层实现了 MySQL 协议，但并不代表它们使用的是相同的源码。之所叫做 TiDB 平台，是因为它是由三个核心部分构成： TiKV: 兼容 ACID 的存储层 支持分布式 Key Value 存储 支持横向扩展、原生多副本机制保证高可用 自动基于范围分区，每个范围都称为一个 Region。Region 会根据需要自动调整，默认最大为 96MB 每个 Region 默认有三分拷贝，使用 Raft 保证一致性 当然，实际上 TiKV 也可以独立部署，并直接使用它的 KV API 访问数据 TiDB: 支持 MySQL 协议，自动转换成分布式请求到 TiKV 无状态、不存储数据 易于水平扩展，高可用 类似一个 Translator，但是这里面的协同处理很有意思 Placement Driver (PD): 集群管理器，就是整个平台的大脑 管理 TiKV Region 负载均衡（比如热点检查、Region 合并） 元数据管理（如 SQL DDL） 时间同步（分布式事务中很关键的一点就是准确的时间） 可选组件：TiSpark: 越过 SQL 层，让 Apache Spark 直接与 TiKV 连接 方便执行复杂的 OLAP 查询、机器学习任务 从 TiDB 平台这种组件化的架构设计可以看到，你可以直接通过不同的方式（Spark、MySQL 协议、Key-Value API 等）访问同样的数据（位于 TiKV 中），而无需走传统的 ETL (Extract-Transform-Load) 那套。 有了 TiDB 平台，就可以同时支持 OLAP 和 OLTP 场景了（传说中的混合模式 HATP）。这样，原先我们用 MySQL 应付 OLTP 场景，用 Hadoop, HBase 或者 Cassandra 等应付 OLAP 场景，都可以在 TiDB 这一个平台完成，从而简化设计和维护工作（真的吗？）。 KOST 技术栈KOST 是指：Kubernetes, Operator, Spark 和 TiDB。K8S 可以帮助我们一步到位搞定 TiDB 平台部署。 在 GKE 上部署 TiDB直接看这个部署教程。 一些提示： 1234567891011121314151. Watch tidb-cluster up and running watch kubectl get pods --namespace tidb -l app.kubernetes.io/instance=tidb -o wide2. List services in the tidb-cluster kubectl get services --namespace tidb -l app.kubernetes.io/instance=tidb3. Wait until tidb-initializer pod becomes completed watch kubectl get po --namespace tidb -l app.kubernetes.io/component=tidb-initializer4. Get the TiDB password PASSWORD=$(kubectl get secret -n tidb demo-tidb -o jsonpath="&#123;.data.password&#125;" | base64 -d | awk '&#123;print $6&#125;') echo $&#123;PASSWORD&#125;5. Access tidb-cluster using the MySQL client kubectl port-forward -n tidb svc/demo-tidb 4000:4000 &amp; mysql -h 127.0.0.1 -P 4000 -u root -D test -p6. View monitor dashboard for TiDB cluster kubectl port-forward -n tidb svc/demo-grafana 3000:3000 Open browser at http://localhost:3000. The default username and password is admin/admin. 使用 MySQL 客户端连接： 12345kubectl run -n tidb mysql-client --rm \ -i --tty --image mysql -- mysql \ -P 4000 -u root -h $(kubectl get \ svc demo-tidb -n tidb --output \ json | jq -r &apos;.spec.clusterIP&apos;) 或者建立隧道： 1234567kubectl -n tidb port-forward \ demo-tidb-0 4000:4000 &amp;&gt;/dev/null \ &amp;sudo apt-get install -y mysql-client \ &amp;&amp;mysql -h 127.0.0.1 -u root -P 4000 貌似现在根本连接不上了，总是提示需要密码，但是默认不是不需要密码的吗？看来需要重建集群，然后首次进入就设置好密码。用户管理参考：TiDB User Account Management]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>TiDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TiDB 学习笔记（一）]]></title>
    <url>%2F2018%2F12%2F02%2Ftidb-academy-learning-notes-part-one%2F</url>
    <content type="text"><![CDATA[引言TiDB Academy 提供了 TiDB 的视频学习资源，方便了解这个全新的数据库。在学习过程中，做了这个系列的笔记，方便后期回顾。 课程概要这个系列课程是为 MySQL DBA 准备的高级课程。讲师也假设学习者拥有 3~5 年的 MySQL 运维和使用经验。因为在讲解的过程中，会将 TiDB 的一些概念直接和 MySQL 对比（虽然并不是 MySQL DBA，但不能阻挡我学习的脚步~）。 我们将在这个系列课程中学习到很多关于如何设计和实现一个类似 TiDB 这样复杂的分布式数据库的细节。总的来说，将会涵盖如下几个话题： TiDB 的架构设计（OLTP/OLAP 支持）？ 如何做到水平扩展，同时保持数据强一致性和高可用的？ 在线 DDL 算法和实现 课前准备为了跟着教程一步步学习，自然是需要有个环境可以部署 TiDB 的咯。Google Cloud Platform 首次使用，第一年免费赠送 $300。只需要一张 Visa 信用卡绑定就可以了。 分布式数据库介绍 20 世纪 60 年代，第一代数据库诞生。主要特点： 非关系型 访问存储记录的语言不统一，与存储格式紧密关联 20 世纪 70 年代，关系模型和 SQL 诞生 20 世纪 70 年代到 21 世纪初，基于 SQL 的关系型数据占据统治地位。主要特点： 数据库厂商很多，均支持 SQL 存储过程语言很多，且移植性很差 面向单机设计 2000 年中期，NoSQL 数据库诞生。主要特点： 扩展性很好 缺乏事务支持 增加了应用程序负担，复杂性提升 新一代 NewSQL 诞生： 类似 NoSQL 的易于扩展性 关系型数据库 支持 SQL 强一致性保证 TiDB，NewSQL 家族成员： 师承 Google Spanner 架构 支持 MySQL 网络协议 应用层基本无痛切换 TiDB 使用乐观锁模型（一个比较大的差别），可参考 这段介绍]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>TiDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VSCode Markdown 写作效率提升]]></title>
    <url>%2F2018%2F11%2F04%2Fmkdown-in-vscode%2F</url>
    <content type="text"><![CDATA[引言平时多使用 VSCode 编写 Markdown 文件，虽然它也有内建的预览功能，但是效果一般。如果能有好的插件支持，可以很大程度上提高写作效率。下面几个插件着重解决这么几个问题： 支持更强大的预览功能和更丰富的扩展语法 支持快捷图片插入，自动补齐 URL 支持快捷键设置加粗、斜体等 增强插件Markdown 实时预览 在 VSCode 的插件中心搜索 Markdown Preview Enhanced 插件并安装，这款插件支持更加丰富的扩展语法，对于提升写作效率帮助很大。另外，预览功能也是非常给力，极力推荐！ 快捷插入图片在 VSCode 插件中心有两款看起来不错的图片插入工具，均支持上传至七牛云，并自动在需要插入图片的位置补全路径。 首先在 VSCode 中搜索并安装插件 paste image to qiniu，接下来配置七牛云（AK, SK, Bucket 等）： 这款插件的特点是支持直接粘贴图片并自动上传的。其默认的粘贴快捷键是 option+command+v~ 另外一款插件 qiniu-upload-image 则支持打开指定的图片并完成自动上传。其配置与上一个插件类似，不再赘述。 默认情况下，两款插件的快捷键可能不是太方便，建议可以根据自己的需要修改下： Markdown 快捷键最后要介绍的是一款能够提供 Markdown 格式常用快捷键的插件：Markdown Shortcuts。支持的快捷操作如下： 加粗 倾斜 删除线 快速制表 插入代码 填写 URL…]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>VSCode</tag>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《代码整洁之道》读书笔记]]></title>
    <url>%2F2018%2F11%2F04%2Fclean-code-notes%2F</url>
    <content type="text"><![CDATA[引言《代码整洁之道》（Clean Code）这本书非常适合每一个希望提高编程质量的程序员阅读。如何给参数命名？如何定义函数？如何编排子函数？等等这些问题的答案，你都可以在书中找到。 项目质量的好坏很大程度上取决于代码风格，如果团队的代码风格能够基本保持一致，对于每一位开发者和维护者来说都是福音。优秀的代码易于理解，逻辑清晰，命名规范，也是非常值得学习的。 本文记录了在阅读 Robert C. Martin 的《代码整洁之道》一书时学习到的关键内容，便于后期复习、反思、总结和进一步提升。努力做一个拥有良好「代码洁癖」的码农~ 命名规则 名副其实： 不需要注释来补充命名的含义 避免误导： 避免使用与本意相悖的词 堤防使用不同之处较小的名称 做有意义的区分： 不要以数字区分 避免废话 废话都是冗余，Variable 一词永远不应当出现在变量名中 要区分名称，就要以读者能鉴别不同之处的方式来区分。 使用读得出来的名称 使用可搜索的名称： 避免使用单字母的词 名称长短应与其作用域大小相对应 避免使用编码： 对于现代编译器，请摒弃匈牙利命名法 不需要成员前缀，如 _m 避免思维映射： 明确是王道 类名： 类名和对象应当是名词或者名词性短语 避免 Manager, Processor, Data 或 Info 这类的类名 类名不应该是动词。 方法名： 方法名应当是动词或动词短语 别扮可爱： 宁可明确，毋为好玩 言到意到，意到言到 每个概念对应一个词 别用双关语： 避免将同一个单词用于不同目的 使用解决方案领域名称： 多使用 CS 术语、算法、模式、数学术语吧 使用源自所涉问题领域的名称 添加有意义的语境： 良好命名的类、函数或命名空间放置名称，提供语境 使用前缀 不要添加没用的语境： 只要短名称足够清楚，就比长名称好 函数 短小： 函数的第一规则是短小，第二条是更短小 函数，20 行封顶最佳 只做一件事： 函数应该只做一件事情，最好这件事情 判断函数是否不止做了一件事情，就是看能否再拆出一个函数 如果函数只是做了该函数同一抽象层上的步骤，则函数还是只做了一件事 每个函数一个抽象层级： 自顶向下读代码：向下规则 让每个函数后面都跟着位于下一抽象层的函数 switch 语句： 多态创建，隐藏于某个继承关系中，不要暴露出来 使用描述性的名称： 如果每个例程都让你感到深合己意，那就是整洁代码 长而具有描述性的名称，比短而令人费解的名称好 长而具有描述性的名称，要比描述性的长注释好 函数参数： 参数不要过多（尽可能） 参数和函数名称处于不同的抽象层级，要求你了解目前并不特别重要的细节 标识参数丑陋不堪，意味着要做不止一件事情 有两个参数的函数要比一元函数难懂 少用参数列表 无副作用： 普遍而言，应避免使用输出参数。如果函数必须要修改某种状态，就修改所属的对象状态吧。 分隔指令与询问： 函数要么做什么事情，要么回答什么，二者不可兼得 函数应该修改对象的状态或返回对象的有关信息。 使用异常替代返回的错误码： 抽离 try/catch 代码块 函数只应该做一件事，错误处理就是一件 别重复自己（DRY)： 重复可能是软件中一切邪恶的根源 很多原则和实践规则都是为了控制与消除重复而创建 结构化编程 并不是从一开始按照规则写函数，没人可以做到。可以一开始让函数工作起来，再利用上面的规范进行优化，同时配合单元测试保证没有错误 真正的目标在于讲述系统的故事，编写的函数必须可以干净利落地拼装在一块，形成一种精确而清晰的语言，帮你讲故事 注释 注释总是一种失败，我们总无法找到不用注释就能表达自我的方法，所以总要有注释，并不值得庆祝 程序员不能坚持维护注释 真正好的注释是不写注释，用代码表达 好的注释： 法律信息 提供信息的注释 对意图的解释 阐释 警示 TODO 注释 放大 坏的注释： 喃喃自语：任何迫使读者查看其它模块的注释都没能与读者沟通好 多余的注释 误导性注释 循规蹈矩式注释 日志式注释 废话注释 可怕的废话 能用函数或变量时就别用注释 位置标记 归属与署名：源码控制系统已经可以搞定 注释掉的代码 HTML 注释 非本地信息：注释要靠近代码 信息过多 不明显的联系：注释要解释代码中不能自行解释的部分，不要让注释需要二次解析 函数头注释：用好的函数名称代替 范例 格式 代码格式很重要。代码格式关乎沟通，而沟通是专业开发的头等大事 让风格和律条永存 短文件通常比长文件易于理解 向报纸学习：循序渐进 概念间垂直方向上的区隔：空行 垂直方向上的靠近：紧密代码相互靠近 垂直距离：关系密切的概念应该相互靠近，应避免读者在源文件和类中跳来跳去 变量声明：尽可能靠近使用位置 实体变量：应在类的顶部声明 相关函数：若某个函数调用了另一个，就应该把它们放到一起，调用者应该尽可能放在被调用者上边 概念相关：此类代码应放在一起，相关性越强，应该越靠近 垂直顺序：自顶向下地展现调用依赖 横向格式：建议每行短小，120 列就是上限了 水平方向上的区隔与靠近： 加空格分隔 水平对齐： 不用太刻意关注 缩进：一种继承结构，体现一种层级关系 空范围：应当缩进开来 团队规则：遵守团队规则。好的软件系统是由一系列读起来不错的代码文件组成的 对象和数据结构 隐藏实现关乎抽象，类并不是简单地用取值器和赋值器将其变量推向外间，而是暴露抽象接口，以便用户无需了解数据的实现就能操作数据本体 数据、对象和反对称性： 对象把数据隐藏于抽象之后，暴露操作数据的函数 数据结构暴露数据，没有提供有意义的函数 过程式代码（使用数据结构的代码）便于在不改动既有数据结构的前提下新增函数。面向对象代码便于在不改动既有函数的前提下新增类，反之亦然 对于两种类型，应该根据情况考虑使用 得墨忒耳律：模块不应该了解它所操作对象的内部情形，方法不应调用任何函数返回的对象的方法（比如链式调用就违反了） 数据传送对象： 最为精炼的数据结构是一个只有公共变量、没有函数的类，即数据传送对象（DTO, Data Transfer Objects） 对象暴露行为，隐藏数据。便于添加新对象类型而无需修改既有行为，同时也难以在既有对象中添加新行为 数据结构暴露数据，没有明显的行为。便于向数据结构添加新行为，同时也难以向既有函数中添加新的数据结构 在任何系统中我们有时希望能够灵活添加新的数据类型，所以这部分使用对象。有时希望灵活添加新行为，这时更希望使用数据类型和过程。优秀的开发者不带成见地了解这些形式，根据情况选择合适的手段 错误处理当错误发生时，程序员有责任保证代码照常工作。错误处理很重要，如果搞乱了代码逻辑，则是错误的做法。 使用异常而非返回码 先写 try-catch-finally 语句： 异常的妙处之一，它们在程序中定义了一个范围 尝试编写强行抛出异常的测试，再往处理器中添加行为，使之满足测试要求 使用不可控异常： 可控异常的代价是违反“开闭原则” 一般应用开发，应该避免可控异常 给出异常发生的环境说明：创建信息充分的错误消息，并和异常一起传递出去。在消息中包括失败的操作和失败的类型 依调用者需要定义异常类： 定义异常，考虑它们应该如何捕获 将第三方 API 打包是个良好的实践手段，当打包一个第三方 API，就降低了对它的依赖，同时在测试时有助于模拟第三方调用 定义常规流程： 创建一个类或配置一个对象，用来处理特例，异常行为封装到特例对象中 避免打断业务逻辑 避免传递 None/NULL/nil 等，否则函数需要做很多额外的判断（当然，这些是必须的） 边界如何保持软件边界整洁？这一章给出一些实践手段和技巧 使用第三方代码： 边界上的接口是隐藏的 不应将含有边界接口的对象到处传递，应当把它保留在类或近亲类中 学习性测试的好处不只是免费： 无论如何都要学习使用 API，而编写测试是获得这些知识的容易而不影响其他工作的途径 学习性测试是一种精确实验，帮助我们队 API 的理解 使用尚不存在的代码： 还有一种边界，将已知和位置分隔开的边界 Fake 和 Adapter 整洁的边界： 边界上的代码需要清晰地分割和定义期望的测试。应该避免我们的代码过多了解第三方代码的特定信息 依靠你能控制的东西，好过依靠你控制不了的东西 可以采用内部隐藏边界接口或者使用适配模式保持边界整洁，从而减少接口的修改 单元测试 TDD 三定律： 在编写不能通过的单元测试前，不可编写生产代码 只可编写刚好无法通过的单元测试，不能编译也算不通过 只编写刚好可以通过当前失败测试的生产代码 保持整洁的测试： 肮脏的测试等同于没有测试 测试必须跟随生产代码修改 测试代码和生成代码一样重要，需要仔细思考、设计和照料，保持整洁 正是单元测试让你的代码可扩展、可维护、可复用 测试带来了一切好处，使变动成为可能 测试越脏，代码最终会越脏 整洁的测试： 可读性 构造-操作-检验（BUILD-OPERATE-CHECK)模式 测试直达目的，只用真正需要的数据类型和函数 专业的开发者将他们的测试代码重构为简洁和具有表达力的形式 每个测试一个断言： 每个测试时一个概念 FIRST： 快速 Fast：能够频繁运行 独立 Independent：某个测试不应为下一个测试设定条件 可重复 Repeatable：测试应当可以在任何环境中重复通过 自足验证 Self-Validating：测试应有布尔值输出，可以直接反馈测试结果 及时 Timely：测试应及时编写 或许测试更为重要，它保证和增强了生产代码的可扩展性、可维护性和可复用性 类 类的组织： 公共函数应跟在变量列表之后，我们喜欢把由某个公共函数调用的私有工具函数紧随在该公共函数的后面，符合自顶向下的原则 类应该短小： 计算「权责 responsibility」衡量类大小 类的名称应当描述权责，如果无法为某个类命名以精确的名称，这个类大概就太长了 单一权责原则（SRP)：类或模块应该有且只有一条加以修改的理由 系统应该由许多短小的类而非少量巨大的类组成。每个小类封装一个权责，只有一个修改的原因，并与少数其他类一起协同达成期望的系统行为 内聚：类应该只有少量的实体变量，类中的每个方法都应该操作一个或多个这种变量 保持内聚会得到许多短小的类 在理想系统中，我们通过扩展而非修改现有系统的方式添加新特性 部件之间的解耦代表系统中的元素相互隔离的很好，隔离也让系统每个元素的理解变得更加容易 依赖倒置原(DIP)：依赖于抽象而非实现的细节 系统（偏 Java）“复杂要人命。它消磨开发者的生命，让产品难以规划、构建和测试”—— Ray Ozzie，微软首席技术官 城市管理：有人负责全局，有人负责局部 将系统的构造和使用分开： “软件系统应将起始过程和起始过程之后的运行时逻辑分离开，在起始过程中构建应用对象，也会存在互相纠缠的依赖关系” 分解 main 工厂 依赖注入：控制反转在依赖管理中的一种应用手段 扩容： “一开始就做对系统”纯属神话 测试驱动开发、迭代和增量敏捷扩展系统 小步快跑：迭代 通过迭代和改进设计达到整洁目的（Kent Beck 的简单设计规则）： 运行所有测试 不可重复 表达了程序员的意图 尽可能减少类和方法的数量 以上规则按重要程度排序 简单设计规则 1：运行所有测试： 全面测试并持续通过所有测试的系统，就是可测试的系统 不可测试的系统不可验证，不可验证的系统，不可部署 紧耦合的代码难以编写测试，同样编写测试越多，就越会遵循 DIP 之类规则 遵循有关编写测试并持续运行测试的简单、明确的规划，系统就会更贴近 OO 低耦合度、高内聚度的目标，编写测试引致更好的设计 简单设计规则 2~4：重构： 测试消除了对清理代码就会破坏代码的恐惧 增量式重构改善代码 提升内聚性、降低耦合度、切分关注面、模块化系统性关注面、缩小函数和类的尺寸、选用更好的名称等 不可重复： 重复包括形式上和实现上的重复 模板方法模式是一种移除高层重复的通用技巧 表达力： 软件项目的主要成本在于长期维护 选用好的名称 保持函数和类尺寸短小 采用标准命名法 编写良好的单元测试 做到有表带最重要的是尝试，太多时候我们写出能工作的代码，就转移到下一个问题，没有下足功夫调整 尽可能减少类和方法： 类和方法的数量太多，有时候是由毫无意义的教条主义导致的 保持函数和类短小的同时，保持整个系统短小精悍 遵循简单设计的实践手段，开发者不必年轻学习就能掌握好的原则和模式 并发编程“对象是对过程的抽象，线程是对调度的抽象” 为什么要并发： 并发是一种解耦策略，把做什么（目的）和何时（时机）分开 解耦目的与时机能明显地改进应用程序的吞吐量和结构 误区： 并发总能改进性能 编写并发程序无需修改设计 实际： 并发会在性能和编写额外代码上增加额外一些开销 正确的并发是复杂的，几遍对于简单的问题也是如此 并发缺陷并非总能重现 并发常常需要对设计策略的根本性修改 并发防御原则： 单一权责原则： 分离并发相关的代码和其它代码 推论：限制数据作用域： 保护临界区共享对象 谨记数据封装，严格限制对可能被共享的数据的访问 推论：使用数据副本 推论：线程应尽可能独立：尝试将数据分解到可被独立线程（可能不同的服务器上）操作的独立子集 了解执行模型： 几种概念： 限定资源 互斥 线程饥饿 死锁 活锁：执行次序一致的线程，每个都想起步，但发现其他线程已经在路上 生产者-消费者模型：中间队列是限定资源 读者-写着模型 宴席哲学家 保持同步区域微小：尽可能减少同步区域，否则会增加资源竞争，执行效率降低 尽早考虑关闭问题，尽早令其正常工作 测试线程代码： 建议编写有潜力暴露问题的测试，在不同的配置和负载下频繁运行。如果测试失败，则跟踪错误 将伪失败看做可能的线程问题 先使用单线程代码可工作 编写可插拔的线程代码 编写可调整的线程代码 运行多于处理器数量的线程 在不同平台上运行 调整代码并强迫发生错误 不要将系统错误归咎于偶发事件 任务交换越频繁，越有可能找到错过临界区或导致死锁的代码 Code Smell &amp; Inspiration 注释： 不恰当的注释 废弃的注释 冗余的注释 糟糕的注释 注释掉的代码 环境： 需要多步才能实现的构建：构建系统应该是单步的小操作 需要多步才能做到的测试：应该能快速运行单元测试 函数： 过多的参数 输出参数 标志参数 死函数 一般性问题： 一个源文件中存在多种语言：应尽力减少源文件中额外语言的数量和范围 明显的行为未实现：应遵循“最小惊讶原则” 不正确的边界行为 忽视安全 重复 在错误的抽象层级上的代码： 创建分离较高层一般性概念与较低层细节概念的抽象模型很重要 孤立抽象是软件开发者最难做到的事情之一，而且一旦做错也没有快捷的修复手段 基类依赖于派生类：通常基类对派生类一无所知 信息过多： 良好设计的模块有非常小的接口 优秀开发者应该限制类或者模块中暴露的接口数量 隐藏数据、工具函数、常量、临时变量 死代码：死代码会变臭 垂直分离： 变量和函数应该靠近被使用的地方定义 私有函数应该刚好在其首次被使用的位置下面定义 前后不一致 混淆视听： 没有用到的变量、函数、注释等都要移除 保持文件整洁、良好组织 人为耦合：人为耦合是指两个没有直接目的的模块的耦合 特性依恋：类的方法只应对其所属类的变量和函数感兴趣，不应该垂青其他类中的变量和函数 选择标志参数：选择标志参数只是一种避免把大函数切分成小函数偷懒的做法 晦涩的意图 位置错误的权责 不恰当的静态方法 使用解释性变量 函数名称应该表达其行为 理解算法 把逻辑依赖改为物理依赖 用多态替换 if/else 遵循约定标准 用命名常量替代魔术数 准确：如果处理货币，请使用整数 结构甚于约定： 封装条件 避免否定性条件 函数只做一件事情 掩蔽时序耦合 别随意 封装边界条件 函数应该只在一个抽象层级上 在较高层级放置可配置数据 避免传递浏览 名称： 采用描述性名称 名称应与抽象层级相符 尽可能使用标准命名法 无歧义的名称 为较大作用范围选用较长的名称 避免编码：如一些前缀等 名称应该说明副作用 测试： 测试不足 使用覆盖率工具 别略过小测试 被忽略的测试就是对不确定事物的疑问 测试边界条件 全面测试相近的缺陷 测试失败的模式有启发性 测试应该快速]]></content>
      <categories>
        <category>编程之道</category>
      </categories>
      <tags>
        <tag>整洁代码</tag>
        <tag>编程风格</tag>
      </tags>
  </entry>
</search>
